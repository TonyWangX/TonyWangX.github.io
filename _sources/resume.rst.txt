.. temp documentation master file, created by
   sphinx-quickstart on Sun Aug 30 20:18:34 2020.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

.. _label-resume:

Resume
******

Here is the `resume in PDF <https://www.dropbox.com/sh/gf3zp00qvdp3row/AABWT45G1hu8XuHtwF7pqaLAa/web/resume.pdf?raw=1>`_.

My `Google Scholar page <https://scholar.google.com/citations?user=uMZhUHcAAAAJ&hl=en>`_ and `Researchmap site <https://researchmap.jp/wangxin?lang=en>`_.



Basic info
==========

**Xin Wang** 

Project assistant professor (in fact, post-doc)

National Institute of Informatics 

2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430, Japan 


Education
=========

Ph.D: 2015 - 2018 National Institute of Informatics, SOKENDAI, Tokyo, Japan.

   Fundamental frequency modeling for neural-betwork-based statistical parametric speech synthesis

   Supervisor: Prof. Junichi Yamagishi

   * Thesis (submitted 2018-06-29): `PDF version <https://www.dropbox.com/sh/gf3zp00qvdp3row/AACVs-tg32gsREezFhoQC1vAa/web/XinWang_THESIS_v0809.pdf?raw=1>`_

   * Slides for thesis defense: `defense slides <https://www.dropbox.com/sh/gf3zp00qvdp3row/AAAU462lbZN8qgwiTPlv8dvEa/web/THESIS_E4.pdf?raw=1>`_

   * Appendix: `highway network <https://www.dropbox.com/sh/gf3zp00qvdp3row/AACemZwy4AU8UvssM0rI5dn6a/web/THESIS_appendix_highway.pdf?raw=1>`_, `SAR <https://www.dropbox.com/sh/gf3zp00qvdp3row/AACdQpbXtMTt7j7--C8UQqUGa/web/THESIS_appendix_sar.pdf?raw=1>`_, `DAR <https://www.dropbox.com/sh/gf3zp00qvdp3row/AABQpYIevQ50TVAcm5kWumdwa/web/THESIS_appendix_dar.pdf?raw=1>`_, `VQ-VAE <https://www.dropbox.com/sh/gf3zp00qvdp3row/AADPEvEa56UsxDHMgxPnddnGa/web/THESIS_appendix_vqvae.pdf?raw=1>`_ 


M.Sc.: 2012 - 2015 University of Science and Technology of China, Hefei, China.
    
   Bi-directional optimization for concept-to-speech synthesis

   Supervisor: Prof. Zhen-Hua Ling

B.Sc.: 2008 - 2012 University of Electronic Science and Technology of China, Chengdu, China.

Academic activity
=================

Organizer

 * `ASVspoof5 <https://www.asvspoof.org/>`_, ASVspoof challenges 2021, 2019
 * `Voice Privacy Challenge <https://www.voiceprivacychallenge.org>`_ 2022, 2020 
 * APSIPA ASC 2019 special session on `Deep Generative Models for Media Clones and Its Detection <http://apsipa2019.org/SpecialSessions.html>`_
 * ISCA Interspeech 2019 special session on `Automatic Speaker Verification Spoofing and Countermeasures Challenge 2019 (ASVSpoof 2019) <https://www.interspeech2019.org/program/special_sessions_and_challenges>`_
 * IEEE ASRU 2019 special session on `ASVspoof 2019 <http://asru2019.org/wp/?page_id=622>`_

Guest editor

 * Computer Speech and Language `Special issue on Advances in Automatic Speaker Verification Anti-spoofing <https://www.journals.elsevier.com/computer-speech-and-language/call-for-papers/advances-in-automatic-speaker>`_

Reviewer

 * IEEE/ACM TASLP, TBIOM, Signal processing letters, ICASSP, EUSIPCO

 * Elsevier Computer speech \& language, Speech Communication 

 * ISCA Interspeech, Speech synthesis workshop, Odyssey workshop

 * IEICE Trans on Information and Systems

Session chair

 * `ACM MM 2022 DDAM Workshop <https://dl.acm.org/doi/proceedings/10.1145/3552466>`_, `ASVspoof workshop 2021 <https://www.isca-speech.org/archive/asvspoof_2021/index.html>`_, Interspeech 2021, SSW 2019.

 
Grants
======

* 2021 - 2023, Speech privacy protection by high-quality, invertible, and extendable speech anonymization and de-anonymization, JSPS, Wakate, 21K17775, investigator: Xin Wang

* 2020 - 2021, Deep-learning-based neural source-filtering models for fast and high-quality music signal generation, KAWAI, investigator: Xin Wang

* 2021 - 2022, Enhanced End-to-End Multi-Instrument MIDI/sheet-to-Music Synthesis with Timber and Style Transfer, JST AIP Challenge, investigator: Xin Wang

* 2019 - 2021, One model for all sounds: fast and high-quality neural source-filter model for speech and non-speech waveform modeling, JSPS, grant-for-startup, 19K24371, investigator: Xin Wang
  
* 2021 - 2022, Optimizing a Speech Anti-spoofing Database, Google Research grant, investigators: Junichi Yamagishi, Xin Wang, Eric Cooper
  
* 2019 - 2020, AI Focused Research Awards Program in Japan: Robust and all-purpose neural source-filter models, Google, investigators: Junichi Yamagishi, Xin Wang, Eric Cooper


Publication
===========

Journal & book chapter

#. **Xin Wang**, and Junichi Yamagishi. A Practical Guide to Logical Access Voice Presentation Attack Detection. In Frontiers in Fake Media Generation and Detection. Springer. 2022.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2020. Neural Source-Filter Waveform Models for Statistical Parametric Speech Synthesis. IEEE/ACM Transactions on Audio, Speech, and Language Processing 28: 402–415. doi:10.1109/TASLP.2019.2956145.

#. **Xin Wang**, Shinji Takaki, Junichi Yamagishi, Simon King, and Keiichi Tokuda. 2020. A Vector Quantized Variational Autoencoder (VQ-VAE) Autoregressive Neural F0 Model for Statistical Parametric Speech Synthesis. IEEE/ACM Transactions on Audio, Speech, and Language Processing 28: 157–170. doi:10.1109/TASLP.2019.2950099.

#. **Xin Wang**, Junichi Yamagishi, Massimiliano Todisco, Hector Delgado, Andreas Nautsch, Nicholas Evans, Md Sahidullah, Ville Vestman, Tomi Kinnunen, Kong Aik Lee, Lauri Juvela, Paavo Alku, Yu-Huai Peng, Hsin-Te Hwang, Yu Tsao, Hsin-Min Wang, Sébastien Le Maguer, Markus Becker, Fergus Henderson, Rob Clark, Yu Zhang, Quan Wang, Ye Jia, Kai Onuma, Koji Mushika, Takashi Kaneda, Yuan Jiang, Li-Juan Liu, Yi-Chiao Wu, Wen-Chin Huang, Tomoki Toda, Kou Tanaka, Hirokazu Kameoka, Ingmar Steiner, Driss Matrouf, Jean-François Bonastre, Avashna Govender, Srikanth Ronanki, Jing-Xuan Zhang, and Zhen-Hua Ling. 2020. ASVspoof 2019: A Large-Scale Public Database of Synthesized, Converted and Replayed Speech. Computer Speech & Language, 101114. doi:https://doi.org/10.1016/j.csl.2020.101114.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2018. Investigating Very Deep Highway Networks for Parametric Speech Synthesis. Speech Communication 96: 1–9. doi:https://doi.org/10.1016/j.specom.2017.11.002.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2018. Autoregressive Neural F0 Model for Statistical Parametric Speech Synthesis. IEEE/ACM Transactions on Audio, Speech, and Language Processing 26 (8). IEEE: 1406–1419. doi:10.1109/TASLP.2018.2828650.

#. **Xin Wang**, Zhen-Hua Ling, and Li-Rong Dai. 2016. Concept-to-Speech Generation with Knowledge Sharing for Acoustic Modelling and Utterance Filtering. Computer Speech & Language 38 (July). Elsevier: 46–67. doi:10.1016/j.csl.2015.12.003.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2016. Investigation of Using Continuous Representation of Various Linguistic Units in Neural Network Based Text-to-Speech Synthesis. IEICE Transactions on Information and Systems E99.D (10): 2471–2480. doi:10.1587/transinf.2016SLP0011.

#. Brij Mohan Lal Srivastava, Mohamed Maouche, Md Sahidullah, Emmanuel Vincent, Aurélien Bellet, Marc Tommasi, Natalia Tomashenko, **Xin Wang**, and Junichi Yamagishi. Privacy and Utility of X-Vector Based Speaker Anonymization. IEEE/ACM Transactions on Audio, Speech, and Language Processing 30. IEEE: 2383–2395. 2022.
   
#. Natalia Tomashenko, **Xin Wang**, Emmanuel Vincent, Jose Patino, Brij Mohan Lal Srivastava, Paul-Gauthier Noé, Andreas Nautsch, Nicholas Evans, Junichi Yamagishi, Benjamin O’Brien, Anaïs Chanclu, Jean-François Bonastre, Massimiliano Todisco, and Mohamed Maouche. The VoicePrivacy 2020 Challenge: Results and Findings. Computer Speech & Language, February, 101362. doi:10.1016/j.csl.2022.101362. 2022. 

#. Andreas Nautsch, **Xin Wang**, Nicolas Evans, Tomi Kinnunen, Ville Vestman, Massimiliano Todisco, Hector Delgado, Md Sahidullah, Junichi Yamagishi, and Kong Aik Lee.  ASVspoof 2019: Spoofing Countermeasures for the Detection of Synthesized, Converted and Replayed Speech . IEEE Trans. on Biometrics, Behavior, and Identity (T-BIOM), (accepted). 2021.

#. Yusuke Yasuda, **Xin Wang**, and Junichi Yamagishi.  Investigation of Learning Abilities on Linguistic Features in Sequence-to-Sequence Text-to-Speech Synthesis . Computer Speech & Language 67: 101183, doi:https://doi.org/10.1016/j.csl.2020.101183. 2021.

#. Shuhei Kato, Yusuke Yasuda, **Xin Wang**, Erica Cooper, Shinji Takaki, and Junichi Yamagishi. 2020. Modeling of Rakugo Speech and Its Limitations: Toward Speech Synthesis That Entertains Audiences. IEEE Access 8: 138149–138161.

#. Tomi Kinnunen, Hector Delgado, Nicholas Evans, Kong Aik Lee, Ville Vestman, Andreas Nautsch, Massimiliano Todisco, **Xin Wang**, Md Sahidullah, Junichi Yamagishi, and Douglas A Reynolds. 2020. Tandem Assessment of Spoofing Countermeasures and Automatic Speaker Verification: Fundamentals. IEEE/ACM Transactions on Audio, Speech, and Language Processing. IEEE.



Conference 

#. **Xin Wang**, and Junichi Yamagishi. Investigating Active-Learning-Based Training Data Selection for Speech Spoofing Countermeasure. In Proc. SLT, accepted. 2023.

#. **Xin Wang**, and Junichi Yamagishi. Investigating Self-Supervised Front Ends for Speech Spoofing Countermeasures. Proc. Odyssey. 100-106, 2022 .

#. Hemlata Tak, Massimiliano Todisco, **Xin Wang**, Jee-weon Jung, Junichi Yamagishi, and Nicholas Evans. Automatic Speaker Verification Spoofing and Deepfake Detection Using Wav2vec 2.0 and Data Augmentation. In Proc. Odyssey. 112-119, 2022.

#. Xiaoxiao Miao, **Xin Wang**, Erica Cooper, Junichi Yamagishi, and Natalia Tomashenko. Language-Independent Speaker Anonymization Approach Using Self-Supervised Pre-Trained Models. In Proc. Odyssey, 279-286, 2022.

#. **Xin Wang**, and Junichi Yamagishi. Estimating the Confidence of Speech Spoofing Countermeasure. In Proc. ICASSP. 6372-6376, 2022.

#. Chang Zeng, **Xin Wang**, Erica Cooper, Xiaoxiao Miao, and Junichi Yamagishi. Attention Back-End for Automatic Speaker Verification with Multiple Enrollment Utterances. In Proc. ICASSP. 2022.

#. Erica Cooper, **Xin Wang**, and Junichi Yamagishi. Text-to-Speech Synthesis Techniques for MIDI-to-Audio Synthesis. In Proc. 11th ISCA Speech Synthesis Workshop (SSW 11), 130–135. doi:10.21437/SSW.2021-23. 2021.
   
#. Tomi Kinnunen, Andreas Nautsch, Md. Sahidullah, Nicholas Evans, **Xin Wang**, Massimiliano Todisco, Héctor Delgado, Junichi Yamagishi, and Kong Aik Lee. Visualizing Classifier Adjacency Relations: A Case Study in Speaker Verification and Voice Anti-Spoofing. In Proc. Interspeech, 4299–4303. doi:10.21437/Interspeech.2021-1522. 2021.

#. Lin Zhang, **Xin Wang**, Erica Cooper, and Junichi Yamagishi. Multi-Task Learning in Utterance-Level and Segmental-Level Spoof Detection. In Proc. ASVspoof Challenge Workshop, 9–15. doi:10.21437/ASVSPOOF.2021-2. 2021.

#. Jean-François Bonastre, Héctor Delgado, Nicholas Evans, Tomi Kinnunen, Kong Aik Lee, Xuechen Liu, Andreas Nautsch, Paul-Gauthier Noé, Jose Patino, Md Sahidullah, Brij Mohan Lal Srivastava, Massimiliano Todisco, Natalia Tomashenko, Emmanuel Vincent, **Xin Wang**, and Junichi Yamagishi. Benchmarking and Challenges in Security and Privacy for Voice Biometrics. In Proc. 2021 ISCA Symposium on Security and Privacy in Speech Communication, 52–56. doi:10.21437/SPSC.2021-11. 2021.
   
#. Junichi Yamagishi, **Xin Wang**, Massimiliano Todisco, Md Sahidullah, Jose Patino, Andreas Nautsch, Xuechen Liu, Kong Aik Lee, Tomi Kinnunen, Nicholas Evans, and Héctor Delgado. ASVspoof 2021: Accelerating Progress in Spoofed and Deepfake Speech Detection. In Proc. ASVspoof Challenge Workshop, 47–54. doi:10.21437/ASVSPOOF.2021-8. 2021.

#. **Xin Wang**, and Junich Yamagishi. A Comparative Study on Recent Neural Spoofing Countermeasures for Synthetic Speech Detection. In Proc. Interspeech, 4259–4263. doi:10.21437/Interspeech.2021-702. 2021.

#. Lin Zhang, **Xin Wang**, Erica Cooper, Junichi Yamagishi, Jose Patino, and Nicholas Evans. An Initial Investigation for Detecting Partially Spoofed Audio. In Proc. Interspeech, 4264–4268. doi:10.21437/Interspeech.2021-738. 2021.

#. Yang Ai, Haoyu Li, **Xin Wang**, Junichi Yamagishi, and Zhenhua Ling. Denoising-and-Dereverberation Hierarchical Neural Vocoder for Robust Waveform Generation. In 2021 IEEE Spoken Language Technology Workshop (SLT), 477–484. IEEE. doi:10.1109/SLT48900.2021.9383611. 2021.

#. Shuhei Kato, Yusuke Yasuda, **Xin Wang**, Erica Cooper, and Junichi Yamagishi. How Similar or Different Is Rakugo Speech Synthesizer to Professional Performers? In Proc. ICASSP, 6488–6492. IEEE. doi:10.1109/ICASSP39728.2021.9414175. 2021.
   
#. Yusuke Yasuda, **Xin Wang**, and Junichi Yamagishd. End-to-End Text-to-Speech Using Latent Duration Based on VQ-VAE. In Proc. ICASSP, 5694–5698. IEEE. doi:10.1109/ICASSP39728.2021.9414499. 2021.

#. Brij Mohan Lal Srivastava, Natalia Tomashenko, **Xin Wang**, Emmanuel Vincent, Junichi Yamagishi, Mohamed Maouche, Aurelien Bellet, and Marc Tommasi. 2020. Design Choices for X-Vector Based Speaker Anonymization. In Proc. Interspeech, 1713-1717. ISCA: ISCA. doi:10.21437/Interspeech.2020-2692.

#. Natalia Tomashenko, Brij Mohan Lal Srivastava, **Xin Wang**, Emmanuel Vincent, Andreas Nautsch, Junichi Yamagishi, Nicholas Evans, Jose Patino, Jean-Francois Bonastre, Paul-Gauthier Noe, and Massimiliano Todisco. 2020. Introducing the VoicePrivacy Initiative. In Proc. Interspeech, 1693-1697. ISCA: ISCA. doi:10.21437/Interspeech.2020-1333.

#. **Xin Wang**, and Junichi Yamagishi. 2020. Using Cyclic Noise as the Source Signal for Neural Source-Filter-Based Speech Waveform Model. In Proc. Interspeech, 1992-1996. ISCA: ISCA. doi:10.21437/Interspeech.2020-1018.

#. Yang Ai, **Xin Wang**, Junichi Yamagishi, and Zhen-Hua Ling. 2020. Reverberation Modeling for Source-Filter-Based Neural Vocoder. In Proc. Interspeech, 3560-3564. doi:10.21437/Interspeech.2020-1613.

#. Yi Zhao, **Xin Wang**, Lauri Juvela, and Junichi Yamagishi. 2020. Transferring Neural Speech Waveform Synthesizers to Musical Instrument Sounds Generation. In Proc. ICASSP, 6269–6273. IEEE. doi:10.1109/ICASSP40776.2020.9053047.

#. Yusuke Yasuda, **Xin Wang**, and Junichi Yamagishi. 2020. Effect of Choice of Probability Distribution, Randomness, and Search Methods for Alignment Modeling in Sequence-to-Sequence Text-to-Speech Synthesis Using Hard Alignment. In Proc. ICASSP, 6724–6728.

#. Erica Cooper, Cheng-I Lai, Yusuke Yasuda, Fuming Fang, **Xin Wang**, Nanxin Chen, and Junichi Yamagishi. 2020. Zero-Shot Multi-Speaker Text-to-Speech with State-of-the-Art Neural Speaker Embeddings. In Proc. ICASSP, 6184–6188.

#. Mingyang Zhang, **Xin Wang**, Fuming Fang, Haizhou Li, and Junichi Yamagishi. 2019. Joint Training Framework for Text-to-Speech and Voice Conversion Using Multi-Source Tacotron and WaveNet. In Proc. Interspeech, 1298–1302. doi:10.21437/Interspeech.2019-1357.

#. Yusuke Yasuda, **Xin Wang**, and Junichi Yamagishi. 2019. Initial Investigation of Encoder-Decoder End-to-End TTS Using Marginalization of Monotonic Hard Alignments. In Proc. SSW, 211–216. doi:10.21437/SSW.2019-38.

#. Yusuke Yasuda, **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2019. Investigation of Enhanced Tacotron Text-to-Speech Synthesis Systems with Self-Attention for Pitch Accent Language. In Proc. ICASSP, 6905–6909.

#. **Xin Wang**, and Junichi Yamagishi. 2019. Neural Harmonic-plus-Noise Waveform Model with Trainable Maximum Voice Frequency for Text-to-Speech Synthesis. In Proc. SSW, 1–6. ISCA: ISCA. doi:10.21437/SSW.2019-1.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2019. Neural Source-Filter-Based Waveform Model for Statistical Parametric Speech Synthesis. In Proc. ICASSP, 5916–5920.

#. Massimiliano Todisco, **Xin Wang**, Ville Vestman, Md. Sahidullah, Héctor Delgado, Andreas Nautsch, Junichi Yamagishi, Nicholas Evans, Tomi H Kinnunen, and Kong Aik Lee. 2019. ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection. In Proc. Interspeech, 1008–1012. doi:10.21437/Interspeech.2019-2249.

#. Shinji Takaki, Toru Nakashika, **Xin Wang**, and Junichi Yamagishi. 2019. STFT Spectral Loss for Training a Neural Speech Waveform Model. In Proc. ICASSP, 7065–7069.

#. Hieu-Thi Luong, **Xin Wang**, Junichi Yamagishi, and Nobuyuki Nishizawa. 2019. Training Multi-Speaker Neural Text-to-Speech Systems Using Speaker-Imbalanced Speech Corpora. In Proc. Interspeech, 1303–1307. doi:10.21437/Interspeech.2019-1311.

#. Chen-Chou Lo, Szu-Wei Fu, Wen-Chin Huang, **Xin Wang**, Junichi Yamagishi, Yu Tsao, and Hsin-Min Wang. 2019. MOSnet: Deep Learning-Based Objective Assessment for Voice Conversion. In Proc. Interspeech, 1541–1545. doi:10.21437/Interspeech.2019-2003.

#. Shuhei Kato, Yusuke Yasuda, **Xin Wang**, Erica Cooper, Shinji Takaki, and Junichi Yamagishi. 2019. Rakugo Speech Synthesis Using Segment-to-Segment Neural Transduction and Style Tokens - toward Speech Synthesis for Entertaining Audiences. In Proc. SSW, 111–116. doi:10.21437/SSW.2019-20.

#. Fuming Fang, **Xin Wang**, Junichi Yamagishi, Isao Echizen, Massimiliano Todisco, Nicholas Evans, and Jean-Francois Bonastre. 2019. Speaker Anonymization Using X-Vector and Neural Waveform Models. In Proc. SSW, 155–160. doi:10.21437/SSW.2019-28.

#. Fuming Fang, **Xin Wang**, Junichi Yamagishi, and Isao Echizen. 2019. Audiovisual Speaker Conversion: Jointly and Simultaneously Transforming Facial Expression and Acoustic Characteristics. In Proc. ICASSP, 6795–6799.

#. **Xin Wang**, Jaime Lorenzo-Trueba, Shinji Takaki, Lauri Juvela, and Junichi Yamagishi. 2018. A Comparison of Recent Waveform Generation and Acoustic Modeling Methods for Neural-Network-Based Speech Synthesis. In Proc. ICASSP, 4804–4808.

#. Hieu-Thi Luong, **Xin Wang**, Junichi Yamagishi, and Nobuyuki Nishizawa. 2018. Investigating Accuracy of Pitch-Accent Annotations in Neural-Network-Based Speech Synthesis and Denoising Effects. In Proc. Interspeech 2018, 37–41.

#. Jaime Lorenzo-Trueba, Fuming Fang, **Xin Wang**, Isao Echizen, Junichi Yamagishi, and Tomi Kinnunen. 2018. Can We Steal Your Vocal Identity from the Internet?: Initial Investigation of Cloning Obama’s Voice Using GAN, WaveNet and Low-Quality Found Data. In Proc. Odyssey, 240–247. ISCA: ISCA. doi:10.21437/Odyssey.2018-34.

#. Lauri Juvela, Bajibabu Bollepalli, **Xin Wang**, Hirokazu Kameoka, Manu Airaksinen, Junichi Yamagishi, and Paavo Alku. 2018. Speech Waveform Synthesis from MFCC Sequences with Generative Adversarial Networks. In Proc. ICASSP, 5679–5683.

#. Gustav Eje Henter, Jaime Lorenzo-Trueba, **Xin Wang**, Mariko Kondo, and Junichi Yamagishi. 2018. Cyborg Speech: Deep Multilingual Speech Synthesis for Generating Segmental Foreign Accent with Natural Prosody. In Proc. ICASSP, 4799–4803.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2017. An RNN-Based Quantized F0 Model with Multi-Tier Feedback Links for Text-to-Speech Synthesis. In Proc. Interspeech, 1059–1063.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2017. An Autoregressive Recurrent Mixture Density Network for Parametric Speech Synthesis. In Proc. ICASSP, 4895–4899.

#. Gustav Eje Henter, Jaime Lorenzo-Trueba, **Xin Wang**, and Junichi Yamagishi. 2017. Principles for Learning Controllable TTS from Annotated and Latent Variation. In Proc. Interspeech, 3956–3960. doi:10.21437/Interspeech.2017-171.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2016. Enhance the Word Vector with Prosodic Information for the Recurrent Neural Network Based TTS System. In Proc. Interspeech, 2856–2860.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2016. Investigating Very Deep Highway Networks for Parametric Speech Synthesis. In Proc. SSW9, 181–186.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2016. A Comparative Study of the Performance of HMM, DNN, and RNN Based Speech Synthesis Systems Trained on Very Large Speaker-Dependent Corpora. In Proc. SSW9, 125–128.

#. **Xin Wang**, Minghui Dong, and Zhenhua Ling. 2016. A Full Training Framework of Cross-Stream Dependence Modelling for HMM-Based Singing Voice Synthesis. In Proc. ICASSP, 5165–5169. doi:10.1109/ICASSP.2016.7472662.

#. Cassia Valentini-Botinhao, **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2016. Speech Enhancement for a Noise-Robust Text-to-Speech Synthesis System Using Deep Recurrent Neural Networks. In Proc. Interspeech, 352–356.

#. Cassia Valentini-Botinhao, **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2016. Investigating RNN-Based Speech Enhancement Methods for Noise-Robust Text-to-Speech. In Proc. SSW, 146–152.

#. Lauri Juvela, **Xin Wang**, Shinji Takaki, Manu Airaksinen, Junichi Yamagishi, and Paavo Alku. 2016. Using Text and Acoustic Features in Predicting Glottal Excitation Waveforms for Parametric Speech Synthesis with Recurrent Neural Networks. In Proc. Interspeech, 2283–2287.

#. **Xin Wang**, Zhen-Hua Ling, and Li-Rong Dai. 2014. Concept-to-Speech Generation by Integrating Syntagmatic Features into HMM-Based Speech Synthesis. In Proc. Interspeech, 2942–2946.

#. **Xin Wang**, Zhen-Hua Ling, and Li-Rong Dai. 2012. Cross-Stream Dependency Modeling Using Continuous F0 Model for HMM-Based Speech Synthesis. In Proc. ISCSLP, 84–87.

Talk
====

(check :ref:`label-slide` to download slides)

* 2022 Sep, ``SPSC Symposium: tutorial on speaker anonymization (software part)``. The hands-on notebook is available on `Google Colab <https://colab.research.google.com/drive/1_zRL_f9iyDvl_5Y2Rdakg0hYAl_5Rgyq?usp=sharing>`__.

* 2022 May, ``ICASSP short course: inclusive Neural Speech Synthesis - neural vocoder part``. ICASSP 2022. The materials for ICASSP short course on neural vocoders are available on `Google colab <https://colab.research.google.com/drive/1EO-ggi1U9f2zXwTiqg7AEljVx11JKta7>`_. The old contents are re-edited, and new contents are available. 

* 2021 Dec, ``Two speech security issues after the speech synthesis boom``. Speech Synthesis Forum, China Computer Federation. `Slides here <https://www.dropbox.com/sh/gf3zp00qvdp3row/AADDhVJGzMbXEquzf2Z1Y8YHa/web/CCF-talk-2021.pptx>`_.
  
* 2021 Oct, ``Deepfakes: High-tech Illusions to Trick the Human Brain.``, JST Science Agora 2021, pre-Agora event, with Sascha Frühholz (University of Zurich), Erica Cooper, Florence Steiner (University of Zurich). Video is `here <https://youtu.be/FfhiGFA0dg8>`_

* 2021 July, ``Advancement in Neural Vocoders``. Tutorial at ISCA 2021 Speech Processing Courses in Crete, with Prof. Yamagishi. Hands-on-materials on `github <https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts/tree/master/tutorials>`_. `Slides <https://www.slideshare.net/jyamagis/advancements-in-neural-vocoders>`_
  
* 2020 Nov., ``Neural statistical parametric speech synthesis``. Tutorial as ISCA 2020 Speaker Odyssey, Tokyo. `PDF <https://www.dropbox.com/sh/gf3zp00qvdp3row/AABFY0RiorILzSuX1YuQXyA7a/web/Odyssesy2020_Tutorial_TTS_XINWANG.pdf?raw=1>`_ and `PPT slides <https://www.dropbox.com/sh/gf3zp00qvdp3row/AABn3DyzRuZeBJwEGPV1ouFSa/web/Odyssesy2020_Tutorial_TTS_XINWANG.pptx?raw=1>`_ are available.

* 2020 July, ``Neural auto-regressive, source-filter and glottal vocoders for speech and music signals``. Tutorial at ISCA 2020 Speech Processing Courses in Crete, with Prof. Yamagishi. Hands-on-materials on `github <https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts/tree/master/tutorials>`_.

* 2019 Sep, ``Neural waveform models for text-to-speech synthesis``, Fraunhofer IIS, invited talk, Erlangen, Germany. Slide is `here 1 <https://www.dropbox.com/sh/gf3zp00qvdp3row/AAByUSX6u4O51bGHpIFlgy-ba/web/201909-FraunhoderIIS-neural-waveform-models.pdf?raw=1>`_

* 2019 Jan, ``Tutorial on recent neural waveform models``, IEICE Technical Committee on Speech (SP), invited tutorial, Kanazawa, Japan. Slide is `here 2 <https://www.slideshare.net/jyamagis/tutorial-on-endtoend-texttospeech-synthesis-part-1-neural-waveform-modeling>`_

* 2018 Nov, ``Autoregressive neural networks for parametric speech synthesis``, Nagoya Institute of Technology, Tokuda lab. Slide is `here 3 <https://www.dropbox.com/sh/gf3zp00qvdp3row/AACZVX1Tf9Qw1MUc2YHQKf4Ia/web/20180111-Nagoya-ARmodels.pdf?raw=1>`_

* 2018 Jun, ``Autoregressive neural networks for parametric speech synthesis``, University of Eastern Finland, School of Computing, Aalto University, Paavo Alku lab (same content as above)


Awards & scholarship
====================
* Best paper award for `SSW 2016 <https://www.soken.ac.jp/news/5935/>`_, ISCA SynSig

* `SOKENDAI Award <https://www.soken.ac.jp/news/5935/>`_, SOKENDAI, Japan

* `Young Researcher's Award in Speech Field <https://www.ieice.org/iss/sp/jpn/special/sp-prize.html>`_, IEICE ISS, Japan

* 11th IEEE Signal Processing Society Japan Student `Best Paper Award <https://ieee-jp.org/section/tokyo/chapter/SP-01/past-student-paper.htm>`_, IEEE Japan

* MEXT Scholarship (Ph.D 2015 - 2018), Japan


Language
========
* Mandarin
* English (Toefl 2015, 112/120)
* Japanese (N1, 2021 Dec)
  
.. toctree::
   :hidden:
   :maxdepth: 1

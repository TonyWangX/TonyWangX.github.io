
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Resume &#8212; HomePage-WangXin  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Research" href="research.html" />
    <link rel="prev" title="Welcome" href="index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="resume">
<span id="label-resume"></span><h1>Resume<a class="headerlink" href="#resume" title="Permalink to this heading">¶</a></h1>
<p>Here is the <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABWT45G1hu8XuHtwF7pqaLAa/web/resume.pdf?raw=1">resume in PDF</a>.</p>
<p>My <a class="reference external" href="https://scholar.google.com/citations?user=uMZhUHcAAAAJ&amp;hl=en">Google Scholar page</a> and <a class="reference external" href="https://researchmap.jp/wangxin?lang=en">Researchmap site</a>.</p>
<section id="basic-info">
<h2>Basic info<a class="headerlink" href="#basic-info" title="Permalink to this heading">¶</a></h2>
<p><strong>Xin Wang</strong></p>
<p>Project Associate Professor (in fact, post-doc)</p>
<p>National Institute of Informatics</p>
<p>2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430, Japan</p>
</section>
<section id="education">
<h2>Education<a class="headerlink" href="#education" title="Permalink to this heading">¶</a></h2>
<p>Ph.D: 2015 - 2018 National Institute of Informatics, SOKENDAI, Tokyo, Japan.</p>
<blockquote>
<div><p>Fundamental frequency modeling for neural-betwork-based statistical parametric speech synthesis</p>
<p>Supervisor: Prof. Junichi Yamagishi</p>
<ul class="simple">
<li><p>Thesis (submitted 2018-06-29): <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AACVs-tg32gsREezFhoQC1vAa/web/XinWang_THESIS_v0809.pdf?raw=1">PDF version</a></p></li>
<li><p>Slides for thesis defense: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAAU462lbZN8qgwiTPlv8dvEa/web/THESIS_E4.pdf?raw=1">defense slides</a></p></li>
<li><p>Appendix: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AACemZwy4AU8UvssM0rI5dn6a/web/THESIS_appendix_highway.pdf?raw=1">highway network</a>, <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AACdQpbXtMTt7j7--C8UQqUGa/web/THESIS_appendix_sar.pdf?raw=1">SAR</a>, <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABQpYIevQ50TVAcm5kWumdwa/web/THESIS_appendix_dar.pdf?raw=1">DAR</a>, <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AADPEvEa56UsxDHMgxPnddnGa/web/THESIS_appendix_vqvae.pdf?raw=1">VQ-VAE</a></p></li>
</ul>
</div></blockquote>
<p>M.Sc.: 2012 - 2015 University of Science and Technology of China, Hefei, China.</p>
<blockquote>
<div><p>Bi-directional optimization for concept-to-speech synthesis</p>
<p>Supervisor: Prof. Zhen-Hua Ling</p>
</div></blockquote>
<p>B.Sc.: 2008 - 2012 University of Electronic Science and Technology of China, Chengdu, China.</p>
</section>
<section id="academic-activity">
<h2>Academic activity<a class="headerlink" href="#academic-activity" title="Permalink to this heading">¶</a></h2>
<p>Organizer</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://www.asvspoof.org/">ASVspoof5</a>, ASVspoof challenges 2021, 2019</p></li>
<li><p><a class="reference external" href="https://www.voiceprivacychallenge.org">Voice Privacy Challenge</a> 2022, 2020</p></li>
<li><p>APSIPA ASC 2019 special session on <a class="reference external" href="http://apsipa2019.org/SpecialSessions.html">Deep Generative Models for Media Clones and Its Detection</a></p></li>
<li><p>ISCA Interspeech 2019 special session on <a class="reference external" href="https://www.interspeech2019.org/program/special_sessions_and_challenges">Automatic Speaker Verification Spoofing and Countermeasures Challenge 2019 (ASVSpoof 2019)</a></p></li>
<li><p>IEEE ASRU 2019 special session on <a class="reference external" href="http://asru2019.org/wp/?page_id=622">ASVspoof 2019</a></p></li>
</ul>
</div></blockquote>
<p>Guest editor</p>
<blockquote>
<div><ul class="simple">
<li><p>Computer Speech and Language <a class="reference external" href="https://www.journals.elsevier.com/computer-speech-and-language/call-for-papers/advances-in-automatic-speaker">Special issue on Advances in Automatic Speaker Verification Anti-spoofing</a></p></li>
</ul>
</div></blockquote>
<p>Reviewer</p>
<blockquote>
<div><ul class="simple">
<li><p>IEEE/ACM TASLP, TBIOM, Signal processing letters, ICASSP, EUSIPCO</p></li>
<li><p>Elsevier Computer speech &amp; language, Speech Communication</p></li>
<li><p>ISCA Interspeech, Speech synthesis workshop, Odyssey workshop</p></li>
<li><p>IEICE Trans on Information and Systems</p></li>
</ul>
</div></blockquote>
<p>Session chair</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://dl.acm.org/doi/proceedings/10.1145/3552466">ACM MM 2022 DDAM Workshop</a>, <a class="reference external" href="https://www.isca-speech.org/archive/asvspoof_2021/index.html">ASVspoof workshop 2021</a>, Interspeech 2021, SSW 2019.</p></li>
</ul>
</div></blockquote>
</section>
<section id="grants">
<h2>Grants<a class="headerlink" href="#grants" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>2023 - 2027, Unified framework for speech privacy protection and anti-spoofing, JST, PRESTO, investigator: Xin Wang</p></li>
<li><p>2021 - 2023, Speech privacy protection by high-quality, invertible, and extendable speech anonymization and de-anonymization, JSPS, Wakate, 21K17775, investigator: Xin Wang</p></li>
<li><p>2020 - 2021, Deep-learning-based neural source-filtering models for fast and high-quality music signal generation, KAWAI, investigator: Xin Wang</p></li>
<li><p>2021 - 2022, Enhanced End-to-End Multi-Instrument MIDI/sheet-to-Music Synthesis with Timber and Style Transfer, JST AIP Challenge, investigator: Xin Wang</p></li>
<li><p>2019 - 2021, One model for all sounds: fast and high-quality neural source-filter model for speech and non-speech waveform modeling, JSPS, grant-for-startup, 19K24371, investigator: Xin Wang</p></li>
<li><p>2021 - 2022, Optimizing a Speech Anti-spoofing Database, Google Research grant, investigators: Junichi Yamagishi, Xin Wang, Eric Cooper</p></li>
<li><p>2019 - 2020, AI Focused Research Awards Program in Japan: Robust and all-purpose neural source-filter models, Google, investigators: Junichi Yamagishi, Xin Wang, Eric Cooper</p></li>
</ul>
</section>
<section id="publication">
<h2>Publication<a class="headerlink" href="#publication" title="Permalink to this heading">¶</a></h2>
<section id="journal-book-chapters">
<h3>Journal &amp; book chapters<a class="headerlink" href="#journal-book-chapters" title="Permalink to this heading">¶</a></h3>
<blockquote>
<div><p>Speech Synthesis</p>
</div></blockquote>
<ol class="arabic">
<li><p><strong>Xin Wang</strong>, Shinji Takaki, Junichi Yamagishi, Simon King and Keiichi Tokuda. A Vector Quantized Variational Autoencoder (VQ-VAE) Autoregressive Neural F0 Model for Statistical Parametric Speech SynthesisIEEE/ACM Transactions on Audio, Speech, and Language Processingvol: 28, pages 157-170. doi: 10.1109/TASLP.2019.2950099. 2020.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Neural Source-Filter Waveform Models for Statistical Parametric Speech SynthesisIEEE/ACM Transactions on Audio, Speech, and Language Processingvol: 28, pages 402-415. doi: 10.1109/TASLP.2019.2956145. 2020.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Investigating very deep highway networks for parametric speech synthesisSpeech Communicationvol: 96, pages 1-9. doi: 10.1016/j.specom.2017.11.002. 2018.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Autoregressive Neural F0 Model for Statistical Parametric Speech SynthesisIEEE/ACM Transactions on Audio, Speech, and Language Processingvol: 26, pages 1406-1419. doi: 10.1109/TASLP.2018.2828650. 2018.</p></li>
<li><p><strong>Xin Wang</strong>, Zhen-Hua Ling and Li-Rong Dai. Concept-to-Speech generation with knowledge sharing for acoustic modelling and utterance filteringComputer Speech &amp; Languagevol: 38, pages 46-67. doi: 10.1016/j.csl.2015.12.003. 2016.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Investigation of Using Continuous Representation of Various Linguistic Units in Neural Network Based Text-to-Speech SynthesisIEICE Transactions on Information and Systemsvol: E99.D, pages 2471-2480. doi: 10.1587/transinf.2016SLP0011. 2016.</p></li>
<li><p>Yusuke Yasuda, <strong>Xin Wang</strong> and Junichi Yamagishi. Investigation of learning abilities on linguistic features in sequence-to-sequence text-to-speech synthesisComputer Speech &amp; Languagevol: 67, pages 101183. doi: <a class="reference external" href="https://doi.org/10.1016/j.csl.2020.101183">https://doi.org/10.1016/j.csl.2020.101183</a>. 2021.</p></li>
<li><p>Shuhei Kato, Yusuke Yasuda, <strong>Xin Wang</strong>, Erica Cooper, Shinji Takaki and Junichi Yamagishi. Modeling of Rakugo Speech and Its Limitations: Toward Speech Synthesis That Entertains AudiencesIEEE Accessvol: 8, pages 138149-138161. doi: 10.1109/ACCESS.2020.3011975. 2020.</p>
<p>Speech anti-spoofing</p>
</li>
<li><p><strong>Xin Wang</strong>, Junichi Yamagishi, Massimiliano Todisco, H{'{e}}ctor Delgado, Andreas Nautsch, Nicholas Evans, Md Sahidullah, Ville Vestman, Tomi Kinnunen, Kong Aik Lee, Lauri Juvela, Paavo Alku, Yu-Huai Peng, Hsin-Te Hwang, Yu Tsao, Hsin-Min Wang, S{'{e}}bastien Le Maguer, Markus Becker, Fergus Henderson, Rob Clark, Yu Zhang, Quan Wang, Ye Jia, Kai Onuma, Koji Mushika, Takashi Kaneda, Yuan Jiang, Li-Juan Liu, Yi-Chiao Wu, Wen-Chin Huang, Tomoki Toda, Kou Tanaka, Hirokazu Kameoka, Ingmar Steiner, Driss Matrouf, Jean-Fran{c{c}}ois Bonastre, Avashna Govender, Srikanth Ronanki, Jing-Xuan Zhang and Zhen-Hua Ling. ASVspoof 2019: A large-scale public database of synthesized, converted and replayed speechComputer Speech &amp; Languagevol: 64, pages 101114. doi: 10.1016/j.csl.2020.101114. 2020.</p></li>
<li><p>Xuechen Liu, <strong>Xin Wang</strong>, Md Sahidullah, Jose Patino, H{'{e}}ctor Delgado, Tomi Kinnunen, Massimiliano Todisco, Junichi Yamagishi, Nicholas Evans, Andreas Nautsch and Kong Aik Lee. ASVspoof 2021: Towards Spoofed and Deepfake Speech Detection in the WildIEEE Trans. on Audio, Speech, and Language Processingpages (accepted). 2023.</p></li>
<li><p>Lin Zhang, <strong>Xin Wang</strong>, Erica Cooper, Nicholas Evans and Junichi Yamagishi. The PartialSpoof Database and Countermeasures for the Detection of Short Fake Speech Segments Embedded in an UtteranceIEEE/ACM Transactions on Audio, Speech, and Language Processingpages 1-13. doi: 10.1109/TASLP.2022.3233236. 2022.</p></li>
<li><p>Andreas Nautsch, <strong>Xin Wang</strong>, Nicholas Evans, Tomi H. Kinnunen, Ville Vestman, Massimiliano Todisco, Hector Delgado, Md Sahidullah, Junichi Yamagishi and Kong Aik Lee. ASVspoof 2019: Spoofing Countermeasures for the Detection of Synthesized, Converted and Replayed SpeechIEEE Transactions on Biometrics, Behavior, and Identity Sciencevol: 3, pages 252-265. doi: 10.1109/TBIOM.2021.3059479. 2021.</p></li>
<li><p>Tomi Kinnunen, Hector Delgado, Nicholas Evans, Kong Aik Lee, Ville Vestman, Andreas Nautsch, Massimiliano Todisco, <strong>Xin Wang</strong>, Md Sahidullah, Junichi Yamagishi and Douglas A Reynolds. Tandem Assessment of Spoofing Countermeasures and Automatic Speaker Verification: FundamentalsIEEE/ACM Transactions on Audio, Speech, and Language Processingvol: 28, pages 2195-2210. doi: 10.1109/TASLP.2020.3009494. 2020.</p></li>
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. A Practical Guide to Logical Access Voice Presentation Attack DetectionFrontiers in Fake Media Generation and Detectionpages 169-214. doi: 10.1007/978-981-19-1524-6_8. 2022.</p></li>
<li><p>Md Sahidullah, H{'{e}}ctor Delgado, Massimiliano Todisco, Andreas Nautsch, <strong>Xin Wang</strong>, Tomi Kinnunen, Nicholas Evans, Junichi Yamagishi and Kong-Aik Lee. Introduction to Voice Presentation Attack Detection and Recent AdvancesHandbook of Biometric Anti-Spoofingpages 339-385. doi: 10.1007/978-981-19-5288-3_13. 2023.</p>
<p>Speaker anonymization</p>
</li>
<li><p>Xiaoxiao Miao, <strong>Xin Wang</strong>, Erica Cooper, Junichi Yamagishi and Natalia Tomashenko. Language-Independent Speaker Anonymization Using Orthogonal {{Householder}} Neural NetworkIEEE/ACM Transactions on Audio, Speech, and Language Processingpages (accepted). 2023.</p></li>
<li><p>Natalia Tomashenko, <strong>Xin Wang</strong>, Emmanuel Vincent, Jose Patino, Brij Mohan Lal Srivastava, Paul-Gauthier No{'{e}}, Andreas Nautsch, Nicholas Evans, Junichi Yamagishi, Benjamin O’Brien, Ana{&quot;{i}}s Chanclu, Jean-Fran{c{c}}ois Bonastre, Massimiliano Todisco and Mohamed Maouche. The VoicePrivacy 2020 Challenge: Results and findingsComputer Speech &amp; Languagepages 101362. doi: <a class="reference external" href="https://doi.org/10.1016/j.csl.2022.101362">https://doi.org/10.1016/j.csl.2022.101362</a>. 2022.</p></li>
<li><p>Brij Mohan Lal Srivastava, Mohamed Maouche, Md Sahidullah, Emmanuel Vincent, Aurelien Bellet, Marc Tommasi, Natalia Tomashenko, <strong>Xin Wang</strong> and Junichi Yamagishi. Privacy and Utility of X-Vector Based Speaker AnonymizationIEEE/ACM Transactions on Audio, Speech, and Language Processingvol: 30, pages 2383-2395. doi: 10.1109/TASLP.2022.3190741. 2022.</p></li>
</ol>
</section>
<section id="conference">
<h3>Conference<a class="headerlink" href="#conference" title="Permalink to this heading">¶</a></h3>
<blockquote>
<div><p>Speech Synthesis</p>
</div></blockquote>
<ol class="arabic">
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. Using Cyclic Noise as the Source Signal for Neural Source-Filter-Based Speech Waveform ModelProc. Interspeechpages 1992-1996. doi: 10.21437/Interspeech.2020-1018. 2020.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Neural Source-filter-based Waveform Model for Statistical Parametric Speech SynthesisProc. ICASSPpages 5916-5920. doi: 10.1109/ICASSP.2019.8682298. 2019.</p></li>
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. Neural Harmonic-plus-Noise Waveform Model with Trainable Maximum Voice Frequency for Text-to-Speech SynthesisProc. SSWpages 1-6. doi: 10.21437/SSW.2019-1. 2019.</p></li>
<li><p><strong>Xin Wang</strong>, Jaime Lorenzo-Trueba, Shinji Takaki, Lauri Juvela and Junichi Yamagishi. A comparison of recent waveform generation and acoustic modeling methods for neural-network-based speech synthesisProc. ICASSPpages 4804-4808. 2018.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. An RNN-based quantized F0 model with multi-tier feedback links for text-to-speech synthesisProc. Interspeechpages 1059-1063. 2017.</p></li>
<li><p><strong>Xin Wang</strong>, Minghui Dong and Zhenhua Ling. A full training framework of cross-stream dependence modelling for HMM-based singing voice synthesisProc. ICASSPpages 5165-5169. doi: 10.1109/ICASSP.2016.7472662. 2016.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. A comparative study of the performance of HMM, DNN, and RNN based speech synthesis systems trained on very large speaker-dependent corporaProc. SSWpages 125-128. 2016.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Investigating very deep highway networks for parametric speech synthesisProc. SSWpages 181-186. 2016.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Enhance the word vector with prosodic information for the recurrent neural network based TTS systemProc. Interspeechpages 2856-2860. 2016.</p></li>
<li><p><strong>Xin Wang</strong>, Zhen-Hua Ling and Li-Rong Dai. Concept-to-speech generation by integrating syntagmatic features into HMM-based speech synthesisProc. Interspeechpages 2942-2946. 2014.</p></li>
<li><p><strong>Xin Wang</strong>, Zhen-Hua Ling and Li-Rong Dai. Cross-stream dependency modeling using continuous F0 model for HMM-based speech synthesisProc. ISCSLPpages 84-87. 2012.</p></li>
<li><p>Shuhei Kato, Yusuke Yasuda, <strong>Xin Wang</strong>, Erica Cooper and Junichi Yamagishi. How Similar or Different is Rakugo Speech Synthesizer to Professional Performers?Proc. ICASSPpages 6488-6492. doi: 10.1109/ICASSP39728.2021.9414175. 2021.</p></li>
<li><p>Yang Ai, Haoyu Li, <strong>Xin Wang</strong>, Junichi Yamagishi and Zhenhua Ling. Denoising-and-Dereverberation Hierarchical Neural Vocoder for Robust Waveform GenerationProc. SLTpages 477-484. doi: 10.1109/SLT48900.2021.9383611. 2021.</p></li>
<li><p>Yusuke Yasuda, <strong>Xin Wang</strong> and Junichi Yamagishd. End-to-End Text-to-Speech Using Latent Duration Based on VQ-VAEProc. ICASSPpages 5694-5698. doi: 10.1109/ICASSP39728.2021.9414499. 2021.</p></li>
<li><p>Erica Cooper, <strong>Xin Wang</strong> and Junichi Yamagishi. Text-to-Speech Synthesis Techniques for MIDI-to-Audio SynthesisProc. SSWpages 130-135. doi: 10.21437/SSW.2021-23. 2021.</p></li>
<li><p>Yi Zhao, <strong>Xin Wang</strong>, Lauri Juvela and Junichi Yamagishi. Transferring neural speech waveform synthesizers to musical instrument sounds generationProc. ICASSPpages 6269-6273. doi: 10.1109/ICASSP40776.2020.9053047. 2020.</p></li>
<li><p>Erica Cooper, Cheng-I Lai, Yusuke Yasuda, Fuming Fang, <strong>Xin Wang</strong>, Nanxin Chen and Junichi Yamagishi. Zero-shot multi-speaker text-to-speech with state-of-the-art neural speaker embeddingsProc. ICASSPpages 6184-6188. 2020.</p></li>
<li><p>Yusuke Yasuda, <strong>Xin Wang</strong> and Junichi Yamagishi. Effect of choice of probability distribution, randomness, and search methods for alignment modeling in sequence-to-sequence text-to-speech synthesis using hard alignmentProc. ICASSPpages 6724-6728. 2020.</p></li>
<li><p>Yang Ai, <strong>Xin Wang</strong>, Junichi Yamagishi and Zhen-Hua Ling. Reverberation Modeling for Source-Filter-Based Neural VocoderProc. Interspeechpages 3560-3564. doi: 10.21437/Interspeech.2020-1613. 2020.</p></li>
<li><p>Yusuke Yasuda, <strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Investigation of enhanced Tacotron text-to-speech synthesis systems with self-attention for pitch accent languageProc. ICASSPpages 6905-6909. 2019.</p></li>
<li><p>Fuming Fang, <strong>Xin Wang</strong>, Junichi Yamagishi and Isao Echizen. Audiovisual speaker conversion: jointly and simultaneously transforming facial expression and acoustic characteristicsProc. ICASSPpages 6795-6799. 2019.</p></li>
<li><p>Shinji Takaki, Toru Nakashika, <strong>Xin Wang</strong> and Junichi Yamagishi. STFT spectral loss for training a neural speech waveform modelProc. ICASSPpages 7065-7069. 2019.</p></li>
<li><p>Hieu-Thi Luong, <strong>Xin Wang</strong>, Junichi Yamagishi and Nobuyuki Nishizawa. Training multi-speaker neural text-to-speech systems using speaker-imbalanced speech corporaProc. Interspeechpages 1303-1307. doi: 10.21437/Interspeech.2019-1311. 2019.</p></li>
<li><p>Mingyang Zhang, <strong>Xin Wang</strong>, Fuming Fang, Haizhou Li and Junichi Yamagishi. Joint training framework for text-to-speech and voice conversion using multi-source tacotron and WaveNetProc. Interspeechpages 1298-1302. doi: 10.21437/Interspeech.2019-1357. 2019.</p></li>
<li><p>Yusuke Yasuda, <strong>Xin Wang</strong> and Junichi Yamagishi. Initial investigation of encoder-decoder end-to-end TTS using marginalization of monotonic hard alignmentsProc. SSWpages 211-216. doi: 10.21437/SSW.2019-38. 2019.</p></li>
<li><p>Shuhei Kato, Yusuke Yasuda, <strong>Xin Wang</strong>, Erica Cooper, Shinji Takaki and Junichi Yamagishi. Rakugo speech synthesis using segment-to-segment neural transduction and style tokens - toward speech synthesis for entertaining audiencesProc. SSWpages 111-116. doi: 10.21437/SSW.2019-20. 2019.</p></li>
<li><p>Gustav Eje Henter, Jaime Lorenzo-Trueba, <strong>Xin Wang</strong>, Mariko Kondo and Junichi Yamagishi. Cyborg speech: Deep multilingual speech synthesis for generating segmental foreign accent with natural prosodyProc. ICASSPpages 4799-4803. 2018.</p></li>
<li><p>Lauri Juvela, Bajibabu Bollepalli, <strong>Xin Wang</strong>, Hirokazu Kameoka, Manu Airaksinen, Junichi Yamagishi and Paavo Alku. Speech waveform synthesis from MFCC sequences with generative adversarial networksProc. ICASSPpages 5679-5683. 2018.</p></li>
<li><p>Hieu-Thi Luong, <strong>Xin Wang</strong>, Junichi Yamagishi and Nobuyuki Nishizawa. Investigating accuracy of pitch-accent annotations in neural-network-based speech synthesis and denoising effectsProc. Interspeechpages 37-41. 2018.</p></li>
<li><p>Jaime Lorenzo-Trueba, Fuming Fang, <strong>Xin Wang</strong>, Isao Echizen, Junichi Yamagishi and Tomi Kinnunen. Can we steal your vocal identity from the Internet?: Initial investigation of cloning Obama’s voice using GAN, WaveNet and low-quality found dataProc. Odysseypages 240-247. doi: 10.21437/Odyssey.2018-34. 2018.</p></li>
<li><p>Gustav Eje Henter, Jaime Lorenzo-Trueba, <strong>Xin Wang</strong> and Junichi Yamagishi. Principles for learning controllable TTS from annotated and latent variationProc. Interspeechpages 3956-3960. doi: 10.21437/Interspeech.2017-171. 2017.</p></li>
<li><p>Lauri Juvela, <strong>Xin Wang</strong>, Shinji Takaki, Manu Airaksinen, Junichi Yamagishi and Paavo Alku. Using text and acoustic features in predicting glottal excitation waveforms for parametric speech synthesis with recurrent neural networksProc. Interspeechpages 2283-2287. 2016.</p>
<p>Speech anti-spoofing</p>
</li>
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. Investigating Active-learning-based Training Data Selection for Speech Spoofing CountermeasureProc. SLTpages 585-592. 2023.</p></li>
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. Spoofed training data for speech spoofing countermeasure can be efficiently created using neural vocodersProc. ICASSPpages (accepted). 2023.</p></li>
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. Estimating the Confidence of Speech Spoofing CountermeasureProc. ICASSPpages 6372-6376. doi: 10.1109/ICASSP43922.2022.9746204. 2022.</p></li>
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. Investigating Self-Supervised Front Ends for Speech Spoofing CountermeasuresProc. Odysseypages 100-106. doi: 10.21437/Odyssey.2022-14. 2022.</p></li>
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. A comparative study on recent neural spoofing countermeasures for synthetic speech detectionProc. Interspeechpages 4259-4263. doi: 10.21437/Interspeech.2021-702. 2021.</p></li>
<li><p>Sung Hwan Mun, Hye-jin Shim, Hemlata Tak, <strong>Xin Wang</strong>, Xuechen Liu, Md Sahidullah, Myeonghun Jeong, Min Hyun Han, Massimiliano Todisco, Kong Aik Lee, Junichi Yamagishi, Nicholas Evans, Tomi Kinnunen, Nam Soo Kim and Jee-weon Jung. Towards Single Integrated Spoofing-aware Speaker Verification EmbeddingsProc. Interspeechpages 3989-3993. doi: 10.21437/Interspeech.2023-1402. 2023.</p></li>
<li><p>Chang Zeng, <strong>Xin Wang</strong>, Xiaoxiao Miao, Erica Cooper and Junichi Yamagishi. Improving Generalization Ability of Countermeasures for New Mismatch Scenario by Combining Multiple Advanced Regularization TermsProc. Interspeechpages 1998-2002. doi: 10.21437/Interspeech.2023-125. 2023.</p></li>
<li><p>Lin Zhang, <strong>Xin Wang</strong>, Erica Cooper, Nicholas Evans and Junichi Yamagishi. Range-Based Equal Error Rate for Spoof LocalizationProc. Interspeechpages 3212-3216. doi: 10.21437/Interspeech.2023-1214. 2023.</p></li>
<li><p>Hemlata Tak, Massimiliano Todisco, <strong>Xin Wang</strong>, Jee-weon Jung, Junichi Yamagishi and Nicholas Evans. Automatic speaker verification spoofing and deepfake detection using wav2vec 2.0 and data augmentationProc. Odysseypages 112-119. 2022.</p></li>
<li><p>Lin Zhang, <strong>Xin Wang</strong>, Erica Cooper, Junichi Yamagishi, Jose Patino and Nicholas Evans. An Initial Investigation for Detecting Partially Spoofed AudioProc. Interspeechpages 4264-4268. doi: 10.21437/Interspeech.2021-738. 2021.</p></li>
<li><p>Lin Zhang, <strong>Xin Wang</strong>, Erica Cooper and Junichi Yamagishi. Multi-task Learning in Utterance-level and Segmental-level Spoof DetectionProc. ASVspoof Challenge workshoppages 9-15. doi: 10.21437/ASVSPOOF.2021-2. 2021.</p></li>
<li><p>Tomi Kinnunen, Andreas Nautsch, Md. Sahidullah, Nicholas Evans, <strong>Xin Wang</strong>, Massimiliano Todisco, H{'{e}}ctor Delgado, Junichi Yamagishi and Kong Aik Lee. Visualizing Classifier Adjacency Relations: A Case Study in Speaker Verification and Voice Anti-SpoofingProc. Interspeechpages 4299-4303. doi: 10.21437/Interspeech.2021-1522. 2021.</p></li>
<li><p>Junichi Yamagishi, <strong>Xin Wang</strong>, Massimiliano Todisco, Md Sahidullah, Jose Patino, Andreas Nautsch, Xuechen Liu, Kong Aik Lee, Tomi Kinnunen, Nicholas Evans and H{'{e}}ctor Delgado. ASVspoof 2021: accelerating progress in spoofed and deepfake speech detectionProc. ASVspoof Challenge workshoppages 47-54. doi: 10.21437/ASVSPOOF.2021-8. 2021.</p></li>
<li><p>Massimiliano Todisco, <strong>Xin Wang</strong>, Ville Vestman, Md. Sahidullah, H{'{e}}ctor Delgado, Andreas Nautsch, Junichi Yamagishi, Nicholas Evans, Tomi H Kinnunen and Kong Aik Lee. ASVspoof 2019: future horizons in spoofed and fake audio detectionProc. Interspeechpages 1008-1012. doi: 10.21437/Interspeech.2019-2249. 2019.</p>
<p>Speaker anonymization</p>
</li>
<li><p>Xiaoxiao Miao, <strong>Xin Wang</strong>, Erica Cooper, Junichi Yamagishi and Natalia Tomashenko. Language-Independent Speaker Anonymization Approach Using Self-Supervised Pre-Trained Modelspages 279-286. doi: 10.21437/Odyssey.2022-39. 2022.</p></li>
<li><p>Xiaoxiao Miao, <strong>Xin Wang</strong>, Erica Cooper, Junichi Yamagishi and Natalia Tomashenko. Analyzing Language-Independent Speaker Anonymization Framework under Unseen ConditionsProc. Interspeechpages 4426-4430. doi: 10.21437/Interspeech.2022-11065. 2022.</p></li>
<li><p>Jean-Fran{c{c}}ois Bonastre, H{'{e}}ctor Delgado, Nicholas Evans, Tomi Kinnunen, Kong Aik Lee, Xuechen Liu, Andreas Nautsch, Paul-Gauthier Noe, Jose Patino, Md Sahidullah, Brij Mohan Lal Srivastava, Massimiliano Todisco, Natalia Tomashenko, Emmanuel Vincent, <strong>Xin Wang</strong> and Junichi Yamagishi. Benchmarking and challenges in security and privacy for voice biometricsProc. 2021 ISCA Symposium on Security and Privacy in Speech Communicationpages 52-56. doi: 10.21437/SPSC.2021-11. 2021.</p></li>
<li><p>Natalia Tomashenko, Brij Mohan Lal Srivastava, <strong>Xin Wang</strong>, Emmanuel Vincent, Andreas Nautsch, Junichi Yamagishi, Nicholas Evans, Jose Patino, Jean-Fran{c{c}}ois Bonastre, Paul-Gauthier No{'{e}} and Massimiliano Todisco. Introducing the VoicePrivacy InitiativeProc. Interspeechpages 1693-1697. doi: 10.21437/Interspeech.2020-1333. 2020.</p></li>
<li><p>Brij Mohan Lal Srivastava, Natalia Tomashenko, <strong>Xin Wang</strong>, Emmanuel Vincent, Junichi Yamagishi, Mohamed Maouche, Aur{'{e}}lien Bellet and Marc Tommasi. Design Choices for X-Vector Based Speaker AnonymizationProc. Interspeechpages 1713-1717. doi: 10.21437/Interspeech.2020-2692. 2020.</p></li>
<li><p>Fuming Fang, <strong>Xin Wang</strong>, Junichi Yamagishi, Isao Echizen, Massimiliano Todisco, Nicholas Evans and Jean-Francois Bonastre. Speaker anonymization using X-vector and neural waveform modelsProc. SSWpages 155-160. doi: 10.21437/SSW.2019-28. 2019.</p>
<p>Other topics</p>
</li>
<li><p>Chang Zeng, <strong>Xin Wang</strong>, Erica Cooper, Xiaoxiao Miao and Junichi Yamagishi. Attention Back-end for Automatic Speaker Verification with Multiple Enrollment UtterancesProc. ICASSPpages (accepted). 2022.</p></li>
<li><p>Chen-Chou Lo, Szu-Wei Fu, Wen-Chin Huang, <strong>Xin Wang</strong>, Junichi Yamagishi, Yu Tsao and Hsin-Min Wang. MOSnet: deep learning-based objective assessment for voice conversionProc. Interspeechpages 1541-1545. doi: 10.21437/Interspeech.2019-2003. 2019.</p></li>
<li><p>Cassia Valentini-Botinhao, <strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Investigating RNN-based speech enhancement methods for noise-robust text-to-speechProc. SSWpages 146-152. 2016.</p></li>
<li><p>Cassia Valentini-Botinhao, <strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Speech enhancement for a noise-robust text-to-speech synthesis system using deep recurrent neural networksProc. Interspeechpages 352-356. 2016.</p></li>
</ol>
</section>
</section>
<section id="talk">
<h2>Talk<a class="headerlink" href="#talk" title="Permalink to this heading">¶</a></h2>
<p>(check <a class="reference internal" href="slide.html#label-slide"><span class="std std-ref">Talk &amp; slides</span></a> to download slides)</p>
<ul class="simple">
<li><p>2023 Aug, <code class="docutils literal notranslate"><span class="pre">Interspeech</span> <span class="pre">2023</span> <span class="pre">tutorial:</span> <span class="pre">Advances</span> <span class="pre">in</span> <span class="pre">audio</span> <span class="pre">anti-spoofing</span> <span class="pre">and</span> <span class="pre">deepfake</span> <span class="pre">detection</span> <span class="pre">using</span> <span class="pre">graph</span> <span class="pre">neural</span> <span class="pre">networks</span> <span class="pre">and</span> <span class="pre">self-supervised</span> <span class="pre">learning</span></code>. Materials are available on <a class="reference external" href="https://github.com/Jungjee/INTERSPEECH2023_T6">github</a>.</p></li>
<li><p>2023 Mar, <code class="docutils literal notranslate"><span class="pre">SPSC</span> <span class="pre">webinar:</span> <span class="pre">using</span> <span class="pre">vocoders</span> <span class="pre">to</span> <span class="pre">create</span> <span class="pre">training</span> <span class="pre">data</span> <span class="pre">for</span> <span class="pre">speech</span> <span class="pre">spoofing</span> <span class="pre">countermeasure</span></code>. The slides are available <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAA8o9fpoJV27JL2y02_p46Ea/web/20230306_spsc_webinar_xinwang.pdf">in PDF</a> and <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABdRnr6WPKr0cI4DU32FPN2a/web/20230306_spsc_webinar_xinwang.pptx">PPTX</a>.</p></li>
<li><p>2022 Sep, <code class="docutils literal notranslate"><span class="pre">SPSC</span> <span class="pre">Symposium:</span> <span class="pre">tutorial</span> <span class="pre">on</span> <span class="pre">speaker</span> <span class="pre">anonymization</span> <span class="pre">(software</span> <span class="pre">part)</span></code>. The hands-on notebook is available on <a class="reference external" href="https://colab.research.google.com/drive/1_zRL_f9iyDvl_5Y2Rdakg0hYAl_5Rgyq?usp=sharing">Google Colab</a>.</p></li>
<li><p>2022 May, <code class="docutils literal notranslate"><span class="pre">ICASSP</span> <span class="pre">short</span> <span class="pre">course:</span> <span class="pre">inclusive</span> <span class="pre">Neural</span> <span class="pre">Speech</span> <span class="pre">Synthesis</span> <span class="pre">-</span> <span class="pre">neural</span> <span class="pre">vocoder</span> <span class="pre">part</span></code>. ICASSP 2022. The materials for ICASSP short course on neural vocoders are available on <a class="reference external" href="https://colab.research.google.com/drive/1EO-ggi1U9f2zXwTiqg7AEljVx11JKta7">Google colab</a>. The old contents are re-edited, and new contents are available.</p></li>
<li><p>2021 Dec, <code class="docutils literal notranslate"><span class="pre">Two</span> <span class="pre">speech</span> <span class="pre">security</span> <span class="pre">issues</span> <span class="pre">after</span> <span class="pre">the</span> <span class="pre">speech</span> <span class="pre">synthesis</span> <span class="pre">boom</span></code>. Speech Synthesis Forum, China Computer Federation. <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AADDhVJGzMbXEquzf2Z1Y8YHa/web/CCF-talk-2021.pptx">Slides here</a>.</p></li>
<li><p>2021 Oct, <code class="docutils literal notranslate"><span class="pre">Deepfakes:</span> <span class="pre">High-tech</span> <span class="pre">Illusions</span> <span class="pre">to</span> <span class="pre">Trick</span> <span class="pre">the</span> <span class="pre">Human</span> <span class="pre">Brain.</span></code>, JST Science Agora 2021, pre-Agora event, with Sascha Frühholz (University of Zurich), Erica Cooper, Florence Steiner (University of Zurich). Video is <a class="reference external" href="https://youtu.be/FfhiGFA0dg8">here</a></p></li>
<li><p>2021 July, <code class="docutils literal notranslate"><span class="pre">Advancement</span> <span class="pre">in</span> <span class="pre">Neural</span> <span class="pre">Vocoders</span></code>. Tutorial at ISCA 2021 Speech Processing Courses in Crete, with Prof. Yamagishi. Hands-on-materials on <a class="reference external" href="https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts/tree/master/tutorials">github</a>. <a class="reference external" href="https://www.slideshare.net/jyamagis/advancements-in-neural-vocoders">Slides</a></p></li>
<li><p>2020 Nov., <code class="docutils literal notranslate"><span class="pre">Neural</span> <span class="pre">statistical</span> <span class="pre">parametric</span> <span class="pre">speech</span> <span class="pre">synthesis</span></code>. Tutorial as ISCA 2020 Speaker Odyssey, Tokyo. <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABFY0RiorILzSuX1YuQXyA7a/web/Odyssesy2020_Tutorial_TTS_XINWANG.pdf?raw=1">PDF</a> and <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABn3DyzRuZeBJwEGPV1ouFSa/web/Odyssesy2020_Tutorial_TTS_XINWANG.pptx?raw=1">PPT slides</a> are available.</p></li>
<li><p>2020 July, <code class="docutils literal notranslate"><span class="pre">Neural</span> <span class="pre">auto-regressive,</span> <span class="pre">source-filter</span> <span class="pre">and</span> <span class="pre">glottal</span> <span class="pre">vocoders</span> <span class="pre">for</span> <span class="pre">speech</span> <span class="pre">and</span> <span class="pre">music</span> <span class="pre">signals</span></code>. Tutorial at ISCA 2020 Speech Processing Courses in Crete, with Prof. Yamagishi. Hands-on-materials on <a class="reference external" href="https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts/tree/master/tutorials">github</a>.</p></li>
<li><p>2019 Sep, <code class="docutils literal notranslate"><span class="pre">Neural</span> <span class="pre">waveform</span> <span class="pre">models</span> <span class="pre">for</span> <span class="pre">text-to-speech</span> <span class="pre">synthesis</span></code>, Fraunhofer IIS, invited talk, Erlangen, Germany. Slide is <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAByUSX6u4O51bGHpIFlgy-ba/web/201909-FraunhoderIIS-neural-waveform-models.pdf?raw=1">here 1</a></p></li>
<li><p>2019 Jan, <code class="docutils literal notranslate"><span class="pre">Tutorial</span> <span class="pre">on</span> <span class="pre">recent</span> <span class="pre">neural</span> <span class="pre">waveform</span> <span class="pre">models</span></code>, IEICE Technical Committee on Speech (SP), invited tutorial, Kanazawa, Japan. Slide is <a class="reference external" href="https://www.slideshare.net/jyamagis/tutorial-on-endtoend-texttospeech-synthesis-part-1-neural-waveform-modeling">here 2</a></p></li>
<li><p>2018 Nov, <code class="docutils literal notranslate"><span class="pre">Autoregressive</span> <span class="pre">neural</span> <span class="pre">networks</span> <span class="pre">for</span> <span class="pre">parametric</span> <span class="pre">speech</span> <span class="pre">synthesis</span></code>, Nagoya Institute of Technology, Tokuda lab. Slide is <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AACZVX1Tf9Qw1MUc2YHQKf4Ia/web/20180111-Nagoya-ARmodels.pdf?raw=1">here 3</a></p></li>
<li><p>2018 Jun, <code class="docutils literal notranslate"><span class="pre">Autoregressive</span> <span class="pre">neural</span> <span class="pre">networks</span> <span class="pre">for</span> <span class="pre">parametric</span> <span class="pre">speech</span> <span class="pre">synthesis</span></code>, University of Eastern Finland, School of Computing, Aalto University, Paavo Alku lab (same content as above)</p></li>
</ul>
</section>
<section id="awards-scholarship">
<h2>Awards &amp; scholarship<a class="headerlink" href="#awards-scholarship" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>Best paper award for <a class="reference external" href="https://www.soken.ac.jp/news/5935/">SSW 2016</a>, ISCA SynSig</p></li>
<li><p><a class="reference external" href="https://www.soken.ac.jp/news/5935/">SOKENDAI Award</a>, SOKENDAI, Japan</p></li>
<li><p><a class="reference external" href="https://www.ieice.org/iss/sp/jpn/special/sp-prize.html">Young Researcher’s Award in Speech Field</a>, IEICE ISS, Japan</p></li>
<li><p>11th IEEE Signal Processing Society Japan Student <a class="reference external" href="https://ieee-jp.org/section/tokyo/chapter/SP-01/past-student-paper.htm">Best Paper Award</a>, IEEE Japan</p></li>
<li><p>MEXT Scholarship (Ph.D 2015 - 2018), Japan</p></li>
</ul>
</section>
<section id="language">
<h2>Language<a class="headerlink" href="#language" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>Mandarin</p></li>
<li><p>English (Toefl 2015, 112/120)</p></li>
<li><p>Japanese (N1, 2021 Dec, 169/180)</p></li>
</ul>
<div class="toctree-wrapper compound">
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Page contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Resume</a><ul>
<li><a class="reference internal" href="#basic-info">Basic info</a></li>
<li><a class="reference internal" href="#education">Education</a></li>
<li><a class="reference internal" href="#academic-activity">Academic activity</a></li>
<li><a class="reference internal" href="#grants">Grants</a></li>
<li><a class="reference internal" href="#publication">Publication</a><ul>
<li><a class="reference internal" href="#journal-book-chapters">Journal &amp; book chapters</a></li>
<li><a class="reference internal" href="#conference">Conference</a></li>
</ul>
</li>
<li><a class="reference internal" href="#talk">Talk</a></li>
<li><a class="reference internal" href="#awards-scholarship">Awards &amp; scholarship</a></li>
<li><a class="reference internal" href="#language">Language</a></li>
</ul>
</li>
</ul>
<h3><a href="index.html">Site map</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Welcome</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Resume</a></li>
<li class="toctree-l1"><a class="reference internal" href="research.html">Research work</a></li>
<li class="toctree-l1"><a class="reference internal" href="slide.html">Talk &amp; slides</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, WangXin.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 5.0.2</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/resume.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>
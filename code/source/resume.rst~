.. temp documentation master file, created by
   sphinx-quickstart on Sun Aug 30 20:18:34 2020.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

.. _label-resume:

Resume
******

Here is the `resume in PDF <https://www.dropbox.com/sh/gf3zp00qvdp3row/AABWT45G1hu8XuHtwF7pqaLAa/web/resume.pdf?raw=1>`_.

My `Google Scholar page <https://scholar.google.com/citations?user=uMZhUHcAAAAJ&hl=en>`_ and `Researchmap site <https://researchmap.jp/wangxin?lang=en>`_.



Basic info
==========

**Xin Wang** 

Project assistant professor (in fact, post-doc)

National Institute of Informatics 

2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430, Japan 


Education
=========

Ph.D: 2015 - 2018 National Institute of Informatics, SOKENDAI, Tokyo, Japan.

   Dissertation Fundamental frequency modeling for neural-betwork-based statistical parametric speech synthesis

   Supervisor: Prof. Junichi Yamagishi

M.Sc.: 2012 - 2015 University of Science and Technology of China, Hefei, China.
    
   Bi-directional optimization for concept-to-speech synthesis

   Supervisor: Prof. Zhen-Hua Ling

B.Sc.: 2008 - 2012 University of Electronic Science and Technology of China, Chengdu, China.

Academic activity
=================

Organizer

 * ISCA Interspeech 2020 `special session on voice privacy <https://www.voiceprivacychallenge.org>`_ 
 * APSIPA ASC 2019 special session on `Deep Generative Models for Media Clones and Its Detection <http://apsipa2019.org/SpecialSessions.html>`_
 * ISCA Interspeech 2019 special session on `Automatic Speaker Verification Spoofing and Countermeasures Challenge 2019 (ASVSpoof 2019) <https://www.interspeech2019.org/program/special_sessions_and_challenges>`_
 * IEEE ASRU 2019 `special session on ASVspoof 2019 <http://asru2019.org/wp/?page_id=622>`_

Guest editor

 * Computer Speech and Language `Special issue on Advances in Automatic Speaker Verification Anti-spoofing <https://www.journals.elsevier.com/computer-speech-and-language/call-for-papers/advances-in-automatic-speaker>`_

Reviewer

 * IEEE/ACM TASLP, TBIOM, Signal processing letters, ICASSP, EUSIPCO

 * Elsevier Computer speech \& language 

 * ISCA Interspeech, Speech synthesis workshop

 * IEICE Trans on Information and Systems

Grants
======
* 2020 - 2021, Deep-learning-based neural source-filtering models for fast and high-quality music signal generation, KAWAI, investigator: Xin Wang

* 2019 - 2021, One model for all sounds: fast and high-quality neural source-filter model for speech and non-speech waveform modeling, JSPS, grant-for-startup, 19K24371, investigator: Xin Wang

* 2019 - 2020, AI Focused Research Awards Program in Japan: Robust and all-purpose neural source-filter models, Google, investigators: Junichi Yamagishi, Xin Wang, Eric Cooper


Publication
===========

Journal

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2020. Neural Source-Filter Waveform Models for Statistical Parametric Speech Synthesis. IEEE/ACM Transactions on Audio, Speech, and Language Processing 28: 402–415. doi:10.1109/TASLP.2019.2956145.

#. **Xin Wang**, Shinji Takaki, Junichi Yamagishi, Simon King, and Keiichi Tokuda. 2020. A Vector Quantized Variational Autoencoder (VQ-VAE) Autoregressive Neural F0 Model for Statistical Parametric Speech Synthesis. IEEE/ACM Transactions on Audio, Speech, and Language Processing 28: 157–170. doi:10.1109/TASLP.2019.2950099.

#. **Xin Wang**, Junichi Yamagishi, Massimiliano Todisco, Hector Delgado, Andreas Nautsch, Nicholas Evans, Md Sahidullah, Ville Vestman, Tomi Kinnunen, Kong Aik Lee, Lauri Juvela, Paavo Alku, Yu-Huai Peng, Hsin-Te Hwang, Yu Tsao, Hsin-Min Wang, Sébastien Le Maguer, Markus Becker, Fergus Henderson, Rob Clark, Yu Zhang, Quan Wang, Ye Jia, Kai Onuma, Koji Mushika, Takashi Kaneda, Yuan Jiang, Li-Juan Liu, Yi-Chiao Wu, Wen-Chin Huang, Tomoki Toda, Kou Tanaka, Hirokazu Kameoka, Ingmar Steiner, Driss Matrouf, Jean-François Bonastre, Avashna Govender, Srikanth Ronanki, Jing-Xuan Zhang, and Zhen-Hua Ling. 2020. ASVspoof 2019: A Large-Scale Public Database of Synthesized, Converted and Replayed Speech. Computer Speech & Language, 101114. doi:https://doi.org/10.1016/j.csl.2020.101114.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2018. Investigating Very Deep Highway Networks for Parametric Speech Synthesis. Speech Communication 96: 1–9. doi:https://doi.org/10.1016/j.specom.2017.11.002.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2018. Autoregressive Neural F0 Model for Statistical Parametric Speech Synthesis. IEEE/ACM Transactions on Audio, Speech, and Language Processing 26 (8). IEEE: 1406–1419. doi:10.1109/TASLP.2018.2828650.

#. **Xin Wang**, Zhen-Hua Ling, and Li-Rong Dai. 2016. Concept-to-Speech Generation with Knowledge Sharing for Acoustic Modelling and Utterance Filtering. Computer Speech & Language 38 (July). Elsevier: 46–67. doi:10.1016/j.csl.2015.12.003.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2016. Investigation of Using Continuous Representation of Various Linguistic Units in Neural Network Based Text-to-Speech Synthesis. IEICE Transactions on Information and Systems E99.D (10): 2471–2480. doi:10.1587/transinf.2016SLP0011.

#. Andreas Nautsch, **Xin Wang**, Nicolas Evans, Tomi Kinnunen, Ville Vestman, Massimiliano Todisco, Hector Delgado, Md Sahidullah, Junichi Yamagishi, and Kong Aik Lee. \emph{ ASVspoof 2019: Spoofing Countermeasures for the Detection of Synthesized, Converted and Replayed Speech} . IEEE Trans. on Biometrics, Behavior, and Identity (T-BIOM), (accepted). 2021.

#. Yusuke Yasuda, **Xin Wang**, and Junichi Yamagishi. \emph{ Investigation of Learning Abilities on Linguistic Features in Sequence-to-Sequence Text-to-Speech Synthesis} . Computer Speech & Language 67: 101183doi:https://doi.org/10.1016/j.csl.2020.101183. 2021.

#. Shuhei Kato, Yusuke Yasuda, **Xin Wang**, Erica Cooper, Shinji Takaki, and Junichi Yamagishi. 2020. Modeling of Rakugo Speech and Its Limitations: Toward Speech Synthesis That Entertains Audiences. IEEE Access 8: 138149–138161.

#. Tomi Kinnunen, Hector Delgado, Nicholas Evans, Kong Aik Lee, Ville Vestman, Andreas Nautsch, Massimiliano Todisco, **Xin Wang**, Md Sahidullah, Junichi Yamagishi, and Douglas A Reynolds. 2020. Tandem Assessment of Spoofing Countermeasures and Automatic Speaker Verification: Fundamentals. IEEE/ACM Transactions on Audio, Speech, and Language Processing. IEEE.



Conference 

#. Yang Ai, Haoyu Li, **Xin Wang**, Junichi Yamagishi, and Zhenhua Ling. \emph{ Denoising-and-Dereverberation Hierarchical Neural Vocoder for Robust Waveform Generation} . In Proc. SLT, (to be published). 2021.

#. Yusuke Yasuda, **Xin Wang**, and Junichi Yamagishi. \emph{ End-to-End Text-to-Speech Using Latent Duration Based on VQ-VAE} . In Proc. ICASSP, (accepted). 2021.

#. Shuhei Kato, Yusuke Yasuda, **Xin Wang**, Erica Cooper, and Junichi Yamagishi. \emph{ How Similar or Different Is Rakugo Speech Synthesizer to Professional Performers?} . In Proc. ICASSP, (accepted). 2021.

#. Brij Mohan Lal Srivastava, Natalia Tomashenko, **Xin Wang**, Emmanuel Vincent, Junichi Yamagishi, Mohamed Maouche, Aurelien Bellet, and Marc Tommasi. 2020. Design Choices for X-Vector Based Speaker Anonymization. In Proc. Interspeech, 1713-1717. ISCA: ISCA. doi:10.21437/Interspeech.2020-2692.

#. Natalia Tomashenko, Brij Mohan Lal Srivastava, **Xin Wang**, Emmanuel Vincent, Andreas Nautsch, Junichi Yamagishi, Nicholas Evans, Jose Patino, Jean-Francois Bonastre, Paul-Gauthier Noe, and Massimiliano Todisco. 2020. Introducing the VoicePrivacy Initiative. In Proc. Interspeech, 1693-1697. ISCA: ISCA. doi:10.21437/Interspeech.2020-1333.

#. **Xin Wang**, and Junichi Yamagishi. 2020. Using Cyclic Noise as the Source Signal for Neural Source-Filter-Based Speech Waveform Model. In Proc. Interspeech, 1992-1996. ISCA: ISCA. doi:10.21437/Interspeech.2020-1018.

#. Yang Ai, **Xin Wang**, Junichi Yamagishi, and Zhen-Hua Ling. 2020. Reverberation Modeling for Source-Filter-Based Neural Vocoder. In Proc. Interspeech, 3560-3564. doi:10.21437/Interspeech.2020-1613.

#. Yi Zhao, **Xin Wang**, Lauri Juvela, and Junichi Yamagishi. 2020. Transferring Neural Speech Waveform Synthesizers to Musical Instrument Sounds Generation. In Proc. ICASSP, 6269–6273. IEEE. doi:10.1109/ICASSP40776.2020.9053047.

#. Yusuke Yasuda, **Xin Wang**, and Junichi Yamagishi. 2020. Effect of Choice of Probability Distribution, Randomness, and Search Methods for Alignment Modeling in Sequence-to-Sequence Text-to-Speech Synthesis Using Hard Alignment. In Proc. ICASSP, 6724–6728.

#. Erica Cooper, Cheng-I Lai, Yusuke Yasuda, Fuming Fang, **Xin Wang**, Nanxin Chen, and Junichi Yamagishi. 2020. Zero-Shot Multi-Speaker Text-to-Speech with State-of-the-Art Neural Speaker Embeddings. In Proc. ICASSP, 6184–6188.

#. Mingyang Zhang, **Xin Wang**, Fuming Fang, Haizhou Li, and Junichi Yamagishi. 2019. Joint Training Framework for Text-to-Speech and Voice Conversion Using Multi-Source Tacotron and WaveNet. In Proc. Interspeech, 1298–1302. doi:10.21437/Interspeech.2019-1357.

#. Yusuke Yasuda, **Xin Wang**, and Junichi Yamagishi. 2019. Initial Investigation of Encoder-Decoder End-to-End TTS Using Marginalization of Monotonic Hard Alignments. In Proc. SSW, 211–216. doi:10.21437/SSW.2019-38.

#. Yusuke Yasuda, **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2019. Investigation of Enhanced Tacotron Text-to-Speech Synthesis Systems with Self-Attention for Pitch Accent Language. In Proc. ICASSP, 6905–6909.

#. **Xin Wang**, and Junichi Yamagishi. 2019. Neural Harmonic-plus-Noise Waveform Model with Trainable Maximum Voice Frequency for Text-to-Speech Synthesis. In Proc. SSW, 1–6. ISCA: ISCA. doi:10.21437/SSW.2019-1.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2019. Neural Source-Filter-Based Waveform Model for Statistical Parametric Speech Synthesis. In Proc. ICASSP, 5916–5920.

#. Massimiliano Todisco, **Xin Wang**, Ville Vestman, Md. Sahidullah, Héctor Delgado, Andreas Nautsch, Junichi Yamagishi, Nicholas Evans, Tomi H Kinnunen, and Kong Aik Lee. 2019. ASVspoof 2019: Future Horizons in Spoofed and Fake Audio Detection. In Proc. Interspeech, 1008–1012. doi:10.21437/Interspeech.2019-2249.

#. Shinji Takaki, Toru Nakashika, **Xin Wang**, and Junichi Yamagishi. 2019. STFT Spectral Loss for Training a Neural Speech Waveform Model. In Proc. ICASSP, 7065–7069.

#. Hieu-Thi Luong, **Xin Wang**, Junichi Yamagishi, and Nobuyuki Nishizawa. 2019. Training Multi-Speaker Neural Text-to-Speech Systems Using Speaker-Imbalanced Speech Corpora. In Proc. Interspeech, 1303–1307. doi:10.21437/Interspeech.2019-1311.

#. Chen-Chou Lo, Szu-Wei Fu, Wen-Chin Huang, **Xin Wang**, Junichi Yamagishi, Yu Tsao, and Hsin-Min Wang. 2019. MOSnet: Deep Learning-Based Objective Assessment for Voice Conversion. In Proc. Interspeech, 1541–1545. doi:10.21437/Interspeech.2019-2003.

#. Shuhei Kato, Yusuke Yasuda, **Xin Wang**, Erica Cooper, Shinji Takaki, and Junichi Yamagishi. 2019. Rakugo Speech Synthesis Using Segment-to-Segment Neural Transduction and Style Tokens - toward Speech Synthesis for Entertaining Audiences. In Proc. SSW, 111–116. doi:10.21437/SSW.2019-20.

#. Fuming Fang, **Xin Wang**, Junichi Yamagishi, Isao Echizen, Massimiliano Todisco, Nicholas Evans, and Jean-Francois Bonastre. 2019. Speaker Anonymization Using X-Vector and Neural Waveform Models. In Proc. SSW, 155–160. doi:10.21437/SSW.2019-28.

#. Fuming Fang, **Xin Wang**, Junichi Yamagishi, and Isao Echizen. 2019. Audiovisual Speaker Conversion: Jointly and Simultaneously Transforming Facial Expression and Acoustic Characteristics. In Proc. ICASSP, 6795–6799.

#. **Xin Wang**, Jaime Lorenzo-Trueba, Shinji Takaki, Lauri Juvela, and Junichi Yamagishi. 2018. A Comparison of Recent Waveform Generation and Acoustic Modeling Methods for Neural-Network-Based Speech Synthesis. In Proc. ICASSP, 4804–4808.

#. Hieu-Thi Luong, **Xin Wang**, Junichi Yamagishi, and Nobuyuki Nishizawa. 2018. Investigating Accuracy of Pitch-Accent Annotations in Neural-Network-Based Speech Synthesis and Denoising Effects. In Proc. Interspeech 2018, 37–41.

#. Jaime Lorenzo-Trueba, Fuming Fang, **Xin Wang**, Isao Echizen, Junichi Yamagishi, and Tomi Kinnunen. 2018. Can We Steal Your Vocal Identity from the Internet?: Initial Investigation of Cloning Obama’s Voice Using GAN, WaveNet and Low-Quality Found Data. In Proc. Odyssey, 240–247. ISCA: ISCA. doi:10.21437/Odyssey.2018-34.

#. Lauri Juvela, Bajibabu Bollepalli, **Xin Wang**, Hirokazu Kameoka, Manu Airaksinen, Junichi Yamagishi, and Paavo Alku. 2018. Speech Waveform Synthesis from MFCC Sequences with Generative Adversarial Networks. In Proc. ICASSP, 5679–5683.

#. Gustav Eje Henter, Jaime Lorenzo-Trueba, **Xin Wang**, Mariko Kondo, and Junichi Yamagishi. 2018. Cyborg Speech: Deep Multilingual Speech Synthesis for Generating Segmental Foreign Accent with Natural Prosody. In Proc. ICASSP, 4799–4803.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2017. An RNN-Based Quantized F0 Model with Multi-Tier Feedback Links for Text-to-Speech Synthesis. In Proc. Interspeech, 1059–1063.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2017. An Autoregressive Recurrent Mixture Density Network for Parametric Speech Synthesis. In Proc. ICASSP, 4895–4899.

#. Gustav Eje Henter, Jaime Lorenzo-Trueba, **Xin Wang**, and Junichi Yamagishi. 2017. Principles for Learning Controllable TTS from Annotated and Latent Variation. In Proc. Interspeech, 3956–3960. doi:10.21437/Interspeech.2017-171.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2016. Enhance the Word Vector with Prosodic Information for the Recurrent Neural Network Based TTS System. In Proc. Interspeech, 2856–2860.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2016. Investigating Very Deep Highway Networks for Parametric Speech Synthesis. In Proc. SSW9, 181–186.

#. **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2016. A Comparative Study of the Performance of HMM, DNN, and RNN Based Speech Synthesis Systems Trained on Very Large Speaker-Dependent Corpora. In Proc. SSW9, 125–128.

#. **Xin Wang**, Minghui Dong, and Zhenhua Ling. 2016. A Full Training Framework of Cross-Stream Dependence Modelling for HMM-Based Singing Voice Synthesis. In Proc. ICASSP, 5165–5169. doi:10.1109/ICASSP.2016.7472662.

#. Cassia Valentini-Botinhao, **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2016. Speech Enhancement for a Noise-Robust Text-to-Speech Synthesis System Using Deep Recurrent Neural Networks. In Proc. Interspeech, 352–356.

#. Cassia Valentini-Botinhao, **Xin Wang**, Shinji Takaki, and Junichi Yamagishi. 2016. Investigating RNN-Based Speech Enhancement Methods for Noise-Robust Text-to-Speech. In Proc. SSW, 146–152.

#. Lauri Juvela, **Xin Wang**, Shinji Takaki, Manu Airaksinen, Junichi Yamagishi, and Paavo Alku. 2016. Using Text and Acoustic Features in Predicting Glottal Excitation Waveforms for Parametric Speech Synthesis with Recurrent Neural Networks. In Proc. Interspeech, 2283–2287.

#. **Xin Wang**, Zhen-Hua Ling, and Li-Rong Dai. 2014. Concept-to-Speech Generation by Integrating Syntagmatic Features into HMM-Based Speech Synthesis. In Proc. Interspeech, 2942–2946.

#. **Xin Wang**, Zhen-Hua Ling, and Li-Rong Dai. 2012. Cross-Stream Dependency Modeling Using Continuous F0 Model for HMM-Based Speech Synthesis. In Proc. ISCSLP, 84–87.

Talk
====
* 2020 Nov., ``Neural statistical parametric speech synthesis``. Tutorial as ISCA 2020 Speaker Odyssey, Tokyo. `PDF <https://www.dropbox.com/sh/gf3zp00qvdp3row/AABFY0RiorILzSuX1YuQXyA7a/web/Odyssesy2020_Tutorial_TTS_XINWANG.pdf?raw=1>`_ and `PPT slides <https://www.dropbox.com/sh/gf3zp00qvdp3row/AABn3DyzRuZeBJwEGPV1ouFSa/web/Odyssesy2020_Tutorial_TTS_XINWANG.pptx?raw=1>`_ are available.

* 2020 July, ``Neural auto-regressive, source-filter and glottal vocoders for speech and music signals``. Tutorial at ISCA 2020 Speech Processing Courses in Crete, with Prof. Yamagishi. Hands-on-materials on `github <https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts/tree/master/tutorials>`_.

* 2019 Sep, ``Neural waveform models for text-to-speech synthesis``, Fraunhofer IIS, invited talk, Erlangen, Germany. Slide is `here 1 <https://www.dropbox.com/sh/gf3zp00qvdp3row/AAByUSX6u4O51bGHpIFlgy-ba/web/201909-FraunhoderIIS-neural-waveform-models.pdf?raw=1>`_

* 2019 Jan, ``Tutorial on recent neural waveform models``, IEICE Technical Committee on Speech (SP), invited tutorial, Kanazawa, Japan. Slide is `here 2 <https://www.slideshare.net/jyamagis/tutorial-on-endtoend-texttospeech-synthesis-part-1-neural-waveform-modeling>`_

* 2018 Nov, ``Autoregressive neural networks for parametric speech synthesis``, Nagoya Institute of Technology, Tokuda lab. Slide is `here 3 <https://www.dropbox.com/sh/gf3zp00qvdp3row/AACZVX1Tf9Qw1MUc2YHQKf4Ia/web/20180111-Nagoya-ARmodels.pdf?raw=1>`_

* 2018 Jun, ``Autoregressive neural networks for parametric speech synthesis``, University of Eastern Finland, School of Computing, Aalto University, Paavo Alku lab (same content as above)


Awards & scholarship
====================
* Best paper award for `SSW 2016 <https://www.soken.ac.jp/news/5935/>`_, ISCA SynSig

* `SOKENDAI Award <https://www.soken.ac.jp/news/5935/>`_, SOKENDAI, Japan

* `Young Researcher's Award in Speech Field <https://www.ieice.org/iss/sp/jpn/special/sp-prize.html>`_, IEICE ISS, Japan

* 11th IEEE Signal Processing Society Japan Student `Best Paper Award <https://ieee-jp.org/section/tokyo/chapter/SP-01/past-student-paper.htm>`_, IEEE Japan

* MEXT Scholarship (Ph.D 2015 - 2018), Japan


.. toctree::
   :hidden:
   :maxdepth: 1

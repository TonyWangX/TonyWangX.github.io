
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Talk &amp; slides &#8212; HomePage-WangXin  documentation</title>
    <link rel="stylesheet" href="_static/alabaster.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/language_data.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Research" href="research.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <div class="section" id="talk-slides">
<span id="label-slide"></span><h1>Talk &amp; slides<a class="headerlink" href="#talk-slides" title="Permalink to this headline">¶</a></h1>
<p>Here are somes slides.</p>
<p>In most cases, I cannot directly share samples through PDF. Some samples can be found through the link in the PDF.</p>
<div class="section" id="talk">
<h2>Talk<a class="headerlink" href="#talk" title="Permalink to this headline">¶</a></h2>
<p><strong>Two Speech Security Issues after Speech Synthesis Boom</strong>. 2021 Dec, a talk given at CCF. The slide is <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AADDhVJGzMbXEquzf2Z1Y8YHa/web/CCF-talk-2021.pptx">uploaded here</a>.</p>
<p><strong>Advancement in Neural Vocoders</strong>. 2021 July Tutorial at ISCA 2021 Speech Processing Courses in Crete, with Prof. Yamagishi. Hands-on-materials on <a class="reference external" href="https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts/tree/master/tutorials">github</a>. Slides is <a class="reference external" href="https://www.slideshare.net/jyamagis/advancements-in-neural-vocoders">here</a>.</p>
<p><strong>Tutorial on Neural statistical parametric speech synthesis (recent sequence-to-sequence TTS models)</strong>. 2020 Oct, For Odyssey 2020. <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABFY0RiorILzSuX1YuQXyA7a/web/Odyssesy2020_Tutorial_TTS_XINWANG.pdf?raw=1">PDF</a> and <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABn3DyzRuZeBJwEGPV1ouFSa/web/Odyssesy2020_Tutorial_TTS_XINWANG.pptx?raw=1">PPT slides</a> are available. Audios are collected from reference papers’ official websites or from open domain data repository.</p>
<p><strong>Neural vocoders for speech and music signals</strong>. 2020 Nov, invited talk at YAMAHA, with Prof. Yamagishi.</p>
<p><strong>Neural auto-regressive, source-filter and glottal vocoders for speech and music signals</strong>. 2020 Jul, Tutorial at ISCA 2020 Speech Processing Courses in Crete, with Prof. Yamagishi. Hands-on-materials on <a class="reference external" href="https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts/tree/master/tutorials">github</a>.</p>
<p><strong>Neural waveform models for text-to-speech synthesis</strong>. 2019 Sep, Fraunhofer IIS, invited talk, Erlangen, Germany. Slide is <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAByUSX6u4O51bGHpIFlgy-ba/web/201909-FraunhoderIIS-neural-waveform-models.pdf?raw=1">here 1</a></p>
<p><strong>Tutorial on recent neural waveform models</strong>. 2019 Jan, IEICE Technical Committee on Speech (SP), invited tutorial, Kanazawa, Japan. Slide is <a class="reference external" href="https://www.slideshare.net/jyamagis/tutorial-on-endtoend-texttospeech-synthesis-part-1-neural-waveform-modeling">here 2</a></p>
<p><strong>Autoregressive neural networks for parametric speech synthesis</strong>, 2018 Jan, Nagoya Institute of Technology, Tokuda lab &amp; 2018 Jun, Aalto University, Paavo Alku lab. Slide is <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AACZVX1Tf9Qw1MUc2YHQKf4Ia/web/20180111-Nagoya-ARmodels.pdf?raw=1">here 3</a></p>
</div>
<div class="section" id="conference-presentation">
<h2>Conference presentation<a class="headerlink" href="#conference-presentation" title="Permalink to this headline">¶</a></h2>
<p>Anti-spoofing: Interspeech 2021 presentation for <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAAbQM0rKGea4t5i5m6rn_F_a/web/2021-interspeech-Fri-M-V-7-1.pdf?raw=1">Comparative study on ASVspoof 2019 LA, PPT</a>. Codes are available at <a class="reference external" href="https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts">git repo project/03-asvspoof-mega</a></p>
<p>NSF model (latest ver.): Interspeech 2020 presentation for cyclic-noise-NSF – <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAAMoAEj77_oy4FmG0rkCTWwa/web/2020-interspech.pptx?raw=1">PPT</a> and <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAD0BZlZh4TexeLs3VQVY0kJa/web/2020-interspech.pdf?raw=1">PDF slides</a> . Natural samples are from <a class="reference external" href="http://www.festvox.org/cmu_arctic/">CMU-arctic</a></p>
<p>NSF model (2nd ver.): <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABEVzUUqnJ4QbkxiQcjOhM5a/web/2019-ssw.pdf?raw=1">SSW 2019</a> for paper Neural Harmonic-plus-Noise Waveform Model with Trainable Maximum Voice Frequency for Text-to-Speech Synthesis</p>
<p>NSF model (1st ver.): <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AACIlTwfcTeJYNlMBlnZLE52a/web/2019-ICASSP.pdf?raw=1">ICASSP 2019</a> for paper Neural Source-Filter-Based Waveform Model for Statistical Parametric Speech Synthesis</p>
<p>Speech synthesis comparison: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAC8XgykCv9hSChQMgtzAmVSa/web/2018-ICASSP.pdf?raw=1">ICASSP 2018</a> for paper A Comparison of Recent Waveform Generation and Acoustic Modeling Methods for Neural-Network-Based Speech Synthesis</p>
<p>Deep AR F0 model: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAA0rZJEq6lQYU98mamyterka/web/2017-interspeech.pdf?raw=1">Interspeech 2017 slide</a> for paper An RNN-Based Quantized F0 Model with Multi-Tier Feedback Links for Text-to-Speech Synthesis.</p>
<p>Shallow AR model: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAA5syHnVZvJrljcOILi5U4ga/web/2017-ICASSP.pdf?raw=1">ICASSP 2017 slide</a> for paper An Autoregressive Recurrent Mixture Density Network for Parametric Speech Synthesis.</p>
<p>Speech synthesis: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AACozQp08QjxkmyFEDQlMDZha/web/2016_JVoice.pdf?raw=1">SSW 2016 slide</a> for paper A Comparative Study of the Performance of HMM, DNN, and RNN Based Speech Synthesis Systems Trained on Very Large Speaker-Dependent Corpora.</p>
<p>Prosody embedding: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AADDYHrpFe6b8AbjWjqpRuqTa/web/2016-interspeech.pdf?raw=1">Interspeech 2016 slide</a> for paper Enhance the Word Vector with Prosodic Information for the Recurrent Neural Network Based TTS System.</p>
<p>HMM-based speech synthesis: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AADzOxHtpW9V6SpRAGEZMLXTa/web/2016-ICASSP.pdf?raw=1">ICASSP 2016 slide</a>. For paper A Full Training Framework of Cross-Stream Dependence Modelling for HMM-Based Singing Voice Synthesis.</p>
</div>
<div class="section" id="misc">
<h2>MISC<a class="headerlink" href="#misc" title="Permalink to this headline">¶</a></h2>
<p>On CURRENNT toolkit. These slides were made a long time ago during weekends, and they may be sloppy :)</p>
<blockquote>
<div><ul class="simple">
<li><p>CURRENNT <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABQBuX7Sepgt-1zK49wUTH2a/web/misc-CURRENNT_BASIC.pdf?raw=1">basics</a></p></li>
<li><p>CURRENNT <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAASRaMvZkSc29CyZ_WMXWRIa/web/misc-CURRENNT_LSTM.pdf?raw=1">LSTM explanation</a></p></li>
<li><p>CURRENNT <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AACH1seKkkLfLjEhOsWFr3gSa/web/misc-CURRENNT_CNN.pdf?raw=1">CNN implementation</a></p></li>
<li><p>CURRENNT <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABz4QF9IN5Fa1NlwCrNghJKa/web/misc-CURRENNT_MDN.pdf?raw=1">mixture density network</a></p></li>
<li><p>CURRENNT <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAB5Q1Hdm9WBW8IZ6nepSH9xa/web/misc-CURRENNT_WaveNet.pdf?raw=1">WaveNet</a></p></li>
</ul>
</div></blockquote>
<p>CURRENNT WaveNet is also explained in <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAAxWSo8bmFTTEi0mmJOPPQ_a/web/2018-SLP-tsukuba.pdf?raw=1">another slide</a> with more figures.</p>
<div class="toctree-wrapper compound">
</div>
</div>
</div>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Page contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Talk &amp; slides</a><ul>
<li><a class="reference internal" href="#talk">Talk</a></li>
<li><a class="reference internal" href="#conference-presentation">Conference presentation</a></li>
<li><a class="reference internal" href="#misc">MISC</a></li>
</ul>
</li>
</ul>
<h3><a href="index.html">Site map</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Welcome</a></li>
<li class="toctree-l1"><a class="reference internal" href="resume.html">Resume</a></li>
<li class="toctree-l1"><a class="reference internal" href="research.html">Research work</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Talk &amp; slides</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" />
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, WangXin.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 3.2.1</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/slide.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>
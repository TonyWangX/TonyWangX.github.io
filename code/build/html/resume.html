<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Resume &#8212; Home-page-WangXin  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Research" href="research.html" />
    <link rel="prev" title="Welcome" href="index.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="resume">
<span id="label-resume"></span><h1>Resume<a class="headerlink" href="#resume" title="Permalink to this heading">¶</a></h1>
<div style="text-align: left;">
  <a href="https://scholar.google.com/citations?user=uMZhUHcAAAAJ&hl=en" target="_blank" style="text-decoration: none;">
    <img src="_static/icon1.png" alt="Scholar" style="width:30px;">
  </a>&nbsp;&nbsp;
  <a href="https://researchmap.jp/wangxin?lang=en" target="_blank" style="text-decoration: none;">
    <img src="_static/icon2.png" alt="Scholar" style="width:30px;">
  </a>&nbsp;&nbsp;
  <a href="https://tonywangx.github.io" target="_blank" style="text-decoration: none;">
    <img src="_static/icon3.png" alt="Scholar" style="width:30px;">
  </a>
</div><p><strong>Xin Wang (王鑫)</strong></p>
<p>Project Associate Professor &amp; JST PRESTO researcher</p>
<p>&#64;National Institute of Informatics, 2-1-2 Hitotsubashi, Chiyoda-ku, Tokyo 101-8430, Japan</p>
<section id="education">
<h2>Education<a class="headerlink" href="#education" title="Permalink to this heading">¶</a></h2>
<p><strong>Ph.D</strong>: 2015 - 2018, SOKENDAI/NII, Tokyo, Japan.</p>
<blockquote>
<div><p>Fundamental frequency modeling for neural-betwork-based statistical parametric speech synthesis</p>
<p>Supervisor: Prof. Junichi Yamagishi</p>
<p>Thesis committee: Prof. Keiichi Tokuda, Prof. Nobuaki Minematsu, Prof. Isao Echizen, Prof. Yusuke Miyao</p>
<ul class="simple">
<li><p>Thesis (submitted 2018-06-29): <a class="reference external" href="https://drive.google.com/file/d/10rnN4ViMIswV5IO-Of0uZrAFubb5ZoKy/view?usp=drive_link">PDF</a></p></li>
<li><p>Slides of <a class="reference external" href="https://drive.google.com/file/d/1IXIbLBKfzAAZb1nzCdJd-KF2aL1H_7D0/view?usp=drive_link">pubic defense</a></p></li>
<li><p>Appendix: <a class="reference external" href="https://drive.google.com/file/d/1MTcyHh7C10VAYmJ6JiIeyET1HIfgfsqX/view?usp=drive_link">highway network</a>, <a class="reference external" href="https://drive.google.com/file/d/1Eb4G6WIIEI7C3vb0i3KT0Ci6N2hCD_St/view?usp=drive_link">SAR</a>, <a class="reference external" href="https://drive.google.com/file/d/1wvmXgML1OYx9fBIJbgwKA4L5hvB11Y34/view?usp=drive_link">DAR</a>, <a class="reference external" href="https://drive.google.com/file/d/1204PsYURNpPIurhdtJbgzEEelgfeXqHA/view?usp=drive_link">VQ-VAE</a></p></li>
</ul>
</div></blockquote>
<p><strong>M.Sc.</strong>: 2012 - 2015, University of Science and Technology of China, Hefei, China.</p>
<blockquote>
<div><p>Bi-directional optimization for concept-to-speech synthesis (in Chinese)</p>
<p>Supervisor: Prof. Zhen-Hua Ling</p>
<p>Related <a class="reference external" href="https://doi.org/10.1016/j.csl.2015.12.003">English paper</a></p>
</div></blockquote>
<p><strong>B.Sc.</strong>: 2008 - 2012, University of Electronic Science and Technology of China, Chengdu, China.</p>
<blockquote>
<div><p>Cross-stream dependency modeling for HMM-based statistical parametric speech synthesis (in Chinese)</p>
<p>Supervisor: Prof. Zhen-Hua Ling (done at USTC)</p>
<p>Related <a class="reference external" href="https://doi.org/10.1109/ICASSP.2016.7472662">English paper</a></p>
</div></blockquote>
</section>
<section id="academic-activity">
<h2>Academic activity<a class="headerlink" href="#academic-activity" title="Permalink to this heading">¶</a></h2>
<p>Organizer</p>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference external" href="https://www.asvspoof.org/">ASVspoof5</a>, ASVspoof challenges 2024, 2021, 2019</p></li>
<li><p><a class="reference external" href="https://www.voiceprivacychallenge.org">Voice Privacy Challenge</a> 2024, 2022, 2020</p></li>
<li><p>ASRU 2025 special session on <a class="reference external" href="https://2025.ieeeasru.org/program/special-sessions">Deepfake detection</a></p></li>
<li><p>Interspeech 2025 special session on <a class="reference external" href="https://deepfake-total.com/sourcetracing">source tracing of synthetic speech</a></p></li>
<li><p>APSIPA ASC 2019 special session on <a class="reference external" href="http://apsipa2019.org/SpecialSessions.html">Deep Generative Models for Media Clones and Its Detection</a></p></li>
<li><p>ISCA Interspeech 2019 special session on <a class="reference external" href="https://www.interspeech2019.org/program/special_sessions_and_challenges">ASVspoof</a></p></li>
<li><p>IEEE ASRU 2019 special session on <a class="reference external" href="http://asru2019.org/wp/?page_id=622">ASVspoof</a></p></li>
</ul>
</div></blockquote>
<p>Guest editor</p>
<blockquote>
<div><ul class="simple">
<li><p>Computer Speech and Language <a class="reference external" href="https://www.journals.elsevier.com/computer-speech-and-language/call-for-papers/advances-in-automatic-speaker">Special issue on Advances in Automatic Speaker Verification Anti-spoofing</a></p></li>
</ul>
</div></blockquote>
<p>Session chair</p>
<blockquote>
<div><ul class="simple">
<li><p>Interspeech 2024, ICASSP 2023, <a class="reference external" href="https://dl.acm.org/doi/proceedings/10.1145/3552466">ACM MM 2022 DDAM Workshop</a>, <a class="reference external" href="https://www.isca-speech.org/archive/asvspoof_2021/index.html">ASVspoof workshop 2021</a>, Interspeech 2021, SSW 2019.</p></li>
</ul>
</div></blockquote>
<p>Reviewer</p>
<blockquote>
<div><ul class="simple">
<li><p>IEEE TASLP, TBIOM, TIFS, SPL, ICASSP, ASRU, SLT</p></li>
<li><p>ISCA Interspeech, Speech synthesis workshop, Odyssey workshop, Computer speech &amp; language, Speech Communication</p></li>
<li><p>IEICE Trans on Information and Systems</p></li>
<li><p>EUSIPCO, BIOSIG, COLING-LREC 2024 (meta-reviewer)</p></li>
</ul>
</div></blockquote>
</section>
<section id="grants">
<h2>Grants<a class="headerlink" href="#grants" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>2023 - 2027, <strong>JST, PRESTO (JPMJPR23P9)</strong>: Unified framework for speech privacy protection and anti-spoofing. PI: Xin Wang.</p></li>
<li><p>2021 - 2023, <strong>JSPS, Wakate (21K17775)</strong>: Speech privacy protection by high-quality, invertible, and extendable speech anonymization and de-anonymization. PI: Xin Wang.</p></li>
<li><p>2020 - 2021, <strong>KAWAI</strong>: Deep-learning-based neural source-filtering models for fast and high-quality music signal generation. PI: Xin Wang.</p></li>
<li><p>2021 - 2022, <strong>JST AIP Challenge</strong> Enhanced End-to-End Multi-Instrument MIDI/sheet-to-Music Synthesis with Timber and Style Transfer. PI: Xin Wang.</p></li>
<li><p>2019 - 2021, <strong>JSPS, grant-for-startup (19K24371)</strong>: One model for all sounds: fast and high-quality neural source-filter model for speech and non-speech waveform modeling. PI: Xin Wang.</p></li>
<li><p>2021 - 2022, <strong>Google Research Grant</strong>: Optimizing a Speech Anti-spoofing Database. PI:: Junichi Yamagishi. Collaborator: Xin Wang, Eric Cooper.</p></li>
<li><p>2019 - 2020, <strong>Google AI Focused Research Awards Program in Japan</strong>: Robust and all-purpose neural source-filter models. PI: Junichi Yamagishi. Collaborator: Xin Wang, Eric Cooper.</p></li>
</ul>
</section>
<section id="publication">
<h2>Publication<a class="headerlink" href="#publication" title="Permalink to this heading">¶</a></h2>
<section id="journal-papers">
<h3>Journal papers<a class="headerlink" href="#journal-papers" title="Permalink to this heading">¶</a></h3>
<blockquote>
<div><p><strong>Speech synthesis</strong></p>
</div></blockquote>
<ol class="arabic">
<li><p><strong>Xin Wang</strong>, Shinji Takaki, Junichi Yamagishi, Simon King and Keiichi Tokuda. A Vector Quantized Variational Autoencoder (VQ-VAE) Autoregressive Neural F0 Model for Statistical Parametric Speech Synthesis. IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol: 28, pages 157-170. doi: 10.1109/TASLP.2019.2950099. 2020.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Neural Source-Filter Waveform Models for Statistical Parametric Speech Synthesis. IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol: 28, pages 402-415. doi: 10.1109/TASLP.2019.2956145. 2020.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Investigating very deep highway networks for parametric speech synthesis. Speech Communication, vol: 96, pages 1-9. doi: 10.1016/j.specom.2017.11.002. 2018.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Autoregressive Neural F0 Model for Statistical Parametric Speech Synthesis. IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol: 26, pages 1406-1419. doi: 10.1109/TASLP.2018.2828650. 2018.</p></li>
<li><p><strong>Xin Wang</strong>, Zhen-Hua Ling and Li-Rong Dai. Concept-to-Speech generation with knowledge sharing for acoustic modelling and utterance filtering. Computer Speech &amp; Language, vol: 38, pages 46-67. doi: 10.1016/j.csl.2015.12.003. 2016.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Investigation of Using Continuous Representation of Various Linguistic Units in Neural Network Based Text-to-Speech Synthesis. IEICE Transactions on Information and Systems, vol: E99.D, pages 2471-2480. doi: 10.1587/transinf.2016SLP0011. 2016.</p></li>
<li><p>Cheng Gong, <strong>Xin Wang</strong>, Erica Cooper, Dan Wells, Longbiao Wang, Jianwu Dang, Korin Richmond and Junichi Yamagishi. ZMM-TTS: Zero-Shot Multilingual and Multispeaker Speech Synthesis Conditioned on Self-Supervised Discrete Speech Representations. IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol: 32, pages 4036-4051. doi: 10.1109/TASLP.2024.3451951. 2024.</p></li>
<li><p>Yusuke Yasuda, <strong>Xin Wang</strong> and Junichi Yamagishi. Investigation of learning abilities on linguistic features in sequence-to-sequence text-to-speech synthesis. Computer Speech &amp; Language, vol: 67, pages 101183. doi: <a class="reference external" href="https://doi.org/10.1016/j.csl.2020.101183">https://doi.org/10.1016/j.csl.2020.101183</a>. 2021.</p></li>
<li><p>Shuhei Kato, Yusuke Yasuda, <strong>Xin Wang</strong>, Erica Cooper, Shinji Takaki and Junichi Yamagishi. Modeling of Rakugo Speech and Its Limitations: Toward Speech Synthesis That Entertains Audiences. IEEE Access, vol: 8, pages 138149-138161. doi: 10.1109/ACCESS.2020.3011975. 2020.</p>
<p><strong>Antispoofing &amp; deepfake detection</strong></p>
</li>
<li><p><strong>Xin Wang</strong>, Héctor Delgado, Hemlata Tak, Jee-weon Jung, Hye-jin Shim, Massimiliano Todisco, Ivan Kukanov, Xuechen Liu, Md Sahidullah, Tomi Kinnunen, Nicholas Evans, Kong Aik Lee, Junichi Yamagishi, Myeonghun Jeong, Ge Zhu, Yongyi Zang, Soumi Maiti, Florian Lux, Nicolas Müller, Wangyou Zhang, Chengzhe Sun, Shuwei Hou, Siwei Lyu, Sébastien Le Maguer, Cheng Gong, Hanjie Guo, Liping Chen, and Vishwanath Singh. 2025. ASVspoof 5: Design, collection and validation of public resources for spoofing, deepfake, and adversarial attack detection using crowdsourced speech. Computer Speech &amp; Language (2025). doi.org/doi.org/10.1016/j.csl.2025.101825</p></li>
<li><p><strong>Xin Wang</strong>, Junichi Yamagishi, Massimiliano Todisco, H{'{e}}ctor Delgado, Andreas Nautsch, Nicholas Evans, Md Sahidullah, Ville Vestman, Tomi Kinnunen, Kong Aik Lee, Lauri Juvela, Paavo Alku, Yu-Huai Peng, Hsin-Te Hwang, Yu Tsao, Hsin-Min Wang, S{'{e}}bastien Le Maguer, Markus Becker, Fergus Henderson, Rob Clark, Yu Zhang, Quan Wang, Ye Jia, Kai Onuma, Koji Mushika, Takashi Kaneda, Yuan Jiang, Li-Juan Liu, Yi-Chiao Wu, Wen-Chin Huang, Tomoki Toda, Kou Tanaka, Hirokazu Kameoka, Ingmar Steiner, Driss Matrouf, Jean-Fran{c{c}}ois Bonastre, Avashna Govender, Srikanth Ronanki, Jing-Xuan Zhang and Zhen-Hua Ling. ASVspoof 2019: A large-scale public database of synthesized, converted and replayed speech. Computer Speech &amp; Language, vol: 64, pages 101114. doi: 10.1016/j.csl.2020.101114. 2020.</p></li>
<li><p>Jee-weon Jung, Yihan Wu, <strong>Xin Wang</strong>, Ji-Hoon Kim, Soumi Maiti, Yuta Matsunaga, Hye-jin Shim, Jinchuan Tian, Nicholas Evans, Joon Son Chung, Wangyou Zhang, Seyun Um, Shinnosuke Takamichi, and Shinji Watanabe. 2025. SpoofCeleb: Speech Deepfake Detection and SASV In The Wild. IEEE Open Journal of Signal Processing (2025).</p></li>
<li><p>Chang Zeng, Xiaoxiao Miao, <strong>Xin Wang</strong>, Erica Cooper and Junichi Yamagishi. Joint Speaker Encoder and Neural Back-End Model for Fully End-to-End Automatic Speaker Verification with Multiple Enrollment Utterances. Computer Speech &amp; Language, vol: 86, doi: 10.1016/j.csl.2024.101619. 2024.</p></li>
<li><p>Xuechen Liu, <strong>Xin Wang</strong>, Md Sahidullah, Jose Patino, H{'{e}}ctor Delgado, Tomi Kinnunen, Massimiliano Todisco, Junichi Yamagishi, Nicholas Evans, Andreas Nautsch and Kong Aik Lee. ASVspoof 2021: Towards Spoofed and Deepfake Speech Detection in the Wild. IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol: 31, pages 2507-2522. doi: 10.1109/TASLP.2023.3285283. 2023.</p></li>
<li><p>Lin Zhang, <strong>Xin Wang</strong>, Erica Cooper, Nicholas Evans and Junichi Yamagishi. The PartialSpoof Database and Countermeasures for the Detection of Short Fake Speech Segments Embedded in an Utterance. IEEE/ACM Transactions on Audio, Speech, and Language Processing, pages 1-13. doi: 10.1109/TASLP.2022.3233236. 2022.</p></li>
<li><p>Andreas Nautsch, <strong>Xin Wang</strong>, Nicholas Evans, Tomi H. Kinnunen, Ville Vestman, Massimiliano Todisco, Hector Delgado, Md Sahidullah, Junichi Yamagishi and Kong Aik Lee. ASVspoof 2019: Spoofing Countermeasures for the Detection of Synthesized, Converted and Replayed Speech. IEEE Transactions on Biometrics, Behavior, and Identity Science, vol: 3, pages 252-265. doi: 10.1109/TBIOM.2021.3059479. 2021.</p></li>
<li><p>Tomi Kinnunen, Hector Delgado, Nicholas Evans, Kong Aik Lee, Ville Vestman, Andreas Nautsch, Massimiliano Todisco, <strong>Xin Wang</strong>, Md Sahidullah, Junichi Yamagishi and Douglas A Reynolds. Tandem Assessment of Spoofing Countermeasures and Automatic Speaker Verification: Fundamentals. IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol: 28, pages 2195-2210. doi: 10.1109/TASLP.2020.3009494. 2020.</p>
<p><strong>Speech anonymization</strong></p>
</li>
<li><p>Xiaoxiao Miao, Yuxiang Zhang, <strong>Xin Wang</strong>, Natalia Tomashenko, Donny Cheng Lock Soh, and Ian Mcloughlin. 2025. Adapting general disentanglement-based speaker anonymization for enhanced emotion preservation. Computer Speech &amp; Language 94, (November 2025), 101810. doi.org/10.1016/j.csl.2025.101810</p></li>
<li><p>Xiaoxiao Miao, Ruijie Tao, Chang Zeng, and <strong>Xin Wang</strong>. A Benchmark for Multi-speaker Anonymization. IEEE Trans.Inform.Forensic Secur. doi: 10.1109/TIFS.2025.3556345. 2025</p></li>
<li><p>Michele Panariello, Natalia Tomashenko, <strong>Xin Wang</strong>, Xiaoxiao Miao, Pierre Champion, Hubert Nourtel, Massimiliano Todisco, Nicholas Evans, Emmanuel Vincent and Junichi Yamagishi. The VoicePrivacy 2022 Challenge: Progress and Perspectives in Voice Anonymisation. IEEE/ACM Transactions on Audio, Speech, and Language Processing, pages 1-14. doi: 10.1109/TASLP.2024.3430530. 2024.</p></li>
<li><p>Xiaoxiao Miao, <strong>Xin Wang</strong>, Erica Cooper, Junichi Yamagishi and Natalia Tomashenko. Speaker Anonymization Using Orthogonal Householder Neural Network. IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol: 31, pages 3681-3695. doi: 10.1109/TASLP.2023.3313429. 2023.</p></li>
<li><p>Natalia Tomashenko, <strong>Xin Wang</strong>, Emmanuel Vincent, Jose Patino, Brij Mohan Lal Srivastava, Paul-Gauthier No{'{e}}, Andreas Nautsch, Nicholas Evans, Junichi Yamagishi, Benjamin O’Brien, Ana{&quot;{i}}s Chanclu, Jean-Fran{c{c}}ois Bonastre, Massimiliano Todisco and Mohamed Maouche. The VoicePrivacy 2020 Challenge: Results and findings. Computer Speech &amp; Language, pages 101362. doi: <a class="reference external" href="https://doi.org/10.1016/j.csl.2022.101362">https://doi.org/10.1016/j.csl.2022.101362</a>. 2022.</p></li>
<li><p>Brij Mohan Lal Srivastava, Mohamed Maouche, Md Sahidullah, Emmanuel Vincent, Aurelien Bellet, Marc Tommasi, Natalia Tomashenko, <strong>Xin Wang</strong> and Junichi Yamagishi. Privacy and Utility of X-Vector Based Speaker Anonymization. IEEE/ACM Transactions on Audio, Speech, and Language Processing, vol: 30, pages 2383-2395. doi: 10.1109/TASLP.2022.3190741. 2022.</p></li>
</ol>
</section>
<section id="book-chapters">
<h3>Book chapters<a class="headerlink" href="#book-chapters" title="Permalink to this heading">¶</a></h3>
<blockquote>
<div><p><strong>antispoofing</strong></p>
</div></blockquote>
<ol class="arabic simple">
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. A Practical Guide to Logical Access Voice Presentation Attack Detection. Frontiers in Fake Media Generation and Detection, pages 169-214. doi: 10.1007/978-981-19-1524-6_8. 2022.</p></li>
<li><p>Md Sahidullah, H{'{e}}ctor Delgado, Massimiliano Todisco, Andreas Nautsch, <strong>Xin Wang</strong>, Tomi Kinnunen, Nicholas Evans, Junichi Yamagishi and Kong-Aik Lee. Introduction to Voice Presentation Attack Detection and Recent Advances. Handbook of Biometric Anti-Spoofing, pages 339-385. doi: 10.1007/978-981-19-5288-3_13. 2023.</p></li>
</ol>
</section>
<section id="conference-papers">
<h3>Conference papers<a class="headerlink" href="#conference-papers" title="Permalink to this heading">¶</a></h3>
<blockquote>
<div><p><strong>Speech synthesis</strong></p>
</div></blockquote>
<ol class="arabic">
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. Using Cyclic Noise as the Source Signal for Neural Source-Filter-Based Speech Waveform Model. Proc. Interspeech, pages 1992-1996. doi: 10.21437/Interspeech.2020-1018. 2020.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Neural Source-filter-based Waveform Model for Statistical Parametric Speech Synthesis. Proc. ICASSP, pages 5916-5920. doi: 10.1109/ICASSP.2019.8682298. 2019.</p></li>
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. Neural Harmonic-plus-Noise Waveform Model with Trainable Maximum Voice Frequency for Text-to-Speech Synthesis. Proc. SSW, pages 1-6. doi: 10.21437/SSW.2019-1. 2019.</p></li>
<li><p><strong>Xin Wang</strong>, Jaime Lorenzo-Trueba, Shinji Takaki, Lauri Juvela and Junichi Yamagishi. A comparison of recent waveform generation and acoustic modeling methods for neural-network-based speech synthesis. Proc. ICASSP, pages 4804-4808. 2018.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. An autoregressive recurrent mixture density network for parametric speech synthesis. Proc. ICASSP, pages 4895-4899. 2017.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. An RNN-based quantized F0 model with multi-tier feedback links for text-to-speech synthesis. Proc. Interspeech, pages 1059-1063. 2017.</p></li>
<li><p><strong>Xin Wang</strong>, Minghui Dong and Zhenhua Ling. A full training framework of cross-stream dependence modelling for HMM-based singing voice synthesis. Proc. ICASSP, pages 5165-5169. doi: 10.1109/ICASSP.2016.7472662. 2016.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. A comparative study of the performance of HMM, DNN, and RNN based speech synthesis systems trained on very large speaker-dependent corpora. Proc. SSW, pages 125-128. 2016.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Investigating very deep highway networks for parametric speech synthesis. Proc. SSW, pages 181-186. 2016.</p></li>
<li><p><strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Enhance the word vector with prosodic information for the recurrent neural network based TTS system. Proc. Interspeech, pages 2856-2860. 2016.</p></li>
<li><p><strong>Xin Wang</strong>, Zhen-Hua Ling and Li-Rong Dai. Concept-to-speech generation by integrating syntagmatic features into HMM-based speech synthesis. Proc. Interspeech, pages 2942-2946. 2014.</p></li>
<li><p><strong>Xin Wang</strong>, Zhen-Hua Ling and Li-Rong Dai. Cross-stream dependency modeling using continuous F0 model for HMM-based speech synthesis. Proc. ISCSLP, pages 84-87. 2012.</p></li>
<li><p>Cheng Gong,  Erica Cooper,  Xin Wang,  Chunyu Qiang,  Mengzhe Geng,  Dan Wells,  Longbiao Wang,  Jianwu Dang,  Marc Tessier,  Aidan Pine,  Korin Richmond and  Junichi Yamagishi. An Initial Investigation of Language Adaptation for TTS Systems under Low-resource Scenarios. Proc. Interspeech, pages 4963-4967. 2024.</p></li>
<li><p>Xuan Shi, Erica Cooper, <strong>Xin Wang</strong>, Junichi Yamagishi and Shrikanth Narayanan. Can Knowledge of End-to-End Text-to-Speech Models Improve Neural Midi-to-Audio Synthesis Systems?. Proc. ICASSP, pages . doi: 10.1109/ICASSP49357.2023.10095848. 2023.</p></li>
<li><p>Shuhei Kato, Yusuke Yasuda, <strong>Xin Wang</strong>, Erica Cooper and Junichi Yamagishi. How Similar or Different is Rakugo Speech Synthesizer to Professional Performers?. Proc. ICASSP, pages 6488-6492. doi: 10.1109/ICASSP39728.2021.9414175. 2021.</p></li>
<li><p>Yang Ai, Haoyu Li, <strong>Xin Wang</strong>, Junichi Yamagishi and Zhenhua Ling. Denoising-and-Dereverberation Hierarchical Neural Vocoder for Robust Waveform Generation. Proc. SLT, pages 477-484. doi: 10.1109/SLT48900.2021.9383611. 2021.</p></li>
<li><p>Yusuke Yasuda, <strong>Xin Wang</strong> and Junichi Yamagishd. End-to-End Text-to-Speech Using Latent Duration Based on VQ-VAE. Proc. ICASSP, pages 5694-5698. 2021.</p></li>
<li><p>Erica Cooper, <strong>Xin Wang</strong> and Junichi Yamagishi. Text-to-Speech Synthesis Techniques for MIDI-to-Audio Synthesis. Proc. SSW, pages 130-135. doi: 10.21437/SSW.2021-23. 2021.</p></li>
<li><p>Yi Zhao, <strong>Xin Wang</strong>, Lauri Juvela and Junichi Yamagishi. Transferring neural speech waveform synthesizers to musical instrument sounds generation. Proc. ICASSP, pages 6269-6273. doi: 10.1109/ICASSP40776.2020.9053047. 2020.</p></li>
<li><p>Erica Cooper, Cheng-I Lai, Yusuke Yasuda, Fuming Fang, <strong>Xin Wang</strong>, Nanxin Chen and Junichi Yamagishi. Zero-shot multi-speaker text-to-speech with state-of-the-art neural speaker embeddings. Proc. ICASSP, pages 6184-6188. 2020.</p></li>
<li><p>Yusuke Yasuda, <strong>Xin Wang</strong> and Junichi Yamagishi. Effect of choice of probability distribution, randomness, and search methods for alignment modeling in sequence-to-sequence text-to-speech synthesis using hard alignment. Proc. ICASSP, pages 6724-6728. 2020.</p></li>
<li><p>Yang Ai, <strong>Xin Wang</strong>, Junichi Yamagishi and Zhen-Hua Ling. Reverberation Modeling for Source-Filter-Based Neural Vocoder. Proc. Interspeech, pages 3560-3564. 2020.</p></li>
<li><p>Yusuke Yasuda, <strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Investigation of enhanced Tacotron text-to-speech synthesis systems with self-attention for pitch accent language. Proc. ICASSP, pages 6905-6909. 2019.</p></li>
<li><p>Fuming Fang, <strong>Xin Wang</strong>, Junichi Yamagishi and Isao Echizen. Audiovisual speaker conversion: jointly and simultaneously transforming facial expression and acoustic characteristics. Proc. ICASSP, pages 6795-6799. 2019.</p></li>
<li><p>Shinji Takaki, Toru Nakashika, <strong>Xin Wang</strong> and Junichi Yamagishi. STFT spectral loss for training a neural speech waveform model. Proc. ICASSP, pages 7065-7069. 2019.</p></li>
<li><p>Hieu-Thi Luong, <strong>Xin Wang</strong>, Junichi Yamagishi and Nobuyuki Nishizawa. Training multi-speaker neural text-to-speech systems using speaker-imbalanced speech corpora. Proc. Interspeech, pages 1303-1307. doi: 10.21437/Interspeech.2019-1311. 2019.</p></li>
<li><p>Mingyang Zhang, <strong>Xin Wang</strong>, Fuming Fang, Haizhou Li and Junichi Yamagishi. Joint training framework for text-to-speech and voice conversion using multi-source tacotron and WaveNet. Proc. Interspeech, pages 1298-1302. doi: 10.21437/Interspeech.2019-1357. 2019.</p></li>
<li><p>Yusuke Yasuda, <strong>Xin Wang</strong> and Junichi Yamagishi. Initial investigation of encoder-decoder end-to-end TTS using marginalization of monotonic hard alignments. Proc. SSW, pages 211-216. doi: 10.21437/SSW.2019-38. 2019.</p></li>
<li><p>Shuhei Kato, Yusuke Yasuda, <strong>Xin Wang</strong>, Erica Cooper, Shinji Takaki and Junichi Yamagishi. Rakugo speech synthesis using segment-to-segment neural transduction and style tokens - toward speech synthesis for entertaining audiences. Proc. SSW, pages 111-116. doi: 10.21437/SSW.2019-20. 2019.</p></li>
<li><p>Gustav Eje Henter, Jaime Lorenzo-Trueba, <strong>Xin Wang</strong>, Mariko Kondo and Junichi Yamagishi. Cyborg speech: Deep multilingual speech synthesis for generating segmental foreign accent with natural prosody. Proc. ICASSP, pages 4799-4803. 2018.</p></li>
<li><p>Lauri Juvela, Bajibabu Bollepalli, <strong>Xin Wang</strong>, Hirokazu Kameoka, Manu Airaksinen, Junichi Yamagishi and Paavo Alku. Speech waveform synthesis from MFCC sequences with generative adversarial networks. Proc. ICASSP, pages 5679-5683. 2018.</p></li>
<li><p>Hieu-Thi Luong, <strong>Xin Wang</strong>, Junichi Yamagishi and Nobuyuki Nishizawa. Investigating accuracy of pitch-accent annotations in neural-network-based speech synthesis and denoising effects. Proc. Interspeech, pages 37-41. 2018.</p></li>
<li><p>Jaime Lorenzo-Trueba, Fuming Fang, <strong>Xin Wang</strong>, Isao Echizen, Junichi Yamagishi and Tomi Kinnunen. Can we steal your vocal identity from the Internet?: Initial investigation of cloning Obama’s voice using GAN, WaveNet and low-quality found data. Proc. Odyssey, pages 240-247. doi: 10.21437/Odyssey.2018-34. 2018.</p></li>
<li><p>Gustav Eje Henter, Jaime Lorenzo-Trueba, <strong>Xin Wang</strong> and Junichi Yamagishi. Principles for learning controllable TTS from annotated and latent variation. Proc. Interspeech, pages 3956-3960. doi: 10.21437/Interspeech.2017-171. 2017.</p></li>
<li><p>Lauri Juvela, <strong>Xin Wang</strong>, Shinji Takaki, Manu Airaksinen, Junichi Yamagishi and Paavo Alku. Using text and acoustic features in predicting glottal excitation waveforms for parametric speech synthesis with recurrent neural networks. Proc. Interspeech, pages 2283-2287. 2016.</p>
<p><strong>Speech antispoofing &amp; deepfake detection</strong></p>
</li>
<li><p><strong>Xin Wang</strong>, H{'e}ctor Delgado, Hemlata Tak, Jee-weon Jung, Hye-jin Shim, Massimiliano Todisco, Ivan Kukanov, Xuechen Liu, Md Sahidullah, Tomi Kinnunen, Nicholas Evans, Kong Aik Lee and Junichi Yamagishi. ASVspoof 5: Crowdsourced Speech Data, Deepfakes, and Adversarial Attacks at Scale. ASVspoof Workshop 2024, pages 1-8. 2024.</p></li>
<li><p><strong>Xin Wang</strong>, Tomi Kinnunen, Lee Kong Aik, Paul-Gauthier Noe and Junichi Yamagishi. Revisiting and Improving Scoring Fusion for Spoofing-aware Speaker Verification Using Compositional Data Analysis. Proc. Interspeech, pages 1110-1114. 2024.</p></li>
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. Can Large-Scale Vocoded Spoofed Data Improve Speech Spoofing Countermeasure with a Self-Supervised Front End?. Proc. ICASSP, pages 10311-10315. 2024.</p></li>
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. Investigating Active-learning-based Training Data Selection for Speech Spoofing Countermeasure. Proc. SLT, pages 585-592. 2023.</p></li>
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. Spoofed training data for speech spoofing countermeasure can be efficiently created using neural vocoders. Proc. ICASSP, pages . 2023.</p></li>
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. Estimating the Confidence of Speech Spoofing Countermeasure. Proc. ICASSP, pages 6372-6376. doi: 10.1109/ICASSP43922.2022.9746204. 2022.</p></li>
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. Investigating Self-Supervised Front Ends for Speech Spoofing Countermeasures. Proc. Odyssey, pages 100-106. doi: 10.21437/Odyssey.2022-14. 2022.</p></li>
<li><p><strong>Xin Wang</strong> and Junichi Yamagishi. A comparative study on recent neural spoofing countermeasures for synthetic speech detection. Proc. Interspeech, pages 4259-4263. doi: 10.21437/Interspeech.2021-702. 2021.</p></li>
<li><p>Wanying Ge, <strong>Xin Wang</strong>, and Junichi Yamagishi. 2025. Proactive detection of speaker identity manipulation with neural watermarking. In The 1st workshop on GenAI watermarking, 2025.</p></li>
<li><p>Lauri Juvela and <strong>Xin Wang</strong>. Audio codec augmentation for robust collaborative watermarking of speech synthesis. In Proc. ICASSP, 2025. <a class="reference external" href="https://doi.org/10.1109/ICASSP49660.2025.10888976">https://doi.org/10.1109/ICASSP49660.2025.10888976</a></p></li>
<li><p>Massimiliano Todisco, H{'e}ctor Delgado, Lee Kong Aik, Nicholas Evans, Michele Panariello and <strong>Xin Wang</strong>. Malacopula: Adversarial Automatic Speaker Verification Attacks Using a Neural-Based Generalised Hammerstein Model. ASVspoof Workshop 2024, pages 94-100. 2024.</p></li>
<li><p>Tomi Kinnunen, Rosa Gonzalez Hautamaki, <strong>Xin Wang</strong> and Junichi Yamagishi. Speaker Detection by the Individual Listener and the Crowd: Parametric Models Applicable to Bonafide and Deepfake Speech. Proc. Interspeech, pages 3654-3658. doi: 10.21437/Interspeech.2024-1704. 2024.</p></li>
<li><p>Jee-weon Jung, <strong>Xin Wang</strong>, Nicholas Evans, Shinji Watanabe, Hye-jin Shim, Hemlata Tak, Sidhhant Arora, Junichi Yamagishi and Joon Son Chung. To What Extent Can ASV Systems Naturally Defend against Spoofing Attacks?. Proc. Interspeech, pages 3240-3244. 2024.</p></li>
<li><p>Lin Zhang, <strong>Xin Wang</strong>, Erica Cooper, Mireia Diez,  L, Federico ini, Nicholas Evans and Junichi Yamagishi. Spoof Diarization: “What Spoofed When” in Partially Spoofed Audio. Proc. Interspeech, pages 502-506. 2024.</p></li>
<li><p>Wanying Ge, <strong>Xin Wang</strong>, Junichi Yamagishi, Massimiliano Todisco and Nicholas Evans. Spoofing Attack Augmentation: Can Differently-Trained Attack Models Improve Generalisation?. Proc. ICASSP, pages 12531-12535. 2024.</p></li>
<li><p>Lauri Juvela and <strong>Xin Wang</strong>. Collaborative Watermarking for Adversarial Speech Synthesis. Proc. ICASSP, pages 11231-11235. 2024.</p></li>
<li><p>Sung Hwan Mun, Hye-jin Shim, Hemlata Tak, <strong>Xin Wang</strong>, Xuechen Liu, Md Sahidullah, Myeonghun Jeong, Min Hyun Han, Massimiliano Todisco, Kong Aik Lee, Junichi Yamagishi, Nicholas Evans, Tomi Kinnunen, Nam Soo Kim and Jee-weon Jung. Towards Single Integrated Spoofing-aware Speaker Verification Embeddings. Proc. Interspeech, pages 3989-3993. doi: 10.21437/Interspeech.2023-1402. 2023.</p></li>
<li><p>Chang Zeng, <strong>Xin Wang</strong>, Xiaoxiao Miao, Erica Cooper and Junichi Yamagishi. Improving Generalization Ability of Countermeasures for New Mismatch Scenario by Combining Multiple Advanced Regularization Terms. Proc. Interspeech, pages 1998-2002. doi: 10.21437/Interspeech.2023-125. 2023.</p></li>
<li><p>Lin Zhang, <strong>Xin Wang</strong>, Erica Cooper, Nicholas Evans and Junichi Yamagishi. Range-Based Equal Error Rate for Spoof Localization. Proc. Interspeech, pages 3212-3216. doi: 10.21437/Interspeech.2023-1214. 2023.</p></li>
<li><p>Hemlata Tak, Massimiliano Todisco, <strong>Xin Wang</strong>, Jee-weon Jung, Junichi Yamagishi and Nicholas Evans. Automatic speaker verification spoofing and deepfake detection using wav2vec 2.0 and data augmentation. Proc. Odyssey, pages 112-119. 2022.</p></li>
<li><p>Lin Zhang, <strong>Xin Wang</strong>, Erica Cooper, Junichi Yamagishi, Jose Patino and Nicholas Evans. An Initial Investigation for Detecting Partially Spoofed Audio. Proc. Interspeech, pages 4264-4268. doi: 10.21437/Interspeech.2021-738. 2021.</p></li>
<li><p>Lin Zhang, <strong>Xin Wang</strong>, Erica Cooper and Junichi Yamagishi. Multi-task Learning in Utterance-level and Segmental-level Spoof Detection. Proc. ASVspoof Challenge workshop, pages 9-15. doi: 10.21437/ASVSPOOF.2021-2. 2021.</p></li>
<li><p>Tomi Kinnunen, Andreas Nautsch, Md. Sahidullah, Nicholas Evans, <strong>Xin Wang</strong>, Massimiliano Todisco, H{'{e}}ctor Delgado, Junichi Yamagishi and Kong Aik Lee. Visualizing Classifier Adjacency Relations: A Case Study in Speaker Verification and Voice Anti-Spoofing. Proc. Interspeech, pages 4299-4303. doi: 10.21437/Interspeech.2021-1522. 2021.</p></li>
<li><p>Junichi Yamagishi, <strong>Xin Wang</strong>, Massimiliano Todisco, Md Sahidullah, Jose Patino, Andreas Nautsch, Xuechen Liu, Kong Aik Lee, Tomi Kinnunen, Nicholas Evans and H{'{e}}ctor Delgado. ASVspoof 2021: accelerating progress in spoofed and deepfake speech detection. Proc. ASVspoof Challenge workshop, pages 47-54. doi: 10.21437/ASVSPOOF.2021-8. 2021.</p></li>
<li><p>Massimiliano Todisco, <strong>Xin Wang</strong>, Ville Vestman, Md. Sahidullah, H{'{e}}ctor Delgado, Andreas Nautsch, Junichi Yamagishi, Nicholas Evans, Tomi H Kinnunen and Kong Aik Lee. ASVspoof 2019: future horizons in spoofed and fake audio detection. Proc. Interspeech, pages 1008-1012. doi: 10.21437/Interspeech.2019-2249. 2019.</p>
<p><strong>Speech anonymization</strong></p>
</li>
<li><p>Xiaoxiao Miao, <strong>Xin Wang</strong>, Erica Cooper, Junichi Yamagishi, Nicholas Evans, Massimiliano Todisco, Jean-Fran{c c}ois Bonastre and Mickael Rouvier. SynVox2: Towards a Privacy-Friendly VoxCeleb2 Dataset. Proc. ICASSP, pages 11421-11425. 2024.</p></li>
<li><p>Paul-Gauthier Noe, Xiaoxiao Miao, <strong>Xin Wang</strong>, Junichi Yamagishi, Jean-Francois Bonastre and Driss Matrouf. Hiding Speaker’s Sex in Speech Using Zero-Evidence Speaker Representation in an Analysis/Synthesis Pipeline. Proc. ICASSP, pages . 2023.</p></li>
<li><p>Xiaoxiao Miao, <strong>Xin Wang</strong>, Erica Cooper, Junichi Yamagishi and Natalia Tomashenko. Language-Independent Speaker Anonymization Approach Using Self-Supervised Pre-Trained Models. , pages 279-286. doi: 10.21437/Odyssey.2022-39. 2022.</p></li>
<li><p>Xiaoxiao Miao, <strong>Xin Wang</strong>, Erica Cooper, Junichi Yamagishi and Natalia Tomashenko. Analyzing Language-Independent Speaker Anonymization Framework under Unseen Conditions. Proc. Interspeech, pages 4426-4430. doi: 10.21437/Interspeech.2022-11065. 2022.</p></li>
<li><p>Jean-Fran{c{c}}ois Bonastre, H{'{e}}ctor Delgado, Nicholas Evans, Tomi Kinnunen, Kong Aik Lee, Xuechen Liu, Andreas Nautsch, Paul-Gauthier Noe, Jose Patino, Md Sahidullah, Brij Mohan Lal Srivastava, Massimiliano Todisco, Natalia Tomashenko, Emmanuel Vincent, <strong>Xin Wang</strong> and Junichi Yamagishi. Benchmarking and challenges in security and privacy for voice biometrics. Proc. 2021 ISCA Symposium on Security and Privacy in Speech Communication, pages 52-56. doi: 10.21437/SPSC.2021-11. 2021.</p></li>
<li><p>Natalia Tomashenko, Brij Mohan Lal Srivastava, <strong>Xin Wang</strong>, Emmanuel Vincent, Andreas Nautsch, Junichi Yamagishi, Nicholas Evans, Jose Patino, Jean-Fran{c{c}}ois Bonastre, Paul-Gauthier No{'{e}} and Massimiliano Todisco. Introducing the VoicePrivacy Initiative. Proc. Interspeech, pages 1693-1697. doi: 10.21437/Interspeech.2020-1333. 2020.</p></li>
<li><p>Brij Mohan Lal Srivastava, Natalia Tomashenko, <strong>Xin Wang</strong>, Emmanuel Vincent, Junichi Yamagishi, Mohamed Maouche, Aur{'{e}}lien Bellet and Marc Tommasi. Design Choices for X-Vector Based Speaker Anonymization. Proc. Interspeech, pages 1713-1717. doi: 10.21437/Interspeech.2020-2692. 2020.</p></li>
<li><p>Fuming Fang, <strong>Xin Wang</strong>, Junichi Yamagishi, Isao Echizen, Massimiliano Todisco, Nicholas Evans and Jean-Francois Bonastre. Speaker anonymization using X-vector and neural waveform models. Proc. SSW, pages 155-160. doi: 10.21437/SSW.2019-28. 2019.</p>
<p><strong>Other topics</strong></p>
</li>
<li><p>Jingjing Tang, <strong>Xin Wang</strong>, Zhe Zhang, Junichi Yamagishd, and Fazekas George. 2025. MIDI-VALLE: Improving Expressive Piano Performance Synthesis Through Neural Codec Language Modelling. In Proc. ISMIR, 2025.</p></li>
<li><p>Jingjing Tang, Erica Cooper, <strong>Xin Wang</strong>, Junichi Yamagishi, and George Fazekas. 2025. Towards an integrated approach for expressive piano performance synthesis from music scores. In Proc. ICASSP, 2025.</p></li>
<li><p>Nicolas Jonason, <strong>Xin Wang</strong>, Erica Cooper, Lauri Juvela, Bob L. T. Sturm, and Junichi Yamagishi. 2024. DDSP-based neural waveform synthesis of polyphonic guitar performance from string-wise MIDI input. In Proc. DAFX, 2024.</p></li>
<li><p>Chang Zeng, <strong>Xin Wang</strong>, Erica Cooper, Xiaoxiao Miao and Junichi Yamagishi. Attention Back-end for Automatic Speaker Verification with Multiple Enrollment Utterances. Proc. ICASSP, pages (accepted). 2022.</p></li>
<li><p>Chen-Chou Lo, Szu-Wei Fu, Wen-Chin Huang, <strong>Xin Wang</strong>, Junichi Yamagishi, Yu Tsao and Hsin-Min Wang. MOSnet: deep learning-based objective assessment for voice conversion. Proc. Interspeech, pages 1541-1545. doi: 10.21437/Interspeech.2019-2003. 2019.</p></li>
<li><p>Cassia Valentini-Botinhao, <strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Investigating RNN-based speech enhancement methods for noise-robust text-to-speech. Proc. SSW, pages 146-152. 2016.</p></li>
<li><p>Cassia Valentini-Botinhao, <strong>Xin Wang</strong>, Shinji Takaki and Junichi Yamagishi. Speech enhancement for a noise-robust text-to-speech synthesis system using deep recurrent neural networks. Proc. Interspeech, pages 352-356. 2016.</p></li>
</ol>
</section>
</section>
<section id="talk">
<h2>Talk<a class="headerlink" href="#talk" title="Permalink to this heading">¶</a></h2>
<p>(Slides are available in <a class="reference internal" href="slide.html#label-slide"><span class="std std-ref">Talk &amp; slides</span></a>)</p>
<ul class="simple">
<li><p>2024 Sep, Survey talk on Voice Privacy (link <a class="reference internal" href="slide.html#label-slide-2024-sep-1"><span class="std std-ref">SEP-2024</span></a>)</p></li>
<li><p>2023 Nov, VoicePersonae and ASVspoof workshop (link <a class="reference internal" href="slide.html#label-slide-2023-nov-1"><span class="std std-ref">NOV-2023</span></a>):</p>
<ul>
<li><p>Talk 1: <code class="docutils literal notranslate"><span class="pre">From</span> <span class="pre">DSP</span> <span class="pre">and</span> <span class="pre">DNN</span> <span class="pre">to</span> <span class="pre">DNN+DSP</span> <span class="pre">for</span> <span class="pre">waveform</span> <span class="pre">model</span></code></p></li>
<li><p>Talk 2: <code class="docutils literal notranslate"><span class="pre">Harnessing</span> <span class="pre">data</span> <span class="pre">to</span> <span class="pre">improving</span> <span class="pre">speech</span> <span class="pre">spoofing</span> <span class="pre">countermeasure</span></code></p></li>
</ul>
</li>
<li><p>2023 Aug, Interspeech 2023 tutorial <code class="docutils literal notranslate"><span class="pre">Advances</span> <span class="pre">in</span> <span class="pre">audio</span> <span class="pre">anti-spoofing</span> <span class="pre">and</span> <span class="pre">deepfake</span> <span class="pre">detection</span> <span class="pre">using</span> <span class="pre">graph</span> <span class="pre">neural</span> <span class="pre">networks</span> <span class="pre">and</span> <span class="pre">self-supervised</span> <span class="pre">learning</span></code>. Materials are available on <a class="reference external" href="https://github.com/Jungjee/INTERSPEECH2023_T6">github</a>.</p></li>
<li><p>2023 Mar, SPSC webinar: <code class="docutils literal notranslate"><span class="pre">using</span> <span class="pre">vocoders</span> <span class="pre">to</span> <span class="pre">create</span> <span class="pre">training</span> <span class="pre">data</span> <span class="pre">for</span> <span class="pre">speech</span> <span class="pre">spoofing</span> <span class="pre">countermeasure</span></code> (link <a class="reference internal" href="slide.html#label-slide-2023-mar-1"><span class="std std-ref">MAR-2023</span></a>).</p></li>
<li><p>2022 Sep, SPSC Symposium: <code class="docutils literal notranslate"><span class="pre">tutorial</span> <span class="pre">on</span> <span class="pre">speaker</span> <span class="pre">anonymization</span> <span class="pre">(software</span> <span class="pre">part)</span></code> (link :ref: <cite>label-slide-2022-sep-1</cite>).</p></li>
<li><p>2022 May, ICASSP 2022 short course: <code class="docutils literal notranslate"><span class="pre">inclusive</span> <span class="pre">Neural</span> <span class="pre">Speech</span> <span class="pre">Synthesis</span> <span class="pre">-</span> <span class="pre">neural</span> <span class="pre">vocoder</span> <span class="pre">part</span></code> (link <a class="reference internal" href="slide.html#label-slide-2022-may-1"><span class="std std-ref">MAY-2022</span></a>).</p></li>
<li><p>2021 Dec, Speech Synthesis Forum, China Computer Federation: <code class="docutils literal notranslate"><span class="pre">Two</span> <span class="pre">speech</span> <span class="pre">security</span> <span class="pre">issues</span> <span class="pre">after</span> <span class="pre">the</span> <span class="pre">speech</span> <span class="pre">synthesis</span> <span class="pre">boom</span></code> (link <a class="reference internal" href="slide.html#label-slide-2021-oct-1"><span class="std std-ref">OCT-2021</span></a>).</p></li>
<li><p>2021 Oct, JST Science Agora 2021, pre-Agora event: <code class="docutils literal notranslate"><span class="pre">Deepfakes:</span> <span class="pre">High-tech</span> <span class="pre">Illusions</span> <span class="pre">to</span> <span class="pre">Trick</span> <span class="pre">the</span> <span class="pre">Human</span> <span class="pre">Brain.</span></code>, with Sascha Frühholz (University of Zurich), Erica Cooper, Florence Steiner (University of Zurich). Video is <a class="reference external" href="https://youtu.be/FfhiGFA0dg8">here</a></p></li>
<li><p>2021 July, Tutorial at ISCA 2021 Speech Processing Courses in Crete: <code class="docutils literal notranslate"><span class="pre">Advancement</span> <span class="pre">in</span> <span class="pre">Neural</span> <span class="pre">Vocoders</span></code>, with Prof. Yamagishi (link <a class="reference internal" href="slide.html#label-slide-2021-jul-1"><span class="std std-ref">JUL-2021</span></a>).</p></li>
<li><p>2020 Nov., Tutorial as ISCA 2020 Speaker Odyssey: <code class="docutils literal notranslate"><span class="pre">Neural</span> <span class="pre">statistical</span> <span class="pre">parametric</span> <span class="pre">speech</span> <span class="pre">synthesis</span></code> (link <a class="reference internal" href="slide.html#label-slide-2020-dec-1"><span class="std std-ref">DEC-2020</span></a>).</p></li>
<li><p>2020 July, Tutorial at ISCA 2020 Speech Processing Courses in Crete: <code class="docutils literal notranslate"><span class="pre">Neural</span> <span class="pre">auto-regressive,</span> <span class="pre">source-filter</span> <span class="pre">and</span> <span class="pre">glottal</span> <span class="pre">vocoders</span> <span class="pre">for</span> <span class="pre">speech</span> <span class="pre">and</span> <span class="pre">music</span> <span class="pre">signals</span></code>, with Prof. Yamagishi (link <a class="reference internal" href="slide.html#label-slide-2020-jul-1"><span class="std std-ref">JUL-2020</span></a>).</p></li>
<li><p>2019 Sep, Fraunhofer IIS, invited talk: <code class="docutils literal notranslate"><span class="pre">Neural</span> <span class="pre">waveform</span> <span class="pre">models</span> <span class="pre">for</span> <span class="pre">text-to-speech</span> <span class="pre">synthesis</span></code> (link <a class="reference internal" href="slide.html#label-slide-2019-sep-1"><span class="std std-ref">SEP-2019</span></a>).</p></li>
<li><p>2019 Jan, IEICE Technical Committee on Speech (SP), invited tutorial, Kanazawa, Japan: <code class="docutils literal notranslate"><span class="pre">Tutorial</span> <span class="pre">on</span> <span class="pre">recent</span> <span class="pre">neural</span> <span class="pre">waveform</span> <span class="pre">models</span></code> (link <a class="reference internal" href="slide.html#label-slide-2019-jan-1"><span class="std std-ref">JAN-2019</span></a>).</p></li>
<li><p>2018 Nov, Nagoya Institute of Technology, Tokuda lab: <code class="docutils literal notranslate"><span class="pre">Autoregressive</span> <span class="pre">neural</span> <span class="pre">networks</span> <span class="pre">for</span> <span class="pre">parametric</span> <span class="pre">speech</span> <span class="pre">synthesis</span></code> (link <a class="reference internal" href="slide.html#label-slide-2018-jan-1"><span class="std std-ref">JAN-2018</span></a>).</p></li>
<li><p>2018 Jun, University of Eastern Finland and Aalto University <code class="docutils literal notranslate"><span class="pre">Autoregressive</span> <span class="pre">neural</span> <span class="pre">networks</span> <span class="pre">for</span> <span class="pre">parametric</span> <span class="pre">speech</span> <span class="pre">synthesis</span></code> (same content as above).</p></li>
</ul>
</section>
<section id="awards-scholarship">
<h2>Awards &amp; scholarship<a class="headerlink" href="#awards-scholarship" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>Best paper award for <a class="reference external" href="https://www.soken.ac.jp/news/5935/">SSW 2016</a>, ISCA SynSig</p></li>
<li><p><a class="reference external" href="https://www.soken.ac.jp/news/5935/">SOKENDAI Award</a>, SOKENDAI, Japan</p></li>
<li><p><a class="reference external" href="https://www.ieice.org/iss/sp/jpn/special/sp-prize.html">Young Researcher’s Award in Speech Field</a>, IEICE ISS, Japan</p></li>
<li><p>11th IEEE Signal Processing Society Japan Student <a class="reference external" href="https://ieee-jp.org/section/tokyo/chapter/SP-01/past-student-paper.htm">Best Paper Award</a>, IEEE Japan</p></li>
<li><p>MEXT Scholarship (Ph.D 2015 - 2018), Japan</p></li>
</ul>
</section>
<section id="language">
<h2>Language<a class="headerlink" href="#language" title="Permalink to this heading">¶</a></h2>
<ul class="simple">
<li><p>Mandarin</p></li>
<li><p>English (Toefl 2015, 112/120)</p></li>
<li><p>Japanese (N1, 2021 Dec, 169/180)</p></li>
</ul>
<div class="toctree-wrapper compound">
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Page contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Resume</a><ul>
<li><a class="reference internal" href="#education">Education</a></li>
<li><a class="reference internal" href="#academic-activity">Academic activity</a></li>
<li><a class="reference internal" href="#grants">Grants</a></li>
<li><a class="reference internal" href="#publication">Publication</a><ul>
<li><a class="reference internal" href="#journal-papers">Journal papers</a></li>
<li><a class="reference internal" href="#book-chapters">Book chapters</a></li>
<li><a class="reference internal" href="#conference-papers">Conference papers</a></li>
</ul>
</li>
<li><a class="reference internal" href="#talk">Talk</a></li>
<li><a class="reference internal" href="#awards-scholarship">Awards &amp; scholarship</a></li>
<li><a class="reference internal" href="#language">Language</a></li>
</ul>
</li>
</ul>
<h3><a href="index.html">Site map</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Welcome</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Resume</a></li>
<li class="toctree-l1"><a class="reference internal" href="research.html">Research overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="presto.html">Research PRESTO</a></li>
<li class="toctree-l1"><a class="reference internal" href="slide.html">Talk &amp; slides</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2025, WangXin.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.0.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/resume.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>
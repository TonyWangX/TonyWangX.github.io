<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Talk &amp; slides &#8212; Home-page-WangXin  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="JST PRESTO Project" href="presto.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="talk-slides">
<span id="label-slide"></span><h1>Talk &amp; slides<a class="headerlink" href="#talk-slides" title="Permalink to this heading">¶</a></h1>
<p>In most cases, I cannot directly share audio samples. Some samples can be found through the link in the PDF.</p>
<section id="talk">
<h2>Talk<a class="headerlink" href="#talk" title="Permalink to this heading">¶</a></h2>
<section id="sep-24-2024">
<span id="label-slide-2024-sep-2"></span><h3>SEP-24-2024<a class="headerlink" href="#sep-24-2024" title="Permalink to this heading">¶</a></h3>
<p><strong>APSIPA China-Japan Joint Symposium</strong>: Introduction to the research of NII Yamagishi Lab</p>
<ul class="simple">
<li><p>Slides (gdrive): <a class="reference external" href="https://drive.google.com/file/d/1bLBBX53C-eD-B7yNpgvlLCyNeUpw7-h2/view?usp=drive_link">PDF</a> and <a class="reference external" href="https://docs.google.com/presentation/d/125BBQTUFoj1Bv5UpKDSl7szJLIhPO82I/edit?usp=drive_link&amp;ouid=110003331173621958152&amp;rtpof=true&amp;sd=true">PPT</a></p></li>
</ul>
</section>
<section id="sep-2024">
<span id="label-slide-2024-sep-1"></span><h3>SEP-2024<a class="headerlink" href="#sep-2024" title="Permalink to this heading">¶</a></h3>
<p><strong>Interspeech 2024 survey talk</strong>: Current trend in speech privacy and security</p>
<ul class="simple">
<li><p>Slides (privacy part): <a class="reference external" href="https://drive.google.com/file/d/1I71v6arn0Q5unMzfVJxlcRjsrf9vpKyY/view?usp=drive_link">PDF</a></p></li>
</ul>
</section>
<section id="nov-2023">
<span id="label-slide-2023-nov-1"></span><h3>NOV-2023<a class="headerlink" href="#nov-2023" title="Permalink to this heading">¶</a></h3>
<p><strong>VoicePersonae workshop talk 2</strong>: Harnessing data to improve speech spoofing countermeasures</p>
<p>High-level summary of the talk to use vocoded data to train speech anti-spoofing models. Slides can be downloaded here <a class="reference external" href="https://drive.google.com/file/d/1UlDah9mXE2FehJMAaXsKzC2ZfkYbWR6H/view?usp=drive_link">gdrive</a>.</p>
<p><strong>VoicePersonae workshop talk 1</strong>: DNN+DSP waveform model</p>
<p>An overview talk given at VoicePersonae workshop. The title is From DSP and DNN to DNN/DSP: Neural speech waveform models and its applications in speech and music audio waveform modelling. Slides can be downloaded here <a class="reference external" href="https://drive.google.com/file/d/1v8wI3gik4QEs40NGautZrlmS8xNbMm-l/view?usp=drive_link">gdrive</a>.</p>
</section>
<section id="oct-2023">
<span id="label-slide-2023-oct-31"></span><h3>OCT-2023<a class="headerlink" href="#oct-2023" title="Permalink to this heading">¶</a></h3>
<p><strong>Shonan Seminar</strong></p>
<p>During the No.182 Shonan Seminar  <a class="reference external" href="https://shonan.nii.ac.jp/seminars/182/">https://shonan.nii.ac.jp/seminars/182/</a>, I had chance to introduce voice privacy. Slides are available on <a class="reference external" href="https://drive.google.com/file/d/115k8GzxBQiGB8E8x3zDmiI0qW7eoX4iw/view?usp=drive_link">gdrive</a>.</p>
</section>
<section id="aug-2023">
<span id="label-slide-2023-aug-1"></span><h3>AUG-2023<a class="headerlink" href="#aug-2023" title="Permalink to this heading">¶</a></h3>
<p><strong>Interspeech Tutorial: anti-spoofing</strong></p>
<p>Interspeech 2023 tutorial Advances in audio anti-spoofing and deepfake detection using graph neural networks and self-supervised learning.</p>
<p>Slides and notebook are available on <a class="reference external" href="https://github.com/Jungjee/INTERSPEECH2023_T6">github</a>.</p>
</section>
<section id="mar-2023">
<span id="label-slide-2023-mar-1"></span><h3>MAR-2023<a class="headerlink" href="#mar-2023" title="Permalink to this heading">¶</a></h3>
<p><strong>SPSC Webinar: using vocoders to create spoofed data for speech spoofing countermeasures</strong></p>
<p>Based on <a class="reference external" href="https://arxiv.org/abs/2210.10570">ICASSP 2023 paper</a> Spoofed training data for speech spoofing countermeasure can be efficiently created using neural vocoders.</p>
<p>Slides <a class="reference external" href="https://drive.google.com/file/d/1vRKyMRLvb_WbOn-n5mbQbvW7tKIbdSxl/view?usp=drive_link">in PDF</a> and <a class="reference external" href="https://docs.google.com/presentation/d/1D5Qw7qFTIV27Wu3prTsaac3zsCgU8Bp6/edit?usp=drive_link&amp;ouid=110003331173621958152&amp;rtpof=true&amp;sd=true">PPTX</a></p>
</section>
<section id="sep-2022">
<span id="label-slide-2022-sep-1"></span><h3>SEP-2022<a class="headerlink" href="#sep-2022" title="Permalink to this heading">¶</a></h3>
<p><strong>SPSC Symposium: tutorial on speaker anonymization (software part)</strong></p>
<p>This short tutorial shows the basic process of speaker anonymization, using baselines in Voice Privacy Challenge 2022.</p>
<p>The hands-on notebook is available on <a class="reference external" href="https://colab.research.google.com/drive/1_zRL_f9iyDvl_5Y2Rdakg0hYAl_5Rgyq?usp=sharing">Google Colab</a>.</p>
</section>
<section id="may-2022">
<span id="label-slide-2022-may-1"></span><h3>MAY-2022<a class="headerlink" href="#may-2022" title="Permalink to this heading">¶</a></h3>
<p><strong>ICASSP 2022 short course: neural vocoder</strong></p>
<p>This talk summarizes a few representative neural vocoders. For a more detailed talk, please check <a class="reference internal" href="#label-slide-2021-jul-1"><span class="std std-ref">the slide for Advancement in Neural Vocoders</span></a>.</p>
<p>The hands-on materials cover a few latest neural vocoders. There are step-to-step instructions on implementation, demonstration with pre-trained models, and detailed explanation on some common DSP and deep learning techniques. Please check <a class="reference external" href="https://colab.research.google.com/drive/1EO-ggi1U9f2zXwTiqg7AEljVx11JKta7">Google Colab</a>.</p>
</section>
<section id="dec-2021">
<span id="label-slide-2021-dec-1"></span><h3>DEC-2021<a class="headerlink" href="#dec-2021" title="Permalink to this heading">¶</a></h3>
<p><strong>Two Speech Security Issues after Speech Synthesis Boom</strong></p>
<p>This talk introduces anti-spoofing (audio deepfake detection) and voice privacy. It is mainly for new comers to these fields.</p>
<p>The slide can be found <a class="reference external" href="https://drive.google.com/file/d/14SHRTz6KIFAo46hXWkhBRcfn7Srt5SWv/view?usp=drive_link">on gdrive</a>, <a class="reference external" href="https://docs.google.com/presentation/d/1i5NDmiT1bUpjOsDKOUzE8s_t-Kds15gz/edit?usp=drive_link&amp;ouid=110003331173621958152&amp;rtpof=true&amp;sd=true">(PPT)</a>.</p>
</section>
<section id="oct-2021">
<span id="label-slide-2021-oct-1"></span><h3>OCT-2021<a class="headerlink" href="#oct-2021" title="Permalink to this heading">¶</a></h3>
<p><strong>DeepFake: high-tech illusions to deceive human brains</strong></p>
<p>This is a talk given at JST Science Agora with Dr. Erica Cooper. It is an introduction on anti-spoofing (audio deepfake detection).</p>
<p>Slides: <a class="reference external" href="https://drive.google.com/file/d/1nT7chwCIWfR8iMioonE8kefvWmNJvHcJ/view?usp=drive_link">Agora PDF</a>  and <a class="reference external" href="https://docs.google.com/presentation/d/1nV9E70MpGwIH_Gm2pzhhKnZ_8DbAQKId/edit?usp=drive_link&amp;ouid=110003331173621958152&amp;rtpof=true&amp;sd=true">PPT</a>.</p>
</section>
<section id="jul-2021">
<span id="label-slide-2021-jul-1"></span><h3>JUL-2021<a class="headerlink" href="#jul-2021" title="Permalink to this heading">¶</a></h3>
<p><strong>Advancement in Neural Vocoders</strong></p>
<p>This is the tutorial on neural vocoders, at ISCA 2021 Speech Processing Courses in Crete, with Prof. Yamagishi. It was a very long tutorial (&gt;3 hours). Slides <a class="reference external" href="https://drive.google.com/file/d/1LUUddVl7IIQcfC0BzbvMxmWAQcjoDsoT/view?usp=drive_link">here</a>.</p>
<p>The hands-on materials were re-edited and uploaded to Google Colab. See <a class="reference internal" href="#label-slide-2022-may-1"><span class="std std-ref">ICASSP 2022 short course: neural vocoder</span></a>.</p>
</section>
<section id="dec-2020">
<span id="label-slide-2020-dec-1"></span><h3>DEC-2020<a class="headerlink" href="#dec-2020" title="Permalink to this heading">¶</a></h3>
<p><strong>Tutorial on Neural statistical parametric speech synthesis</strong></p>
<p>This is a tutorial on text-to-speech synthesis, at ISCA speaker Odyssey 2020. It is mainly on sequence-to-sequence TTS acoustic models (both soft- and hard-attention based approaches), but it also covers some basic ideas from the classical HMM-based approaches.</p>
<p><a class="reference external" href="https://drive.google.com/file/d/1NILLI8fDmVp_oZ9DFSNGw1D4E7fZkwjt/view?usp=drive_link">PDF</a> and <a class="reference external" href="https://docs.google.com/presentation/d/1wxvD0bcpJg8QfjFDhEh_G24DQk7B5kW2/edit?usp=drive_link&amp;ouid=110003331173621958152&amp;rtpof=true&amp;sd=true">PPT slides</a> are available.</p>
<p>The video is on <a class="reference external" href="https://youtu.be/WCe7SYcDzAI">youtube</a>. There many audios samples collected from reference papers’ official websites or from open domain data repository.</p>
</section>
<section id="nov-2020">
<span id="label-slide-2020-nov-1"></span><h3>NOV-2020<a class="headerlink" href="#nov-2020" title="Permalink to this heading">¶</a></h3>
<p><strong>Neural vocoders for speech and music signals</strong></p>
<p>This an invited talk at YAMAHA, with Prof. Yamagishi. No slides available.</p>
</section>
<section id="jul-2020">
<span id="label-slide-2020-jul-1"></span><h3>JUL-2020<a class="headerlink" href="#jul-2020" title="Permalink to this heading">¶</a></h3>
<p><strong>Neural auto-regressive, source-filter and glottal vocoders for speech and music signals</strong></p>
<p>This is the early version of the tutorial on neural vocoders, given at ISCA 2020 Speech Processing Courses in Crete, with Prof. Yamagishi.</p>
<p>The hands-on materials were re-edited and uploaded to Google Colab. See <a class="reference internal" href="#label-slide-2022-may-1"><span class="std std-ref">ICASSP 2022 short course: neural vocoder</span></a>.</p>
</section>
<section id="sep-2019">
<span id="label-slide-2019-sep-1"></span><h3>SEP-2019<a class="headerlink" href="#sep-2019" title="Permalink to this heading">¶</a></h3>
<p><strong>Neural waveform models for text-to-speech synthesis</strong></p>
<p>Invited talk given at Fraunhofer IIS, Erlangen, Germany.</p>
<p>This is about the neural source-filter vocoders and related experiments done by 2019.</p>
<p>Slide is <a class="reference external" href="https://drive.google.com/file/d/1hsq8gAK_dncEMtQY-04CXTBen4BrQJQ3/view?usp=drive_link">here</a> and <a class="reference external" href="https://docs.google.com/presentation/d/1j3u4E54guwKlrFEmklVpKm7CWEHOwvzb/edit?usp=drive_link&amp;ouid=110003331173621958152&amp;rtpof=true&amp;sd=true">here</a></p>
</section>
<section id="jan-2019">
<span id="label-slide-2019-jan-1"></span><h3>JAN-2019<a class="headerlink" href="#jan-2019" title="Permalink to this heading">¶</a></h3>
<p><strong>Tutorial on recent neural waveform models</strong></p>
<p>This is a talk on neural vocoders, but the contents and explanations are based on my knowledge by then. It is out-of-date. Please check tutorials above for my latest understanding.</p>
<p>IEICE Technical Committee on Speech (SP), invited tutorial, Kanazawa, Japan. Slides not available</p>
</section>
<section id="jan-2018">
<span id="label-slide-2018-jan-1"></span><h3>JAN-2018<a class="headerlink" href="#jan-2018" title="Permalink to this heading">¶</a></h3>
<p><strong>Autoregressive neural networks for parametric speech synthesis</strong></p>
<p>This is a talk on the previous-generation TTS system. It talks about autoregressive models for F0 prediction.</p>
<p>It was given at Nagoya Institute of Technology, Tokuda lab, and Aalto University, Paavo Alku lab. Slide is <a class="reference external" href="https://drive.google.com/file/d/1H31HRmKWN8YfSc5i9Txb2AQnl5IoExZr/view?usp=drive_link">here</a></p>
</section>
</section>
<section id="conference-presentation">
<span id="label-slide-conf-landing"></span><h2>Conference presentation<a class="headerlink" href="#conference-presentation" title="Permalink to this heading">¶</a></h2>
<section id="asvspoof-2024">
<span id="label-slide-asvspoof2024-1"></span><h3>ASVSPOOF-2024<a class="headerlink" href="#asvspoof-2024" title="Permalink to this heading">¶</a></h3>
<p>Summary of ASVspoof 5: <a class="reference external" href="https://www.asvspoof.org/file/ASVspoof_Workshop_2024_Slides.pdf">PDF</a></p>
</section>
<section id="is-2024">
<span id="label-slide-is2024-1"></span><h3>IS-2024<a class="headerlink" href="#is-2024" title="Permalink to this heading">¶</a></h3>
<p>Revisiting score fusion for spoofing-aware speaker verification</p>
<ul class="simple">
<li><p>Paper: <a class="reference external" href="https://www.isca-archive.org/interspeech_2024/wang24l_interspeech.html">https://www.isca-archive.org/interspeech_2024/wang24l_interspeech.html</a></p></li>
<li><p>Slides: <a class="reference external" href="https://drive.google.com/file/d/11IlXr_XCcBB93wxj2pzeQNDLRm4OUfiM/view?usp=drive_link">PDF</a> and <a class="reference external" href="https://docs.google.com/presentation/d/1AdZbCSCShn4njkFKq6BGUD6tZlDakf9w/edit?usp=drive_link&amp;ouid=110003331173621958152&amp;rtpof=true&amp;sd=true">PDF</a></p></li>
<li><p>Github: <a class="reference external" href="https://github.com/nii-yamagishilab/SpeechSPC-mini">https://github.com/nii-yamagishilab/SpeechSPC-mini</a></p></li>
</ul>
</section>
<section id="icassp-2024">
<span id="label-slide-icassp2024-1"></span><h3>ICASSP-2024<a class="headerlink" href="#icassp-2024" title="Permalink to this heading">¶</a></h3>
<p>Can Large-Scale Vocoded Spoofed Data Improve Speech Spoofing Countermeasure with a Self-Supervised Front End?</p>
<ul class="simple">
<li><p>Paper: <a class="reference external" href="https://ieeexplore.ieee.org/document/10446331">https://ieeexplore.ieee.org/document/10446331</a></p></li>
<li><p>Slides: <a class="reference external" href="https://drive.google.com/file/d/1Iwph16smPFXAlCQjUPV2UKObdKe6C0jB/view?usp=drive_link">PDF</a> and <a class="reference external" href="https://docs.google.com/presentation/d/16Jf5r_1lDcA6EBmi_Mi6sWK5vRoJkjuo/edit?usp=drive_link&amp;ouid=110003331173621958152&amp;rtpof=true&amp;sd=true">PPT</a></p></li>
</ul>
</section>
<section id="icassp-2023">
<span id="label-slide-icassp2023-1"></span><h3>ICASSP-2023<a class="headerlink" href="#icassp-2023" title="Permalink to this heading">¶</a></h3>
<p>Anti-spoofing using vocoded data: <a class="reference external" href="https://drive.google.com/file/d/1OB9zz7ByatNA9KZxrR1ehzf2ZJUcNI-L/view?usp=drive_link">PDF</a></p>
</section>
<section id="slt-2022">
<span id="label-slide-slt2022-1"></span><h3>SLT-2022<a class="headerlink" href="#slt-2022" title="Permalink to this heading">¶</a></h3>
<p>Anti-spoofing using active learning: <a class="reference external" href="https://drive.google.com/file/d/1t1S1oRJVKcyTBgmLFbBznSb4bHAGBzKE/view?usp=drive_link">PDF</a></p>
</section>
<section id="odyssey-2022">
<span id="label-slide-od2021-1"></span><h3>ODYSSEY-2022<a class="headerlink" href="#odyssey-2022" title="Permalink to this heading">¶</a></h3>
<p>Anti-spoofing using SSL features: <a class="reference external" href="https://drive.google.com/file/d/1IegE9Q69W4q37VYwRon7umrOUBcQ2O-c/view?usp=drive_link">PDF</a>.</p>
</section>
<section id="is-2021">
<span id="label-slide-is2021-1"></span><h3>IS-2021<a class="headerlink" href="#is-2021" title="Permalink to this heading">¶</a></h3>
<p>Anti-spoofing: Interspeech 2021 presentation for Comparative study on ASVspoof 2019 LA <a class="reference external" href="https://drive.google.com/file/d/1QXqbwgtwIeSz78c4U0C6DVcu-bV9LqWo/view?usp=drive_link">PDF</a>. Codes are available at git repo project/03-asvspoof-mega <a class="reference external" href="https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts">git:</a></p>
</section>
<section id="is-2020">
<span id="label-slide-is2020-1"></span><h3>IS-2020<a class="headerlink" href="#is-2020" title="Permalink to this heading">¶</a></h3>
<p>NSF model (latest ver.): Interspeech 2020 presentation for cyclic-noise-NSF – <a class="reference external" href="https://docs.google.com/presentation/d/1gfA1x3ESQ11bjvdrd197y93mlJmAo-pD/edit?usp=drive_link&amp;ouid=110003331173621958152&amp;rtpof=true&amp;sd=true">PPT</a> and <a class="reference external" href="https://drive.google.com/file/d/1i5oxGxXZNuWyYe3znTYyo38kK6siGkkh/view?usp=drive_link">PDF slides</a> . Natural samples are from <a class="reference external" href="http://www.festvox.org/cmu_arctic/">CMU-arctic</a></p>
</section>
<section id="ssw-2019">
<span id="label-slide-ssw2019-1"></span><h3>SSW-2019<a class="headerlink" href="#ssw-2019" title="Permalink to this heading">¶</a></h3>
<p>NSF model (2nd ver.): <a class="reference external" href="https://drive.google.com/file/d/1pueibDGoI5v2wsaC7W2hQSkywYqYoAlf/view?usp=drive_link">SSW 2019</a> for paper Neural Harmonic-plus-Noise Waveform Model with Trainable Maximum Voice Frequency for Text-to-Speech Synthesis</p>
</section>
<section id="icassp-2019">
<span id="label-slide-icassp2019-1"></span><h3>ICASSP-2019<a class="headerlink" href="#icassp-2019" title="Permalink to this heading">¶</a></h3>
<p>NSF model (1st ver.): <a class="reference external" href="https://drive.google.com/file/d/1laHPcwbBeWrpYqmvA_yDlfWRgkvIFaxu/view?usp=drive_link">ICASSP 2019</a> for paper Neural Source-Filter-Based Waveform Model for Statistical Parametric Speech Synthesis</p>
</section>
<section id="icassp-2018">
<span id="label-slide-icassp2018-1"></span><h3>ICASSP-2018<a class="headerlink" href="#icassp-2018" title="Permalink to this heading">¶</a></h3>
<p>Speech synthesis comparison: <a class="reference external" href="https://drive.google.com/file/d/1LYu57nKXZTLaCAuVqy-Ym2tO92S2RoOZ/view?usp=drive_link">ICASSP 2018</a> for paper A Comparison of Recent Waveform Generation and Acoustic Modeling Methods for Neural-Network-Based Speech Synthesis</p>
</section>
<section id="is-2017">
<span id="label-slide-is2017-1"></span><h3>IS-2017<a class="headerlink" href="#is-2017" title="Permalink to this heading">¶</a></h3>
<p>Deep AR F0 model: <a class="reference external" href="https://drive.google.com/file/d/1sOicPmH2Gjqk5pF_53kTFkTI-Hq9jBnO/view?usp=drive_link">Interspeech 2017 slide</a> for paper An RNN-Based Quantized F0 Model with Multi-Tier Feedback Links for Text-to-Speech Synthesis.</p>
</section>
<section id="icassp-2017">
<span id="label-slide-icassp2017-1"></span><h3>ICASSP-2017<a class="headerlink" href="#icassp-2017" title="Permalink to this heading">¶</a></h3>
<p>Shallow AR model: <a class="reference external" href="https://drive.google.com/file/d/1MpxLs7WD0J8QL2q-eDRO-IS0CLeULCKN/view?usp=drive_link">ICASSP 2017 slide</a> for paper An Autoregressive Recurrent Mixture Density Network for Parametric Speech Synthesis.</p>
</section>
<section id="ssw-2016">
<span id="label-slide-ssw2016-1"></span><h3>SSW-2016<a class="headerlink" href="#ssw-2016" title="Permalink to this heading">¶</a></h3>
<p>Speech synthesis: <a class="reference external" href="https://drive.google.com/file/d/1wcpkBltIHRtRZndA3EhJHl95QCs4Z1lA/view?usp=drive_link">SSW 2016 slide</a> for paper A Comparative Study of the Performance of HMM, DNN, and RNN Based Speech Synthesis Systems Trained on Very Large Speaker-Dependent Corpora.</p>
</section>
<section id="is-2016">
<span id="label-slide-is2016-1"></span><h3>IS-2016<a class="headerlink" href="#is-2016" title="Permalink to this heading">¶</a></h3>
<p>Prosody embedding: <a class="reference external" href="https://drive.google.com/file/d/1NEovmpajAd1tQAFOXizkqCRlvG-TihsQ/view?usp=drive_link">Interspeech 2016 slide</a> for paper Enhance the Word Vector with Prosodic Information for the Recurrent Neural Network Based TTS System.</p>
</section>
<section id="icassp-2016">
<span id="label-slide-icassp2016-1"></span><h3>ICASSP-2016<a class="headerlink" href="#icassp-2016" title="Permalink to this heading">¶</a></h3>
<p>HMM-based speech synthesis: <a class="reference external" href="https://drive.google.com/file/d/1yLE4jScXN1EoNG-PyqR2-tOmdqHO9D1P/view?usp=drive_link">ICASSP 2016 slide</a>. For paper A Full Training Framework of Cross-Stream Dependence Modelling for HMM-Based Singing Voice Synthesis.</p>
</section>
</section>
<section id="misc">
<h2>MISC<a class="headerlink" href="#misc" title="Permalink to this heading">¶</a></h2>
<p>On CURRENNT toolkit. These slides were made a long time ago during weekends, and they may be sloppy :)</p>
<blockquote>
<div><ul class="simple">
<li><p>CURRENNT <a class="reference external" href="https://drive.google.com/file/d/1t9XqHszPnW-HJbhg96FUSa26Cw3T_7Xt/view?usp=drive_link">basics</a></p></li>
<li><p>CURRENNT <a class="reference external" href="https://drive.google.com/file/d/1yXn5UkaQRkDsca706ETPMnLa1nMA47sn/view?usp=drive_link">LSTM explanation</a></p></li>
<li><p>CURRENNT <a class="reference external" href="https://drive.google.com/file/d/1KJvcQE7JlkU5jFSExbKcv1pJhKoibqRv/view?usp=drive_link">CNN implementation</a></p></li>
<li><p>CURRENNT <a class="reference external" href="https://drive.google.com/file/d/1zJXBGZCluCSx_WsiIePcTo0eHMa80R8c/view?usp=drive_link">mixture density network</a></p></li>
<li><p>CURRENNT CUDA implementation of <a class="reference external" href="https://drive.google.com/file/d/19Kb1UvtL2MRwjDy6tLCJIsswAsoqAhYh/view?usp=drive_link">WaveNet</a></p></li>
</ul>
</div></blockquote>
<p>CURRENNT WaveNet is also explained in <a class="reference external" href="https://drive.google.com/file/d/1NICBLQpMpZKdyh7CPo_tXeD1_MpejEEP/view?usp=drive_link">another slide</a> with more figures.</p>
<div class="toctree-wrapper compound">
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Page contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Talk &amp; slides</a><ul>
<li><a class="reference internal" href="#talk">Talk</a><ul>
<li><a class="reference internal" href="#sep-24-2024">SEP-24-2024</a></li>
<li><a class="reference internal" href="#sep-2024">SEP-2024</a></li>
<li><a class="reference internal" href="#nov-2023">NOV-2023</a></li>
<li><a class="reference internal" href="#oct-2023">OCT-2023</a></li>
<li><a class="reference internal" href="#aug-2023">AUG-2023</a></li>
<li><a class="reference internal" href="#mar-2023">MAR-2023</a></li>
<li><a class="reference internal" href="#sep-2022">SEP-2022</a></li>
<li><a class="reference internal" href="#may-2022">MAY-2022</a></li>
<li><a class="reference internal" href="#dec-2021">DEC-2021</a></li>
<li><a class="reference internal" href="#oct-2021">OCT-2021</a></li>
<li><a class="reference internal" href="#jul-2021">JUL-2021</a></li>
<li><a class="reference internal" href="#dec-2020">DEC-2020</a></li>
<li><a class="reference internal" href="#nov-2020">NOV-2020</a></li>
<li><a class="reference internal" href="#jul-2020">JUL-2020</a></li>
<li><a class="reference internal" href="#sep-2019">SEP-2019</a></li>
<li><a class="reference internal" href="#jan-2019">JAN-2019</a></li>
<li><a class="reference internal" href="#jan-2018">JAN-2018</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conference-presentation">Conference presentation</a><ul>
<li><a class="reference internal" href="#asvspoof-2024">ASVSPOOF-2024</a></li>
<li><a class="reference internal" href="#is-2024">IS-2024</a></li>
<li><a class="reference internal" href="#icassp-2024">ICASSP-2024</a></li>
<li><a class="reference internal" href="#icassp-2023">ICASSP-2023</a></li>
<li><a class="reference internal" href="#slt-2022">SLT-2022</a></li>
<li><a class="reference internal" href="#odyssey-2022">ODYSSEY-2022</a></li>
<li><a class="reference internal" href="#is-2021">IS-2021</a></li>
<li><a class="reference internal" href="#is-2020">IS-2020</a></li>
<li><a class="reference internal" href="#ssw-2019">SSW-2019</a></li>
<li><a class="reference internal" href="#icassp-2019">ICASSP-2019</a></li>
<li><a class="reference internal" href="#icassp-2018">ICASSP-2018</a></li>
<li><a class="reference internal" href="#is-2017">IS-2017</a></li>
<li><a class="reference internal" href="#icassp-2017">ICASSP-2017</a></li>
<li><a class="reference internal" href="#ssw-2016">SSW-2016</a></li>
<li><a class="reference internal" href="#is-2016">IS-2016</a></li>
<li><a class="reference internal" href="#icassp-2016">ICASSP-2016</a></li>
</ul>
</li>
<li><a class="reference internal" href="#misc">MISC</a></li>
</ul>
</li>
</ul>
<h3><a href="index.html">Site map</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Welcome</a></li>
<li class="toctree-l1"><a class="reference internal" href="resume.html">Resume</a></li>
<li class="toctree-l1"><a class="reference internal" href="research.html">Research overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="presto.html">Research PRESTO</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Talk &amp; slides</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2025, WangXin.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.0.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/slide.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>
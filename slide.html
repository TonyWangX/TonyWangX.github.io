<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Talk &amp; slides &#8212; HomePage-WangXin  documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css" />
    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="JST PRESTO Project" href="presto.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="talk-slides">
<span id="label-slide"></span><h1>Talk &amp; slides<a class="headerlink" href="#talk-slides" title="Permalink to this heading">¶</a></h1>
<p>In most cases, I cannot directly share audio samples. Some samples can be found through the link in the PDF.</p>
<section id="talk">
<h2>Talk<a class="headerlink" href="#talk" title="Permalink to this heading">¶</a></h2>
<section id="nov-2023">
<span id="label-slide-2023-nov-1"></span><h3>NOV-2023<a class="headerlink" href="#nov-2023" title="Permalink to this heading">¶</a></h3>
<p><strong>VoicePersonae workshop talk 2: Harnessing data to improve speech spoofing countermeasures</strong></p>
<p>High-level summary of the talk to use vocoded data to train speech anti-spoofing models.</p>
<p>Slides can be downloaded here <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AACIULzpbAQNmP6GjGSwnjAIa/web/20231122_ASVspoof_data.pdf">dropbox</a>.</p>
<p><strong>VoicePersonae workshop talk 1: DNN+DSP waveform model</strong></p>
<p>An overview talk given at VoicePersonae workshop. The title is From DSP and DNN to DNN/DSP: Neural speech waveform models and its applications in speech and music audio waveform modelling.</p>
<p>Slides can be downloaded here <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAD7uQRQpnJsbverEVlrl2OBa/web?dl=0&amp;preview=20231121_VoicePersonae_DSP-NDSP.pdf">dropbox</a>.</p>
</section>
<section id="oct-2023">
<span id="label-slide-2023-oct-31"></span><h3>OCT-2023<a class="headerlink" href="#oct-2023" title="Permalink to this heading">¶</a></h3>
<p><strong>Shonan Seminar: casual presentation</strong></p>
<p>During the No.182 Shonan Seminar  <a class="reference external" href="https://shonan.nii.ac.jp/seminars/182/">https://shonan.nii.ac.jp/seminars/182/</a>, I had chance to introduce voice privacy.</p>
<p>Slides are available on <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABwpFTp7e7E7T7O8QKinQYRa/web/20231102_shonan-seminar-v1.pdf">dropbox</a>.</p>
</section>
<section id="aug-2023">
<span id="label-slide-2023-aug-1"></span><h3>AUG-2023<a class="headerlink" href="#aug-2023" title="Permalink to this heading">¶</a></h3>
<p><strong>Interspeech Tutorial: anti-spoofing</strong></p>
<p>Interspeech 2023 tutorial Advances in audio anti-spoofing and deepfake detection using graph neural networks and self-supervised learning.</p>
<p>Slides and notebook are available on <a class="reference external" href="https://github.com/Jungjee/INTERSPEECH2023_T6">github</a>.</p>
</section>
<section id="mar-2023">
<span id="label-slide-2023-mar-1"></span><h3>MAR-2023<a class="headerlink" href="#mar-2023" title="Permalink to this heading">¶</a></h3>
<p><strong>SPSC Webinar: using vocoders to create spoofed data for speech spoofing countermeasures</strong></p>
<p>for <a class="reference external" href="https://arxiv.org/abs/2210.10570">ICASSP 2023 paper</a> “Spoofed training data for speech spoofing countermeasure can be efficiently created using neural vocoders”.</p>
<p>Slides <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAA8o9fpoJV27JL2y02_p46Ea/web/20230306_spsc_webinar_xinwang.pdf">in PDF</a> and <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABdRnr6WPKr0cI4DU32FPN2a/web/20230306_spsc_webinar_xinwang.pptx">PPTX</a></p>
</section>
<section id="sep-2022">
<span id="label-slide-2022-sep-1"></span><h3>SEP-2022<a class="headerlink" href="#sep-2022" title="Permalink to this heading">¶</a></h3>
<p><strong>SPSC Symposium: tutorial on speaker anonymization (software part)</strong></p>
<p>This short tutorial shows the basic process of speaker anonymization, using baselines in Voice Privacy Challenge 2022.</p>
<p>The hands-on notebook is available on <a class="reference external" href="https://colab.research.google.com/drive/1_zRL_f9iyDvl_5Y2Rdakg0hYAl_5Rgyq?usp=sharing">Google Colab</a>.</p>
</section>
<section id="may-2022">
<span id="label-slide-2022-may-1"></span><h3>MAY-2022<a class="headerlink" href="#may-2022" title="Permalink to this heading">¶</a></h3>
<p><strong>ICASSP 2022 short course: neural vocoder</strong></p>
<p>This talk briefly summarizes a few representative neural vocoders. For a more detailed talk, please check <a class="reference internal" href="#label-slide-2021-jul-1"><span class="std std-ref">the slide for Advancement in Neural Vocoders</span></a>.</p>
<p>The hands-on materials used for this short course cover a few latest neural vocoders. There are step-to-step instructions on implementation, demonstration with pre-trained models, and detailed explanation on some common DSP and deep learning techniques. Please check <a class="reference external" href="https://colab.research.google.com/drive/1EO-ggi1U9f2zXwTiqg7AEljVx11JKta7">Google Colab</a>.</p>
</section>
<section id="dec-2021">
<span id="label-slide-2021-dec-1"></span><h3>DEC-2021<a class="headerlink" href="#dec-2021" title="Permalink to this heading">¶</a></h3>
<p><strong>Two Speech Security Issues after Speech Synthesis Boom</strong></p>
<p>This talk briefly introduces anti-spoofing (audio deepfake detection) and voice privacy. It is mainly for new comers to these fields.</p>
<p>The slide can be found <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AADDhVJGzMbXEquzf2Z1Y8YHa/web/CCF-talk-2021.pptx">on dropbox here (PPTX)</a>, <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAANoSBvdc4y16CteakUcF9Ia/web/CCF-talk-2021.pdf">(PDF)</a>.</p>
</section>
<section id="oct-2021">
<span id="label-slide-2021-oct-1"></span><h3>OCT-2021<a class="headerlink" href="#oct-2021" title="Permalink to this heading">¶</a></h3>
<p><strong>DeepFake: high-tech illusions to deceive human brains</strong></p>
<p>This is a talk given at JST Science Agora with Dr. Erica Cooper.</p>
<p>It is an introduction on anti-spoofing (audio deepfake detection).</p>
<p>Here is the part presented by me: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAC3cXcoPNA7M8MHB2CAXnY5a/web/Science-Agora-2021_part2.pdf">Agora PDF</a>  and <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AADLL5SEUSZ-fRPGSl_eiYRba/web/Science-Agora-2021_part2.pptx">Aogra PPT</a>.</p>
</section>
<section id="jul-2021">
<span id="label-slide-2021-jul-1"></span><h3>JUL-2021<a class="headerlink" href="#jul-2021" title="Permalink to this heading">¶</a></h3>
<p><strong>Advancement in Neural Vocoders</strong></p>
<p>This is the tutorial on neural vocoders, at ISCA 2021 Speech Processing Courses in Crete, with Prof. Yamagishi.</p>
<p>It was a very long tutorial (&gt;3 hours). Slides are <a class="reference external" href="https://www.slideshare.net/jyamagis/advancements-in-neural-vocoders">on slideshare</a> (I only own part of it).</p>
<p>The hands-on materials were re-edited and uploaded to Google Colab. See <a class="reference internal" href="#label-slide-2022-may-1"><span class="std std-ref">ICASSP 2022 short course: neural vocoder</span></a>.</p>
</section>
<section id="dec-2020">
<span id="label-slide-2020-dec-1"></span><h3>DEC-2020<a class="headerlink" href="#dec-2020" title="Permalink to this heading">¶</a></h3>
<p><strong>Tutorial on Neural statistical parametric speech synthesis</strong></p>
<p>This is a tutorial on text-to-speech synthesis, at ISCA speaker Odyssey 2020.</p>
<p>It is mainly on sequence-to-sequence TTS acoustic models (both soft- and hard-attention based approaches), but it also covers some basic ideas from the classical HMM-based approaches.</p>
<p><a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABFY0RiorILzSuX1YuQXyA7a/web/Odyssesy2020_Tutorial_TTS_XINWANG.pdf?raw=1">PDF</a> and <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABn3DyzRuZeBJwEGPV1ouFSa/web/Odyssesy2020_Tutorial_TTS_XINWANG.pptx?raw=1">PPT slides</a> are available.</p>
<p>The video is on <a class="reference external" href="https://youtu.be/WCe7SYcDzAI">youtube</a></p>
<p>There many audios samples collected from reference papers’ official websites or from open domain data repository.</p>
</section>
<section id="nov-2020">
<span id="label-slide-2020-nov-1"></span><h3>NOV-2020<a class="headerlink" href="#nov-2020" title="Permalink to this heading">¶</a></h3>
<p><strong>Neural vocoders for speech and music signals</strong></p>
<p>This an invited talk at YAMAHA, with Prof. Yamagishi.</p>
<p>Nothing can be disclosed.</p>
</section>
<section id="jul-2020">
<span id="label-slide-2020-jul-1"></span><h3>JUL-2020<a class="headerlink" href="#jul-2020" title="Permalink to this heading">¶</a></h3>
<p><strong>Neural auto-regressive, source-filter and glottal vocoders for speech and music signals</strong></p>
<p>This is the early version of the tutorial on neural vocoders, given at ISCA 2020 Speech Processing Courses in Crete, with Prof. Yamagishi.</p>
<p>The hands-on materials were re-edited and uploaded to Google Colab. See <a class="reference internal" href="#label-slide-2022-may-1"><span class="std std-ref">ICASSP 2022 short course: neural vocoder</span></a>.</p>
</section>
<section id="sep-2019">
<span id="label-slide-2019-sep-1"></span><h3>SEP-2019<a class="headerlink" href="#sep-2019" title="Permalink to this heading">¶</a></h3>
<p><strong>Neural waveform models for text-to-speech synthesis</strong></p>
<p>Invited talk given at Fraunhofer IIS, Erlangen, Germany.</p>
<p>This is about the neural source-filter vocoders and related experiments done by 2019.</p>
<p>Slide is <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAByUSX6u4O51bGHpIFlgy-ba/web/201909-FraunhoderIIS-neural-waveform-models.pdf?raw=1">here 1</a></p>
</section>
<section id="jan-2019">
<span id="label-slide-2019-jan-1"></span><h3>JAN-2019<a class="headerlink" href="#jan-2019" title="Permalink to this heading">¶</a></h3>
<p><strong>Tutorial on recent neural waveform models</strong></p>
<p>This is a talk on neural vocoders, but the contents and explanations are based on my knowledge by then. It is out-of-date. Please check tutorials above for my latest understanding.</p>
<p>IEICE Technical Committee on Speech (SP), invited tutorial, Kanazawa, Japan. Slide is <a class="reference external" href="https://www.slideshare.net/jyamagis/tutorial-on-endtoend-texttospeech-synthesis-part-1-neural-waveform-modeling">here 2</a></p>
</section>
<section id="jan-2018">
<span id="label-slide-2018-jan-1"></span><h3>JAN-2018<a class="headerlink" href="#jan-2018" title="Permalink to this heading">¶</a></h3>
<p><strong>Autoregressive neural networks for parametric speech synthesis</strong></p>
<p>This is a talk on the previous-generation TTS system. It talks about autoregressive models for F0 prediction.</p>
<p>It was given at Nagoya Institute of Technology, Tokuda lab, and Aalto University, Paavo Alku lab. Slide is <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AACZVX1Tf9Qw1MUc2YHQKf4Ia/web/20180111-Nagoya-ARmodels.pdf?raw=1">here 3</a></p>
</section>
</section>
<section id="conference-presentation">
<h2>Conference presentation<a class="headerlink" href="#conference-presentation" title="Permalink to this heading">¶</a></h2>
<p>Anti-spoofing: Interspeech 2021 presentation for <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAAbQM0rKGea4t5i5m6rn_F_a/web/2021-interspeech-Fri-M-V-7-1.pdf?raw=1">Comparative study on ASVspoof 2019 LA, PPT</a>. Codes are available at <a class="reference external" href="https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts">git repo project/03-asvspoof-mega</a></p>
<p>NSF model (latest ver.): Interspeech 2020 presentation for cyclic-noise-NSF – <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAAMoAEj77_oy4FmG0rkCTWwa/web/2020-interspech.pptx?raw=1">PPT</a> and <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAD0BZlZh4TexeLs3VQVY0kJa/web/2020-interspech.pdf?raw=1">PDF slides</a> . Natural samples are from <a class="reference external" href="http://www.festvox.org/cmu_arctic/">CMU-arctic</a></p>
<p>NSF model (2nd ver.): <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABEVzUUqnJ4QbkxiQcjOhM5a/web/2019-ssw.pdf?raw=1">SSW 2019</a> for paper Neural Harmonic-plus-Noise Waveform Model with Trainable Maximum Voice Frequency for Text-to-Speech Synthesis</p>
<p>NSF model (1st ver.): <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AACIlTwfcTeJYNlMBlnZLE52a/web/2019-ICASSP.pdf?raw=1">ICASSP 2019</a> for paper Neural Source-Filter-Based Waveform Model for Statistical Parametric Speech Synthesis</p>
<p>Speech synthesis comparison: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAC8XgykCv9hSChQMgtzAmVSa/web/2018-ICASSP.pdf?raw=1">ICASSP 2018</a> for paper A Comparison of Recent Waveform Generation and Acoustic Modeling Methods for Neural-Network-Based Speech Synthesis</p>
<p>Deep AR F0 model: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAA0rZJEq6lQYU98mamyterka/web/2017-interspeech.pdf?raw=1">Interspeech 2017 slide</a> for paper An RNN-Based Quantized F0 Model with Multi-Tier Feedback Links for Text-to-Speech Synthesis.</p>
<p>Shallow AR model: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAA5syHnVZvJrljcOILi5U4ga/web/2017-ICASSP.pdf?raw=1">ICASSP 2017 slide</a> for paper An Autoregressive Recurrent Mixture Density Network for Parametric Speech Synthesis.</p>
<p>Speech synthesis: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AACozQp08QjxkmyFEDQlMDZha/web/2016_JVoice.pdf?raw=1">SSW 2016 slide</a> for paper A Comparative Study of the Performance of HMM, DNN, and RNN Based Speech Synthesis Systems Trained on Very Large Speaker-Dependent Corpora.</p>
<p>Prosody embedding: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AADDYHrpFe6b8AbjWjqpRuqTa/web/2016-interspeech.pdf?raw=1">Interspeech 2016 slide</a> for paper Enhance the Word Vector with Prosodic Information for the Recurrent Neural Network Based TTS System.</p>
<p>HMM-based speech synthesis: <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AADzOxHtpW9V6SpRAGEZMLXTa/web/2016-ICASSP.pdf?raw=1">ICASSP 2016 slide</a>. For paper A Full Training Framework of Cross-Stream Dependence Modelling for HMM-Based Singing Voice Synthesis.</p>
</section>
<section id="misc">
<h2>MISC<a class="headerlink" href="#misc" title="Permalink to this heading">¶</a></h2>
<p>On CURRENNT toolkit. These slides were made a long time ago during weekends, and they may be sloppy :)</p>
<blockquote>
<div><ul class="simple">
<li><p>CURRENNT <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABQBuX7Sepgt-1zK49wUTH2a/web/misc-CURRENNT_BASIC.pdf?raw=1">basics</a></p></li>
<li><p>CURRENNT <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAASRaMvZkSc29CyZ_WMXWRIa/web/misc-CURRENNT_LSTM.pdf?raw=1">LSTM explanation</a></p></li>
<li><p>CURRENNT <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AACH1seKkkLfLjEhOsWFr3gSa/web/misc-CURRENNT_CNN.pdf?raw=1">CNN implementation</a></p></li>
<li><p>CURRENNT <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AABz4QF9IN5Fa1NlwCrNghJKa/web/misc-CURRENNT_MDN.pdf?raw=1">mixture density network</a></p></li>
<li><p>CURRENNT <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAB5Q1Hdm9WBW8IZ6nepSH9xa/web/misc-CURRENNT_WaveNet.pdf?raw=1">WaveNet</a></p></li>
</ul>
</div></blockquote>
<p>CURRENNT WaveNet is also explained in <a class="reference external" href="https://www.dropbox.com/sh/gf3zp00qvdp3row/AAAxWSo8bmFTTEi0mmJOPPQ_a/web/2018-SLP-tsukuba.pdf?raw=1">another slide</a> with more figures.</p>
<div class="toctree-wrapper compound">
</div>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h3><a href="index.html">Page contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Talk &amp; slides</a><ul>
<li><a class="reference internal" href="#talk">Talk</a><ul>
<li><a class="reference internal" href="#nov-2023">NOV-2023</a></li>
<li><a class="reference internal" href="#oct-2023">OCT-2023</a></li>
<li><a class="reference internal" href="#aug-2023">AUG-2023</a></li>
<li><a class="reference internal" href="#mar-2023">MAR-2023</a></li>
<li><a class="reference internal" href="#sep-2022">SEP-2022</a></li>
<li><a class="reference internal" href="#may-2022">MAY-2022</a></li>
<li><a class="reference internal" href="#dec-2021">DEC-2021</a></li>
<li><a class="reference internal" href="#oct-2021">OCT-2021</a></li>
<li><a class="reference internal" href="#jul-2021">JUL-2021</a></li>
<li><a class="reference internal" href="#dec-2020">DEC-2020</a></li>
<li><a class="reference internal" href="#nov-2020">NOV-2020</a></li>
<li><a class="reference internal" href="#jul-2020">JUL-2020</a></li>
<li><a class="reference internal" href="#sep-2019">SEP-2019</a></li>
<li><a class="reference internal" href="#jan-2019">JAN-2019</a></li>
<li><a class="reference internal" href="#jan-2018">JAN-2018</a></li>
</ul>
</li>
<li><a class="reference internal" href="#conference-presentation">Conference presentation</a></li>
<li><a class="reference internal" href="#misc">MISC</a></li>
</ul>
</li>
</ul>
<h3><a href="index.html">Site map</a></h3>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="index.html">Welcome</a></li>
<li class="toctree-l1"><a class="reference internal" href="resume.html">Resume</a></li>
<li class="toctree-l1"><a class="reference internal" href="research.html">Research overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="presto.html">Research PRESTO</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Talk &amp; slides</a></li>
</ul>

<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2020, WangXin.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.0.0</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.12</a>
      
      |
      <a href="_sources/slide.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>
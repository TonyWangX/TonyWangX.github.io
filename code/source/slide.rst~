.. temp documentation master file, created by
   sphinx-quickstart on Sun Aug 30 20:18:34 2020.
   You can adapt this file completely to your liking, but it should at least
   contain the root `toctree` directive.

.. _label-slide:

Talk & slides
*************
Here are somes slides. 

In most cases, I cannot directly share samples through PDF. Some samples can be found through the link in the PDF.

Talk
============
**Tutorial on recent sequence-to-sequence TTS models**. 2020 Oct, For Odyssey 2020. `PDF <https://www.dropbox.com/sh/gf3zp00qvdp3row/AABFY0RiorILzSuX1YuQXyA7a/web/Odyssesy2020_Tutorial_TTS_XINWANG.pdf?raw=1>`_ and `PPT slides <https://www.dropbox.com/sh/gf3zp00qvdp3row/AABn3DyzRuZeBJwEGPV1ouFSa/web/Odyssesy2020_Tutorial_TTS_XINWANG.pptx?raw=1>`_ are available. Audios are collected from reference papers' official websites or from open domain data repository.

**Neural auto-regressive, source-filter and glottal vocoders for speech and music signals**. 2020 Jul, Tutorial at ISCA 2020 Speech Processing Courses in Crete, with Prof. Yamagishi. Hands-on-materials on `github <https://github.com/nii-yamagishilab/project-NN-Pytorch-scripts/tree/master/tutorials>`_.

**Neural waveform models for text-to-speech synthesis**. 2019 Sep, Fraunhofer IIS, invited talk, Erlangen, Germany. Slide is `here 1 <https://www.dropbox.com/sh/gf3zp00qvdp3row/AAByUSX6u4O51bGHpIFlgy-ba/web/201909-FraunhoderIIS-neural-waveform-models.pdf?raw=1>`_

**Tutorial on recent neural waveform models**. 2019 Jan, IEICE Technical Committee on Speech (SP), invited tutorial, Kanazawa, Japan. Slide is `here 2 <https://www.slideshare.net/jyamagis/tutorial-on-endtoend-texttospeech-synthesis-part-1-neural-waveform-modeling>`_

**Autoregressive neural networks for parametric speech synthesis**, 2018 Jan, Nagoya Institute of Technology, Tokuda lab & 2018 Jun, Aalto University, Paavo Alku lab. Slide is `here 3 <https://www.dropbox.com/sh/gf3zp00qvdp3row/AACZVX1Tf9Qw1MUc2YHQKf4Ia/web/20180111-Nagoya-ARmodels.pdf?raw=1>`_


Conference presentation
=======================
NSF model (latest ver.): Interspeech 2020 presentation for cyclic-noise-NSF -- `PPT <https://www.dropbox.com/sh/gf3zp00qvdp3row/AAAMoAEj77_oy4FmG0rkCTWwa/web/2020-interspech.pptx?raw=1>`_ and `PDF slides <https://www.dropbox.com/sh/gf3zp00qvdp3row/AAD0BZlZh4TexeLs3VQVY0kJa/web/2020-interspech.pdf?raw=1>`_ . Natural samples are from `CMU-arctic <http://www.festvox.org/cmu_arctic/>`_


NSF model (2nd ver.): `SSW 2019 <https://www.dropbox.com/sh/gf3zp00qvdp3row/AABEVzUUqnJ4QbkxiQcjOhM5a/web/2019-ssw.pdf?raw=1>`_ for paper Neural Harmonic-plus-Noise Waveform Model with Trainable Maximum Voice Frequency for Text-to-Speech Synthesis


NSF model (1st ver.): `ICASSP 2019 <https://www.dropbox.com/sh/gf3zp00qvdp3row/AACIlTwfcTeJYNlMBlnZLE52a/web/2019-ICASSP.pdf?raw=1>`_ for paper Neural Source-Filter-Based Waveform Model for Statistical Parametric Speech Synthesis

Speech synthesis comparison: `ICASSP 2018 <https://www.dropbox.com/sh/gf3zp00qvdp3row/AAC8XgykCv9hSChQMgtzAmVSa/web/2018-ICASSP.pdf?raw=1>`_ for paper A Comparison of Recent Waveform Generation and Acoustic Modeling Methods for Neural-Network-Based Speech Synthesis

Deep AR F0 model: `Interspeech 2017 slide <https://www.dropbox.com/sh/gf3zp00qvdp3row/AAA0rZJEq6lQYU98mamyterka/web/2017-interspeech.pdf?raw=1>`_ for paper An RNN-Based Quantized F0 Model with Multi-Tier Feedback Links for Text-to-Speech Synthesis.
 
Shallow AR model: `ICASSP 2017 slide <https://www.dropbox.com/sh/gf3zp00qvdp3row/AAA5syHnVZvJrljcOILi5U4ga/web/2017-ICASSP.pdf?raw=1>`_ for paper An Autoregressive Recurrent Mixture Density Network for Parametric Speech Synthesis.

Speech synthesis: `SSW 2016 slide <https://www.dropbox.com/sh/gf3zp00qvdp3row/AACozQp08QjxkmyFEDQlMDZha/web/2016_JVoice.pdf?raw=1>`_ for paper A Comparative Study of the Performance of HMM, DNN, and RNN Based Speech Synthesis Systems Trained on Very Large Speaker-Dependent Corpora.

Prosody embedding: `Interspeech 2016 slide <https://www.dropbox.com/sh/gf3zp00qvdp3row/AADDYHrpFe6b8AbjWjqpRuqTa/web/2016-interspeech.pdf?raw=1>`_ for paper Enhance the Word Vector with Prosodic Information for the Recurrent Neural Network Based TTS System.

HMM-based speech synthesis: `ICASSP 2016 slide <https://www.dropbox.com/sh/gf3zp00qvdp3row/AADzOxHtpW9V6SpRAGEZMLXTa/web/2016-ICASSP.pdf?raw=1>`_. For paper A Full Training Framework of Cross-Stream Dependence Modelling for HMM-Based Singing Voice Synthesis.


MISC
====

On CURRENNT toolkit. These slides were made a long time ago during weekends, and they may be sloppy :)


 * CURRENNT `basics <https://www.dropbox.com/sh/gf3zp00qvdp3row/AABQBuX7Sepgt-1zK49wUTH2a/web/misc-CURRENNT_BASIC.pdf?raw=1>`_ 

 * CURRENNT `LSTM explanation <https://www.dropbox.com/sh/gf3zp00qvdp3row/AAASRaMvZkSc29CyZ_WMXWRIa/web/misc-CURRENNT_LSTM.pdf?raw=1>`_

 * CURRENNT `CNN implementation <https://www.dropbox.com/sh/gf3zp00qvdp3row/AACH1seKkkLfLjEhOsWFr3gSa/web/misc-CURRENNT_CNN.pdf?raw=1>`_

 * CURRENNT `mixture density network <https://www.dropbox.com/sh/gf3zp00qvdp3row/AABz4QF9IN5Fa1NlwCrNghJKa/web/misc-CURRENNT_MDN.pdf?raw=1>`_

 * CURRENNT `WaveNet <https://www.dropbox.com/sh/gf3zp00qvdp3row/AAB5Q1Hdm9WBW8IZ6nepSH9xa/web/misc-CURRENNT_WaveNet.pdf?raw=1>`_


CURRENNT WaveNet is also explained in `another slide <https://www.dropbox.com/sh/gf3zp00qvdp3row/AAAxWSo8bmFTTEi0mmJOPPQ_a/web/2018-SLP-tsukuba.pdf?raw=1>`_ with more figures.



.. toctree::
   :hidden:
   :maxdepth: 1
